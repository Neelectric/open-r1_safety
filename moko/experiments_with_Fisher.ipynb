{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "lcg7OL6UDyJd"
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers accelerate\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322,
          "referenced_widgets": [
            "0a9cd86371154105b73bcf2ede9feea1",
            "4017aa81e3504205b797a47b4541d236",
            "1afded3de67843e89d9ce05dacf97cf6",
            "3d2e1581055140788c0638914354f8ed",
            "b07617e6f8d34273a5929b6ed5998120",
            "c27c084743f643cc972967bcb0eb5753",
            "6e69c53fb73d44caaf004f4a1baf5330",
            "4a197dbff6da43a6b445dfe17b2c2522",
            "412823a0f00e42059339c56fb4bd9c9f",
            "7bc5dd35c071495b82c20903d663b66c",
            "91a9aec8a55f4f418af506009da10f35",
            "d2e42c54ade243779ec71eb5fd4a51bf",
            "6099f135e0814a47822b3749934696b3",
            "3ee498aad5c54b4c956bb39619959b60",
            "5df1c3945e404094b3f18c099b502a84",
            "7dddedc6cfcb46848461c6aa231650ec",
            "a2f3c8562c204b1d9222851eed5f106f",
            "f521b4a4d7154de6ba16f3e6bdf59b51",
            "e6c8823a320447f7bae20c76e4070c0b",
            "8c9e710110a6423b84ade1d41b8a0529",
            "00a45ce331f049659ddc5a8d3a733689",
            "b7e41e3eac364027a5a1bf7342f7bd49",
            "c199e25df4d54001919f0481edc0b358",
            "e7c2de72aff4428db80fd3ddd8d82557",
            "cb45de6c1d7d4dc7809c42da301e9fba",
            "d8e0603c141f4674a1f57399cee4ef45",
            "8d5615ddaac748d7a1ba5a26726aa6fb",
            "4e9ea7427ef0479c9b0216fdb9604c8a",
            "7805724c2c5448d4b29119483f055636",
            "d928ee45c23f436a9aa89ca5ef53df92",
            "ff49ae10aa48498dbb0cc35ab638c298",
            "019d2a1857fe46099f9fc01c6ba6b8d7",
            "92bf0487d45e4c06869ae88ee0bb877c",
            "46ab261f4cc549e181eeae76c646abaa",
            "21357a168091432fbf46ec848df81842",
            "53dbd36dc7e4462f8d94a403a0d82875",
            "c1bac9dec2244a1e9eef085386d047f1",
            "ec9d2bfc9b82450199239de8eada416d",
            "b5f3adfc279949e58696997e532348ee",
            "4eb8fcc217cf4b9e98b63c09077a17ec",
            "4644d3f2f33d4f089ee5d788d8a2a0ef",
            "38706d9664be4357b79dd614fbac9b27",
            "8ebe0ad1bb4e456a97821b31d8dfb9f6",
            "4a2226e944a4410aa53f1717e07169b5",
            "19a30732e19745b8a333de9eb6332a41",
            "46a0746bf84440f38874b729d617f1df",
            "9de635c4e355447e8e2a4d9f760fdfde",
            "8998157212b8431ba8509dd0df98981b",
            "9921b84c7f784e7ba9f32a97602546a7",
            "f9182aedceb2421b9a77a245d20a9a1e",
            "95b18249d1884fa7895fb09393d2598b",
            "11481ce4d7c54a20b328fe987088d02b",
            "e97ed5800cff4055900545ff376979be",
            "675449c0ef484dc3b3baae5bbe8b5fd5",
            "65ac5143b332424ca9424506b20cd40a"
          ]
        },
        "id": "-KxrbhNtq7bc",
        "outputId": "bd4e7ec8-ef80-4cb7-d16a-808a85c8fd6c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/user/repos/open-r1_safety/openr1_v3/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: cuda:1\n"
          ]
        }
      ],
      "source": [
        "import math\n",
        "import copy\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import GPT2LMHeadModel, GPT2TokenizerFast\n",
        "\n",
        "device = \"cuda:1\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Device:\", device)\n",
        "\n",
        "model_name = \"gpt2\"\n",
        "tokenizer = GPT2TokenizerFast.from_pretrained(model_name)\n",
        "tokenizer.pad_token = tokenizer.eos_token  # for batching\n",
        "\n",
        "# # Tiny toy corpora\n",
        "# protected_french_texts = [\n",
        "#     \"Ceci est une phrase française simple.\",\n",
        "#     \"Le chat noir dort sur le canapé.\",\n",
        "#     \"La météo est agréable aujourd'hui à Paris.\",\n",
        "#     \"Les réseaux de neurones profonds apprennent des représentations complexes.\",\n",
        "# ] * 200  # repeat to get more samples\n",
        "\n",
        "# new_english_texts = [\n",
        "#     \"This is a simple English sentence.\",\n",
        "#     \"The neural network is fine-tuned on a new dataset.\",\n",
        "#     \"We evaluate catastrophic forgetting in this experiment.\",\n",
        "#     \"Language models are tested on multiple capabilities.\",\n",
        "# ] * 200\n",
        "\n",
        "!wget -q -O petit_prince.txt https://www.gutenberg.org/cache/epub/70167/pg70167.txt\n",
        "!wget -q -O alice.txt https://www.gutenberg.org/cache/epub/11/pg11.txt\n",
        "\n",
        "with open(\"petit_prince.txt\") as f:\n",
        "    protected_french_texts = [line.strip() for line in f if len(line.strip()) > 20]\n",
        "\n",
        "with open(\"alice.txt\") as f:\n",
        "    new_english_texts = [line.strip() for line in f if len(line.strip()) > 20]\n",
        "\n",
        "# Train / test splits\n",
        "split_f = int(0.8 * len(protected_french_texts))\n",
        "split_e = int(0.8 * len(new_english_texts))\n",
        "\n",
        "french_train = protected_french_texts[:split_f]\n",
        "french_test  = protected_french_texts[split_f:]\n",
        "\n",
        "english_train = new_english_texts[:split_e]\n",
        "english_test  = new_english_texts[split_e:]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ynTogCxlD6qe",
        "outputId": "2fa89744-95db-4461-bd1f-e9bc372e1f99"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2075, 1026)"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import math\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import GPT2LMHeadModel, GPT2TokenizerFast\n",
        "\n",
        "\n",
        "class LineByLineLMDataset(Dataset):\n",
        "    def __init__(self, texts, tokenizer, block_size=64):\n",
        "        self.examples = []\n",
        "        for t in texts:\n",
        "            ids = tokenizer(\n",
        "                t,\n",
        "                truncation=True,\n",
        "                max_length=block_size,\n",
        "                return_attention_mask=False,\n",
        "                return_tensors=\"pt\",\n",
        "            )[\"input_ids\"][0]\n",
        "            if ids.numel() > 1:\n",
        "                self.examples.append(ids)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.examples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.examples[idx]\n",
        "\n",
        "def collate_fn(batch):\n",
        "    batch = [b for b in batch if b.numel() > 1]\n",
        "    max_len = max(x.size(0) for x in batch)\n",
        "    input_ids = []\n",
        "    attention_mask = []\n",
        "    labels = []\n",
        "    for x in batch:\n",
        "        pad_len = max_len - x.size(0)\n",
        "        padded = torch.cat([x, x.new_full((pad_len,), tokenizer.pad_token_id)])\n",
        "        mask = torch.cat([torch.ones_like(x), torch.zeros(pad_len, dtype=torch.long)])\n",
        "        lab = padded.clone()\n",
        "        lab[mask == 0] = -100  # ignore padding in loss\n",
        "        input_ids.append(padded)\n",
        "        attention_mask.append(mask)\n",
        "        labels.append(lab)\n",
        "    return {\n",
        "        \"input_ids\": torch.stack(input_ids),\n",
        "        \"attention_mask\": torch.stack(attention_mask),\n",
        "        \"labels\": torch.stack(labels),\n",
        "    }\n",
        "\n",
        "block_size = 64\n",
        "batch_size = 8\n",
        "\n",
        "french_train_ds  = LineByLineLMDataset(french_train, tokenizer, block_size)\n",
        "french_test_ds   = LineByLineLMDataset(french_test,  tokenizer, block_size)\n",
        "english_train_ds = LineByLineLMDataset(english_train, tokenizer, block_size)\n",
        "english_test_ds  = LineByLineLMDataset(english_test,  tokenizer, block_size)\n",
        "\n",
        "eng_loader = DataLoader(english_train_ds, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
        "fr_loader  = DataLoader(french_train_ds,  batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
        "\n",
        "len(english_train_ds), len(french_train_ds)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "3COzmCNrD8_u"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def eval_ppl(model, dataset, name, batch_size_eval=8):\n",
        "    model.eval()\n",
        "    loader = DataLoader(dataset, batch_size=batch_size_eval, shuffle=False, collate_fn=collate_fn)\n",
        "    total_loss = 0.0\n",
        "    total_tokens = 0\n",
        "    for batch in loader:\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "        out = model(**batch)\n",
        "        loss = out.loss * batch[\"attention_mask\"].sum()\n",
        "        total_loss += loss.item()\n",
        "        total_tokens += batch[\"attention_mask\"].sum().item()\n",
        "    ppl = math.exp(total_loss / total_tokens)\n",
        "    print(f\"{name} perplexity: {ppl:.3f}\")\n",
        "    model.train()\n",
        "    return ppl\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527,
          "referenced_widgets": [
            "bbe725cd4bf4424490b1b6444fd128a2",
            "149b331d4d87433398ee419064405baa",
            "b0fa9161ed064445aece8d321b3d88a7",
            "cf32259002024b7da355cc4eb0a752e8",
            "503d3af66d1c4b47ac0f9fd4caf475ae",
            "c48cfdbb01a6438087a163d31de89005",
            "a8851e5f5d6f46e8860bc772fa5b81ea",
            "8ee340f1e44442aca9ad56eaf28e3ec6",
            "3c41a4d44ad349d2accb847f8ec65f41",
            "ce768476c2144ff58e413e5195528b39",
            "4f1ed9d96a5a4693ac360e9f90e42b8a",
            "8bdf857cc0fb474f9bf8c73fa0ea2257",
            "17a88ca67a994b51b5f425842c0ab3ff",
            "ecdf1063c4cc48cab41115fbda94cc85",
            "7681bec193b248ad8beca1bd01baf4c6",
            "1f6ddb9d63b442dcb6d2b772c5068212",
            "f7143d3bd72f4e1f9e119e1b29205cfb",
            "cf6bf77b10dc4e04920eb2c05b5a4347",
            "ed40a4f1820246b99ca964b03244c906",
            "a1fc267bd68947dfbafa9ed3e6fb56c9",
            "2846c79926f440708121d6b5efa2f901",
            "3adc4be8a5e442cc8c4d230d8ec3ef85"
          ]
        },
        "id": "YCnIJL95D_xR",
        "outputId": "e54bb78b-1a96-43cb-d896-271084ac0983"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`loss_type=None` was set in the config but it is unrecognized. Using the default loss: `ForCausalLMLoss`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Before opt:\n",
            "English new perplexity: 83.357\n",
            "French protected perplexity: 44.141\n",
            "=== Baseline Adam: train on English only ===\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 32\u001b[39m\n\u001b[32m     29\u001b[39m         fr_ppl  = eval_ppl(model, french_test_ds,  \u001b[33m\"\u001b[39m\u001b[33mFrench protected\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     30\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m baseline_model = \u001b[43mrun_baseline_adam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1e-5\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 19\u001b[39m, in \u001b[36mrun_baseline_adam\u001b[39m\u001b[34m(num_epochs, lr)\u001b[39m\n\u001b[32m     17\u001b[39m batch = {k: v.to(device) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m batch.items()}\n\u001b[32m     18\u001b[39m model.zero_grad()\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m out = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m loss = out.loss\n\u001b[32m     21\u001b[39m loss.backward()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/repos/open-r1_safety/openr1_v3/lib/python3.11/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/repos/open-r1_safety/openr1_v3/lib/python3.11/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/repos/open-r1_safety/openr1_v3/lib/python3.11/site-packages/transformers/models/gpt2/modeling_gpt2.py:1068\u001b[39m, in \u001b[36mGPT2LMHeadModel.forward\u001b[39m\u001b[34m(self, input_ids, past_key_values, cache_position, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict, logits_to_keep, **kwargs)\u001b[39m\n\u001b[32m   1048\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1049\u001b[39m \u001b[33;03minput_ids (`torch.LongTensor` of shape `(batch_size, input_ids_length)`):\u001b[39;00m\n\u001b[32m   1050\u001b[39m \u001b[33;03m    `input_ids_length` = `sequence_length` if `past_key_values` is `None` else\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1064\u001b[39m \u001b[33;03m    are ignored (masked), the loss is only computed for labels in `[0, ..., config.vocab_size]`\u001b[39;00m\n\u001b[32m   1065\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1066\u001b[39m return_dict = return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config.use_return_dict\n\u001b[32m-> \u001b[39m\u001b[32m1068\u001b[39m transformer_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1069\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1070\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1071\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1072\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1073\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1074\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1075\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1076\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1077\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1078\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1079\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1080\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1081\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1082\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1083\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1084\u001b[39m hidden_states = transformer_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m   1086\u001b[39m \u001b[38;5;66;03m# Set device for model parallelism\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/repos/open-r1_safety/openr1_v3/lib/python3.11/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/repos/open-r1_safety/openr1_v3/lib/python3.11/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/repos/open-r1_safety/openr1_v3/lib/python3.11/site-packages/transformers/models/gpt2/modeling_gpt2.py:951\u001b[39m, in \u001b[36mGPT2Model.forward\u001b[39m\u001b[34m(self, input_ids, past_key_values, cache_position, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict, **kwargs)\u001b[39m\n\u001b[32m    948\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m i == v[-\u001b[32m1\u001b[39m] \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mcuda:\u001b[39m\u001b[33m\"\u001b[39m + \u001b[38;5;28mstr\u001b[39m(k) != \u001b[38;5;28mself\u001b[39m.last_device:\n\u001b[32m    949\u001b[39m                 hidden_states = hidden_states.to(\u001b[33m\"\u001b[39m\u001b[33mcuda:\u001b[39m\u001b[33m\"\u001b[39m + \u001b[38;5;28mstr\u001b[39m(k + \u001b[32m1\u001b[39m))\n\u001b[32m--> \u001b[39m\u001b[32m951\u001b[39m hidden_states = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mln_f\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    953\u001b[39m hidden_states = hidden_states.view(output_shape)\n\u001b[32m    954\u001b[39m \u001b[38;5;66;03m# Add last hidden state\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/repos/open-r1_safety/openr1_v3/lib/python3.11/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/repos/open-r1_safety/openr1_v3/lib/python3.11/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/repos/open-r1_safety/openr1_v3/lib/python3.11/site-packages/torch/nn/modules/normalization.py:217\u001b[39m, in \u001b[36mLayerNorm.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlayer_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnormalized_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43meps\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/repos/open-r1_safety/openr1_v3/lib/python3.11/site-packages/torch/nn/functional.py:2905\u001b[39m, in \u001b[36mlayer_norm\u001b[39m\u001b[34m(input, normalized_shape, weight, bias, eps)\u001b[39m\n\u001b[32m   2895\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_variadic(\u001b[38;5;28minput\u001b[39m, weight, bias):\n\u001b[32m   2896\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m   2897\u001b[39m         layer_norm,\n\u001b[32m   2898\u001b[39m         (\u001b[38;5;28minput\u001b[39m, weight, bias),\n\u001b[32m   (...)\u001b[39m\u001b[32m   2903\u001b[39m         eps=eps,\n\u001b[32m   2904\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m2905\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlayer_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2906\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalized_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackends\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcudnn\u001b[49m\u001b[43m.\u001b[49m\u001b[43menabled\u001b[49m\n\u001b[32m   2907\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "from torch.optim import AdamW\n",
        "\n",
        "def run_baseline_adam(num_epochs=2, lr=1e-5):\n",
        "    base_model = GPT2LMHeadModel.from_pretrained(model_name)\n",
        "    base_model.resize_token_embeddings(len(tokenizer))\n",
        "    model = copy.deepcopy(base_model).to(device)\n",
        "    optimizer = AdamW(model.parameters(), lr=lr)\n",
        "\n",
        "    print(f\"Before opt:\")\n",
        "    eng_ppl = eval_ppl(model, english_test_ds, \"English new\")\n",
        "    fr_ppl  = eval_ppl(model, french_test_ds,  \"French protected\")\n",
        "\n",
        "\n",
        "    print(\"=== Baseline Adam: train on English only ===\")\n",
        "    for epoch in range(num_epochs):\n",
        "        for step, batch in enumerate(eng_loader):\n",
        "            batch = {k: v.to(device) for k, v in batch.items()}\n",
        "            model.zero_grad()\n",
        "            out = model(**batch)\n",
        "            loss = out.loss\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            if (step + 1) % 100 == 0:\n",
        "                print(f\"[Epoch {epoch} Step {step+1}] loss_new = {loss.item():.4f}\")\n",
        "\n",
        "        print(f\"Epoch {epoch} evaluation:\")\n",
        "        eng_ppl = eval_ppl(model, english_test_ds, \"English new\")\n",
        "        fr_ppl  = eval_ppl(model, french_test_ds,  \"French protected\")\n",
        "    return model\n",
        "\n",
        "baseline_model = run_baseline_adam(num_epochs=4, lr=1e-5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lz-u9NgkECO1",
        "outputId": "ed415c53-b8ac-47e4-822d-23c48409b63a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Estimating Fisher on French (protected) ...\n",
            "=== EWC: train on English with French EWC penalty ===\n",
            "[Epoch 0 Step 100] loss_new=3.5822, ewc_loss=0.0003\n",
            "[Epoch 0 Step 200] loss_new=2.9228, ewc_loss=0.0004\n",
            "Epoch 0 evaluation:\n",
            "English new (EWC) perplexity: 40.576\n",
            "French protected (EWC) perplexity: 70.271\n",
            "[Epoch 1 Step 100] loss_new=2.4151, ewc_loss=0.0004\n",
            "[Epoch 1 Step 200] loss_new=3.2441, ewc_loss=0.0004\n",
            "Epoch 1 evaluation:\n",
            "English new (EWC) perplexity: 39.289\n",
            "French protected (EWC) perplexity: 63.495\n",
            "[Epoch 2 Step 100] loss_new=2.7618, ewc_loss=0.0004\n",
            "[Epoch 2 Step 200] loss_new=2.3203, ewc_loss=0.0004\n",
            "Epoch 2 evaluation:\n",
            "English new (EWC) perplexity: 42.227\n",
            "French protected (EWC) perplexity: 71.375\n"
          ]
        }
      ],
      "source": [
        "def estimate_fisher_on_french(model, num_batches=200):\n",
        "    model.eval()\n",
        "    params = [p for p in model.parameters() if p.requires_grad]\n",
        "    fisher = {p: torch.zeros_like(p.data) for p in params}\n",
        "\n",
        "    loader = DataLoader(french_train_ds, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
        "    it = iter(loader)\n",
        "    for i in range(num_batches):\n",
        "        try:\n",
        "            batch = next(it)\n",
        "        except StopIteration:\n",
        "            it = iter(loader)\n",
        "            batch = next(it)\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "        model.zero_grad()\n",
        "        out = model(**batch)\n",
        "        loss = out.loss\n",
        "        loss.backward()\n",
        "        for p in params:\n",
        "            if p.grad is None:\n",
        "                continue\n",
        "            fisher[p] += p.grad.data.pow(2)\n",
        "    for p in params:\n",
        "        fisher[p] /= num_batches\n",
        "    model.train()\n",
        "    return fisher\n",
        "\n",
        "def run_ewc(num_epochs=2, lr=5e-5, ewc_lambda=50.0):\n",
        "    base_model = GPT2LMHeadModel.from_pretrained(model_name)\n",
        "    base_model.resize_token_embeddings(len(tokenizer))\n",
        "    model = copy.deepcopy(base_model).to(device)\n",
        "\n",
        "    print(\"Estimating Fisher on French (protected) ...\")\n",
        "    fisher = estimate_fisher_on_french(model, num_batches=100)\n",
        "    theta0 = copy.deepcopy(model).to(device)\n",
        "\n",
        "    optimizer = AdamW(model.parameters(), lr=lr)\n",
        "\n",
        "    params = [p for p in model.parameters() if p.requires_grad]\n",
        "\n",
        "    print(\"=== EWC: train on English with French EWC penalty ===\")\n",
        "    for epoch in range(num_epochs):\n",
        "        for step, batch in enumerate(eng_loader):\n",
        "            batch = {k: v.to(device) for k, v in batch.items()}\n",
        "            model.zero_grad()\n",
        "            out = model(**batch)\n",
        "            loss_new = out.loss\n",
        "\n",
        "            ewc_loss = 0.0\n",
        "            for p, p0 in zip(params, theta0.parameters()):\n",
        "                ewc_loss = ewc_loss + (fisher[p] * (p - p0).pow(2)).sum()\n",
        "            total_loss = loss_new + 0.5 * ewc_lambda * ewc_loss\n",
        "\n",
        "            total_loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            if (step + 1) % 100 == 0:\n",
        "                print(f\"[Epoch {epoch} Step {step+1}] loss_new={loss_new.item():.4f}, ewc_loss={ewc_loss.item():.4f}\")\n",
        "\n",
        "        print(f\"Epoch {epoch} evaluation:\")\n",
        "        eng_ppl = eval_ppl(model, english_test_ds, \"English new (EWC)\")\n",
        "        fr_ppl  = eval_ppl(model, french_test_ds,  \"French protected (EWC)\")\n",
        "    return model\n",
        "\n",
        "ewc_model = run_ewc(num_epochs=3, lr=5e-5, ewc_lambda=50.0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5vS3js6UEEs8",
        "outputId": "50c1adf8-2795-458a-bc1a-6ff40a432ec3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== ProtectedAdam-γ: geometry shaped by French subset ===\n",
            "alpha_geom=1.0, beta_geom=10.0, gamma_exp=0.5\n",
            "[Epoch 0 Step 100] loss_new = 3.8433\n",
            "[Epoch 0 Step 200] loss_new = 3.3800\n",
            "Epoch 0 evaluation:\n",
            "English new (ProtectedAdam-γ) perplexity: 45.727\n",
            "French protected (ProtectedAdam-γ) perplexity: 60.150\n",
            "[Epoch 1 Step 100] loss_new = 3.5988\n",
            "[Epoch 1 Step 200] loss_new = 3.1743\n",
            "Epoch 1 evaluation:\n",
            "English new (ProtectedAdam-γ) perplexity: 44.364\n",
            "French protected (ProtectedAdam-γ) perplexity: 63.657\n",
            "[Epoch 2 Step 100] loss_new = 3.2928\n",
            "[Epoch 2 Step 200] loss_new = 3.4530\n",
            "Epoch 2 evaluation:\n",
            "English new (ProtectedAdam-γ) perplexity: 43.520\n",
            "French protected (ProtectedAdam-γ) perplexity: 65.002\n"
          ]
        }
      ],
      "source": [
        "def run_protected_adam(\n",
        "    num_epochs=2,\n",
        "    lr=5e-5,\n",
        "    alpha_geom=1.0,\n",
        "    beta_geom=10.0,\n",
        "    gamma_exp=0.5,\n",
        "    subset_update_every=5,\n",
        "    rho_all=0.99,\n",
        "    rho_sub=0.99,\n",
        "):\n",
        "    base_model = GPT2LMHeadModel.from_pretrained(model_name)\n",
        "    base_model.resize_token_embeddings(len(tokenizer))\n",
        "    model = copy.deepcopy(base_model).to(device)\n",
        "    model.train()\n",
        "\n",
        "    params = [p for p in model.parameters() if p.requires_grad]\n",
        "\n",
        "    state = {}\n",
        "    for p in params:\n",
        "        state[p] = {\n",
        "            \"m\": torch.zeros_like(p.data),\n",
        "            \"v_all\": torch.zeros_like(p.data),\n",
        "            \"v_sub\": torch.zeros_like(p.data),\n",
        "        }\n",
        "\n",
        "    beta1 = 0.9\n",
        "    eps = 1e-6\n",
        "    global_step = 0\n",
        "\n",
        "    def protected_adam_step():\n",
        "        nonlocal global_step\n",
        "        global_step += 1\n",
        "        for p in params:\n",
        "            if p.grad is None:\n",
        "                continue\n",
        "            grad = p.grad.data\n",
        "            s = state[p]\n",
        "\n",
        "            # first moment\n",
        "            s[\"m\"].mul_(beta1).add_(grad, alpha=1 - beta1)\n",
        "\n",
        "            # second moment on \"all\" (new English) data\n",
        "            s[\"v_all\"].mul_(rho_all).addcmul_(grad, grad, value=1 - rho_all)\n",
        "\n",
        "            v_all = s[\"v_all\"]\n",
        "            v_sub = s[\"v_sub\"]\n",
        "            v_protect = alpha_geom * v_all + beta_geom * v_sub\n",
        "\n",
        "            m_hat = s[\"m\"] / (1 - beta1**global_step)\n",
        "            denom = (v_protect + eps).pow(gamma_exp)\n",
        "            step = m_hat / denom\n",
        "            p.data.add_(step, alpha=-lr)\n",
        "\n",
        "    def update_subset_curvature():\n",
        "        for p in params:\n",
        "            if p.grad is None:\n",
        "                continue\n",
        "            grad = p.grad.data\n",
        "            s = state[p]\n",
        "            s[\"v_sub\"].mul_(rho_sub).addcmul_(grad, grad, value=1 - rho_sub)\n",
        "\n",
        "    fr_iter = iter(fr_loader)\n",
        "\n",
        "    print(\"=== ProtectedAdam-γ: geometry shaped by French subset ===\")\n",
        "    print(f\"alpha_geom={alpha_geom}, beta_geom={beta_geom}, gamma_exp={gamma_exp}\")\n",
        "    for epoch in range(num_epochs):\n",
        "        for step, batch in enumerate(eng_loader):\n",
        "            # 1) English batch: gradient for new task\n",
        "            batch = {k: v.to(device) for k, v in batch.items()}\n",
        "            model.zero_grad()\n",
        "            out = model(**batch)\n",
        "            loss = out.loss\n",
        "            loss.backward()\n",
        "\n",
        "            # 2) Take ProtectedAdam step (updates v_all + params)\n",
        "            protected_adam_step()\n",
        "\n",
        "            # 3) Occasionally update subset curvature using French\n",
        "            if (step + 1) % subset_update_every == 0:\n",
        "                try:\n",
        "                    fr_batch = next(fr_iter)\n",
        "                except StopIteration:\n",
        "                    fr_iter = iter(fr_loader)\n",
        "                    fr_batch = next(fr_iter)\n",
        "                fr_batch = {k: v.to(device) for k, v in fr_batch.items()}\n",
        "                model.zero_grad()\n",
        "                fr_out = model(**fr_batch)\n",
        "                fr_loss = fr_out.loss\n",
        "                fr_loss.backward()\n",
        "                update_subset_curvature()\n",
        "                model.zero_grad()\n",
        "\n",
        "            if (step + 1) % 100 == 0:\n",
        "                print(f\"[Epoch {epoch} Step {step+1}] loss_new = {loss.item():.4f}\")\n",
        "\n",
        "        print(f\"Epoch {epoch} evaluation:\")\n",
        "        eng_ppl = eval_ppl(model, english_test_ds, \"English new (ProtectedAdam-γ)\")\n",
        "        fr_ppl  = eval_ppl(model, french_test_ds,  \"French protected (ProtectedAdam-γ)\")\n",
        "\n",
        "    return model\n",
        "\n",
        "protected_model = run_protected_adam(\n",
        "    num_epochs=3,\n",
        "    lr=1e-5,\n",
        "    alpha_geom=1.0,\n",
        "    beta_geom=10.0,   # strength of protected geometry\n",
        "    gamma_exp=0.5,    # between 0.5 (Adam) and 1.0 (diag NGD)\n",
        "    subset_update_every=5,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yHTG9YTgOOAf",
        "outputId": "f4d4a82a-4533-46c7-c6a2-cbc5f86580ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Before opt:\n",
            "English new (ProtectedAdam-γ) perplexity: 83.357\n",
            "French protected (ProtectedAdam-γ) perplexity: 44.141\n",
            "=== ProtectedAdam-γ: geometry shaped by French subset ===\n",
            "alpha_geom=1.0, beta_geom=10.0, gamma_exp=0.5\n",
            "[Epoch 0 Step 100] loss_new = 3.6329\n",
            "[Epoch 0 Step 200] loss_new = 3.1932\n",
            "Epoch 0 evaluation:\n",
            "English new (ProtectedAdam-γ) perplexity: 46.162\n",
            "French protected (ProtectedAdam-γ) perplexity: 80.233\n",
            "[Epoch 1 Step 100] loss_new = 3.5180\n",
            "[Epoch 1 Step 200] loss_new = 3.0306\n",
            "Epoch 1 evaluation:\n",
            "English new (ProtectedAdam-γ) perplexity: 43.418\n",
            "French protected (ProtectedAdam-γ) perplexity: 76.258\n",
            "[Epoch 2 Step 100] loss_new = 2.7845\n"
          ]
        }
      ],
      "source": [
        "def run_protected_adam2(\n",
        "    num_epochs=3,\n",
        "    lr=5e-5,\n",
        "    alpha_geom=1.0,\n",
        "    beta_geom=10.0,\n",
        "    gamma_exp=0.5,\n",
        "    subset_update_every=5,\n",
        "    rho_all=0.99,\n",
        "    rho_sub=0.99,\n",
        "):\n",
        "    base_model = GPT2LMHeadModel.from_pretrained(model_name)\n",
        "    base_model.resize_token_embeddings(len(tokenizer))\n",
        "    model = copy.deepcopy(base_model).to(device)\n",
        "    model.train()\n",
        "\n",
        "    params = [p for p in model.parameters() if p.requires_grad]\n",
        "\n",
        "    state = {}\n",
        "    for p in params:\n",
        "        state[p] = {\n",
        "            \"m\": torch.zeros_like(p.data),\n",
        "            \"v_all\": torch.zeros_like(p.data),\n",
        "            \"v_sub\": torch.zeros_like(p.data),\n",
        "        }\n",
        "\n",
        "    beta1 = 0.9\n",
        "    eps = 1e-6\n",
        "    global_step = 0\n",
        "\n",
        "    def protected_adam_step():\n",
        "        nonlocal global_step\n",
        "        global_step += 1\n",
        "\n",
        "        # First pass: update moments, compute v_protect, and accumulate\n",
        "        # the mean denominators for γ=0.5 (baseline) and γ=gamma_exp\n",
        "        temp = {}\n",
        "        sum_baseline = 0.0\n",
        "        sum_gamma = 0.0\n",
        "        count_tensors = 0\n",
        "\n",
        "        for p in params:\n",
        "            if p.grad is None:\n",
        "                continue\n",
        "            grad = p.grad.data\n",
        "            s = state[p]\n",
        "\n",
        "            # First moment\n",
        "            s[\"m\"].mul_(beta1).add_(grad, alpha=1 - beta1)\n",
        "\n",
        "            # Second moment on \"all\" (new English) data\n",
        "            s[\"v_all\"].mul_(rho_all).addcmul_(grad, grad, value=1 - rho_all)\n",
        "\n",
        "            v_all = s[\"v_all\"]\n",
        "            v_sub = s[\"v_sub\"]\n",
        "            v_protect = alpha_geom * v_all + beta_geom * v_sub\n",
        "\n",
        "            # Bias-corrected first moment (optional but keeps Adam-like behaviour)\n",
        "            m_hat = s[\"m\"] / (1 - beta1**global_step)\n",
        "\n",
        "            denom_baseline = (v_protect + eps).pow(0.5)\n",
        "            denom_gamma = (v_protect + eps).pow(gamma_exp)\n",
        "\n",
        "            sum_baseline += denom_baseline.mean()\n",
        "            sum_gamma += denom_gamma.mean()\n",
        "            count_tensors += 1\n",
        "\n",
        "            temp[p] = {\n",
        "                \"m_hat\": m_hat,\n",
        "                \"v_protect\": v_protect,\n",
        "            }\n",
        "\n",
        "        if count_tensors == 0:\n",
        "            return\n",
        "\n",
        "        # Renormalization factor so that average step size matches γ=0.5 case\n",
        "        scale = (sum_baseline / sum_gamma).detach()\n",
        "\n",
        "        # Second pass: apply update with renormalized step size\n",
        "        for p in params:\n",
        "            if p.grad is None or p not in temp:\n",
        "                continue\n",
        "            buf = temp[p]\n",
        "            m_hat = buf[\"m_hat\"]\n",
        "            v_protect = buf[\"v_protect\"]\n",
        "\n",
        "            denom_gamma = (v_protect + eps).pow(gamma_exp)\n",
        "            step = (m_hat / denom_gamma) * scale\n",
        "            p.data.add_(step, alpha=-lr)\n",
        "\n",
        "    def update_subset_curvature():\n",
        "        for p in params:\n",
        "            if p.grad is None:\n",
        "                continue\n",
        "            grad = p.grad.data\n",
        "            s = state[p]\n",
        "            s[\"v_sub\"].mul_(rho_sub).addcmul_(grad, grad, value=1 - rho_sub)\n",
        "\n",
        "    fr_iter = iter(fr_loader)\n",
        "\n",
        "    print(f\"Before opt:\")\n",
        "    eng_ppl = eval_ppl(model, english_test_ds, \"English new (ProtectedAdam-γ)\")\n",
        "    fr_ppl  = eval_ppl(model, french_test_ds,  \"French protected (ProtectedAdam-γ)\")\n",
        "\n",
        "\n",
        "    print(\"=== ProtectedAdam-γ: geometry shaped by French subset ===\")\n",
        "    print(f\"alpha_geom={alpha_geom}, beta_geom={beta_geom}, gamma_exp={gamma_exp}\")\n",
        "    for epoch in range(num_epochs):\n",
        "        for step, batch in enumerate(eng_loader):\n",
        "            # 1) English batch: gradient for new task\n",
        "            batch = {k: v.to(device) for k, v in batch.items()}\n",
        "            model.zero_grad()\n",
        "            out = model(**batch)\n",
        "            loss = out.loss\n",
        "            loss.backward()\n",
        "\n",
        "            # 2) Take ProtectedAdam step (updates v_all + params)\n",
        "            protected_adam_step()\n",
        "\n",
        "            # 3) Occasionally update subset curvature using French\n",
        "            if (step + 1) % subset_update_every == 0:\n",
        "                try:\n",
        "                    fr_batch = next(fr_iter)\n",
        "                except StopIteration:\n",
        "                    fr_iter = iter(fr_loader)\n",
        "                    fr_batch = next(fr_iter)\n",
        "                fr_batch = {k: v.to(device) for k, v in fr_batch.items()}\n",
        "                model.zero_grad()\n",
        "                fr_out = model(**fr_batch)\n",
        "                fr_loss = fr_out.loss\n",
        "                fr_loss.backward()\n",
        "                update_subset_curvature()\n",
        "                model.zero_grad()\n",
        "\n",
        "            if (step + 1) % 100 == 0:\n",
        "                print(f\"[Epoch {epoch} Step {step+1}] loss_new = {loss.item():.4f}\")\n",
        "\n",
        "        print(f\"Epoch {epoch} evaluation:\")\n",
        "        eng_ppl = eval_ppl(model, english_test_ds, \"English new (ProtectedAdam-γ)\")\n",
        "        fr_ppl  = eval_ppl(model, french_test_ds,  \"French protected (ProtectedAdam-γ)\")\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "protected_model2 = run_protected_adam2(\n",
        "    num_epochs=3,\n",
        "    lr=5e-5,\n",
        "    alpha_geom=1.0,\n",
        "    beta_geom=10.0,   # strength of protected geometry\n",
        "    gamma_exp=0.5,    # between 0.5 (Adam) and 1.0 (diag NGD)\n",
        "    subset_update_every=5,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZnYsSOoViX2",
        "outputId": "3a83e68c-b724-4a8a-8b25-c1b0b3bb8e87"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Replay baseline: English training + French replay ===\n",
            "subset_update_every=5, replay_weight=1.0\n",
            "Before opt:\n",
            "English new (replay) perplexity: 83.357\n",
            "French protected (replay) perplexity: 44.141\n",
            "[Epoch 0 Step 100] loss_new=3.1352, loss_replay=4.6484, total=7.7836\n",
            "[Epoch 0 Step 200] loss_new=3.1155, loss_replay=4.2754, total=7.3909\n",
            "Epoch 0 evaluation:\n",
            "English new (replay) perplexity: 31.677\n",
            "French protected (replay) perplexity: 42.530\n",
            "[Epoch 1 Step 100] loss_new=2.7900, loss_replay=4.9190, total=7.7090\n",
            "[Epoch 1 Step 200] loss_new=2.5104, loss_replay=4.7519, total=7.2623\n",
            "Epoch 1 evaluation:\n",
            "English new (replay) perplexity: 28.883\n",
            "French protected (replay) perplexity: 37.490\n",
            "[Epoch 2 Step 100] loss_new=2.9443, loss_replay=5.0058, total=7.9501\n",
            "[Epoch 2 Step 200] loss_new=2.8317, loss_replay=3.4480, total=6.2797\n",
            "Epoch 2 evaluation:\n",
            "English new (replay) perplexity: 28.323\n",
            "French protected (replay) perplexity: 34.839\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "def run_replay(\n",
        "    num_epochs=2,\n",
        "    lr=5e-5,\n",
        "    subset_update_every=5,\n",
        "    replay_weight=1.0,   # λ: strength of French replay loss\n",
        "):\n",
        "    \"\"\"\n",
        "    Experience Replay baseline.\n",
        "\n",
        "    - Optimizes English CE loss every step.\n",
        "    - Every `subset_update_every` steps, also optimizes French CE.\n",
        "    - Total loss = CE_english + replay_weight * CE_french.\n",
        "    - Uses plain AdamW.\n",
        "    - No curvature, no shielding, no geometry.\n",
        "    \"\"\"\n",
        "\n",
        "    # Load model\n",
        "    base_model = GPT2LMHeadModel.from_pretrained(model_name)\n",
        "    base_model.resize_token_embeddings(len(tokenizer))\n",
        "    model = copy.deepcopy(base_model).to(device)\n",
        "    model.train()\n",
        "\n",
        "    optimizer = AdamW(model.parameters(), lr=lr)\n",
        "\n",
        "    # French iterator for replay\n",
        "    fr_iter = iter(fr_loader)\n",
        "\n",
        "    print(\"=== Replay baseline: English training + French replay ===\")\n",
        "    print(f\"subset_update_every={subset_update_every}, replay_weight={replay_weight}\")\n",
        "\n",
        "    print(\"Before opt:\")\n",
        "    eval_ppl(model, english_test_ds, \"English new (replay)\")\n",
        "    eval_ppl(model, french_test_ds,  \"French protected (replay)\")\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        for step, batch in enumerate(eng_loader):\n",
        "            batch = {k: v.to(device) for k, v in batch.items()}\n",
        "\n",
        "            # English forward/backward\n",
        "            model.zero_grad()\n",
        "            out = model(**batch)\n",
        "            loss_new = out.loss\n",
        "            total_loss = loss_new\n",
        "\n",
        "            # French replay every N steps\n",
        "            if (step + 1) % subset_update_every == 0:\n",
        "                try:\n",
        "                    fr_batch = next(fr_iter)\n",
        "                except StopIteration:\n",
        "                    fr_iter = iter(fr_loader)\n",
        "                    fr_batch = next(fr_iter)\n",
        "                fr_batch = {k: v.to(device) for k, v in fr_batch.items()}\n",
        "\n",
        "                fr_out = model(**fr_batch)\n",
        "                fr_loss = fr_out.loss\n",
        "\n",
        "                total_loss = loss_new + replay_weight * fr_loss\n",
        "\n",
        "            # Backprop + update\n",
        "            total_loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Logging\n",
        "            if (step + 1) % 100 == 0:\n",
        "                if (step + 1) % subset_update_every == 0:\n",
        "                    print(\n",
        "                        f\"[Epoch {epoch} Step {step+1}] \"\n",
        "                        f\"loss_new={loss_new.item():.4f}, \"\n",
        "                        f\"loss_replay={fr_loss.item():.4f}, \"\n",
        "                        f\"total={total_loss.item():.4f}\"\n",
        "                    )\n",
        "                else:\n",
        "                    print(f\"[Epoch {epoch} Step {step+1}] loss_new={loss_new.item():.4f}\")\n",
        "\n",
        "        # End epoch eval\n",
        "        print(f\"Epoch {epoch} evaluation:\")\n",
        "        eval_ppl(model, english_test_ds, \"English new (replay)\")\n",
        "        eval_ppl(model, french_test_ds,  \"French protected (replay)\")\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "replay_model = run_replay(\n",
        "    num_epochs=3,\n",
        "    lr=5e-5,\n",
        "    subset_update_every=5,\n",
        "    replay_weight=1.0,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "jeeW4bw4ZbWo"
      },
      "outputs": [],
      "source": [
        "def estimate_fisher_french(model, num_batches=200):\n",
        "    model.eval()\n",
        "    fisher = {\n",
        "        name: torch.zeros_like(p.data)\n",
        "        for name, p in model.named_parameters()\n",
        "        if p.requires_grad\n",
        "    }\n",
        "\n",
        "    loader = DataLoader(\n",
        "        french_train_ds,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        collate_fn=collate_fn\n",
        "    )\n",
        "    it = iter(loader)\n",
        "\n",
        "    for i in range(num_batches):\n",
        "        try:\n",
        "            batch = next(it)\n",
        "        except StopIteration:\n",
        "            it = iter(loader)\n",
        "            batch = next(it)\n",
        "\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "        model.zero_grad()\n",
        "        out = model(**batch)\n",
        "        loss = out.loss\n",
        "        loss.backward()\n",
        "\n",
        "        for name, p in model.named_parameters():\n",
        "            if not p.requires_grad or p.grad is None:\n",
        "                continue\n",
        "            fisher[name] += p.grad.data.pow(2)\n",
        "\n",
        "    for name in fisher:\n",
        "        fisher[name] /= num_batches\n",
        "\n",
        "    model.train()\n",
        "    return fisher\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "sIlC7y1Vd0Gj"
      },
      "outputs": [],
      "source": [
        "def estimate_model_fisher_french(model, num_batches=200, top_k=100):\n",
        "    \"\"\"\n",
        "    Compute *model Fisher* diagonal using KL(p_ref || p_model),\n",
        "    with optional top-K truncation of the reference distribution.\n",
        "\n",
        "    top_k < 0  → use full distribution (no truncation)\n",
        "    top_k > 0  → keep only top_k tokens in reference distribution\n",
        "    \"\"\"\n",
        "\n",
        "    # Freeze reference model θ0\n",
        "    ref_model = copy.deepcopy(model).eval().to(device)\n",
        "    for p in ref_model.parameters():\n",
        "        p.requires_grad = False\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    fisher = {\n",
        "        name: torch.zeros_like(p.data)\n",
        "        for name, p in model.named_parameters()\n",
        "        if p.requires_grad\n",
        "    }\n",
        "\n",
        "    loader = DataLoader(\n",
        "        french_train_ds,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        collate_fn=collate_fn\n",
        "    )\n",
        "    it = iter(loader)\n",
        "\n",
        "    for i in range(num_batches):\n",
        "        try:\n",
        "            batch = next(it)\n",
        "        except StopIteration:\n",
        "            it = iter(loader)\n",
        "            batch = next(it)\n",
        "\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "\n",
        "        # ---- 1. Reference distribution ----\n",
        "        with torch.no_grad():\n",
        "            ref_logits = ref_model(**batch).logits\n",
        "            ref_probs_full = ref_logits.softmax(dim=-1)  # shape [B, T, V]\n",
        "\n",
        "        # ---- 2. Possibly truncate to top-K ----\n",
        "        if top_k is not None and top_k > 0:\n",
        "            # Get top-K indices for each token\n",
        "            top_vals, top_idx = torch.topk(ref_probs_full, k=top_k, dim=-1)\n",
        "            # Renormalize probs over top-K\n",
        "            ref_probs = top_vals / top_vals.sum(dim=-1, keepdim=True)\n",
        "            # Make a tensor of zeros [B,T,V]\n",
        "            ref_probs_k = torch.zeros_like(ref_probs_full)\n",
        "            # Scatter top-K probabilities back into vocab dimension\n",
        "            ref_probs_k.scatter_(-1, top_idx, ref_probs)\n",
        "            ref_probs = ref_probs_k\n",
        "        else:\n",
        "            # use full distribution\n",
        "            ref_probs = ref_probs_full\n",
        "\n",
        "        # ---- 3. Model logits ----\n",
        "        logits = model(**batch).logits\n",
        "        log_probs = logits.log_softmax(dim=-1)\n",
        "\n",
        "        # ---- 4. KL(p_ref || p_model) ----\n",
        "        # KL per token: Σ_i q_i log(q_i/p_i)\n",
        "        kl = (ref_probs * (ref_probs.log() - log_probs)).sum(dim=-1)\n",
        "        loss = kl.mean()\n",
        "\n",
        "        # ---- 5. Backprop = model Fisher at θ0 ----\n",
        "        model.zero_grad()\n",
        "        loss.backward()\n",
        "\n",
        "        # ---- 6. Accumulate grad^2 ----\n",
        "        for name, p in model.named_parameters():\n",
        "            if not p.requires_grad or p.grad is None:\n",
        "                continue\n",
        "            fisher[name] += p.grad.data.pow(2)\n",
        "\n",
        "    # Average\n",
        "    for name in fisher:\n",
        "        fisher[name] /= num_batches\n",
        "\n",
        "    model.train()\n",
        "    return fisher\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nmCW04VjZjuS",
        "outputId": "ea63d295-eeb4-4679-e1ba-54b5551efcf9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== ProtectedAdam-γ with precomputed French Fisher ===\n",
            "Epoch 0 evaluation:\n",
            "English new (precomputed-Fisher) perplexity: 45.625\n",
            "French protected (precomputed-Fisher) perplexity: 61.115\n",
            "Epoch 1 evaluation:\n",
            "English new (precomputed-Fisher) perplexity: 44.183\n",
            "French protected (precomputed-Fisher) perplexity: 66.387\n",
            "Epoch 2 evaluation:\n",
            "English new (precomputed-Fisher) perplexity: 43.889\n",
            "French protected (precomputed-Fisher) perplexity: 69.896\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== ProtectedAdam-γ with precomputed French Fisher ===\n",
            "Epoch 0 evaluation:\n",
            "English new (precomputed-Fisher) perplexity: 45.563\n",
            "French protected (precomputed-Fisher) perplexity: 53.926\n",
            "Epoch 1 evaluation:\n",
            "English new (precomputed-Fisher) perplexity: 44.033\n",
            "French protected (precomputed-Fisher) perplexity: 59.137\n",
            "Epoch 2 evaluation:\n",
            "English new (precomputed-Fisher) perplexity: 43.090\n",
            "French protected (precomputed-Fisher) perplexity: 61.565\n"
          ]
        }
      ],
      "source": [
        "def run_protected_adam_precomputed(\n",
        "    num_epochs=2,\n",
        "    lr=5e-5,\n",
        "    alpha_geom=1.0,\n",
        "    beta_geom=10.0,\n",
        "    gamma_exp=0.5,\n",
        "    rho_all=0.99,\n",
        "    fisher_sub=None,   # dict[name -> tensor]\n",
        "):\n",
        "    base_model = GPT2LMHeadModel.from_pretrained(model_name)\n",
        "    base_model.resize_token_embeddings(len(tokenizer))\n",
        "    model = copy.deepcopy(base_model).to(device)\n",
        "    model.train()\n",
        "\n",
        "    # We'll work with named parameters for alignment\n",
        "    named_params = [\n",
        "        (name, p) for name, p in model.named_parameters()\n",
        "        if p.requires_grad\n",
        "    ]\n",
        "\n",
        "    state = {}\n",
        "    for name, p in named_params:\n",
        "        if fisher_sub is not None and name in fisher_sub:\n",
        "            v_sub_init = fisher_sub[name].clone().to(device)\n",
        "        else:\n",
        "            v_sub_init = torch.zeros_like(p.data)\n",
        "\n",
        "        state[name] = {\n",
        "            \"m\": torch.zeros_like(p.data),\n",
        "            \"v_all\": torch.zeros_like(p.data),\n",
        "            \"v_sub\": v_sub_init,\n",
        "        }\n",
        "\n",
        "    beta1 = 0.9\n",
        "    eps = 1e-6\n",
        "    global_step = 0\n",
        "\n",
        "    def protected_adam_step():\n",
        "        nonlocal global_step\n",
        "        global_step += 1\n",
        "        for name, p in named_params:\n",
        "            if p.grad is None:\n",
        "                continue\n",
        "            grad = p.grad.data\n",
        "            s = state[name]\n",
        "\n",
        "            # first moment\n",
        "            s[\"m\"].mul_(beta1).add_(grad, alpha=1 - beta1)\n",
        "\n",
        "            # second moment on \"all\" (new English) data\n",
        "            s[\"v_all\"].mul_(rho_all).addcmul_(grad, grad, value=1 - rho_all)\n",
        "\n",
        "            v_all = s[\"v_all\"]\n",
        "            v_sub = s[\"v_sub\"]  # fixed precomputed Fisher\n",
        "            v_protect = alpha_geom * v_all + beta_geom * v_sub\n",
        "\n",
        "            m_hat = s[\"m\"] / (1 - beta1**global_step)\n",
        "            denom = (v_protect + eps).pow(gamma_exp)\n",
        "            step = m_hat / denom\n",
        "            p.data.add_(step, alpha=-lr)\n",
        "\n",
        "    print(\"=== ProtectedAdam-γ with precomputed French Fisher ===\")\n",
        "    for epoch in range(num_epochs):\n",
        "        for step, batch in enumerate(eng_loader):\n",
        "            batch = {k: v.to(device) for k, v in batch.items()}\n",
        "            model.zero_grad()\n",
        "            out = model(**batch)\n",
        "            loss = out.loss\n",
        "            loss.backward()\n",
        "            protected_adam_step()\n",
        "\n",
        "        print(f\"Epoch {epoch} evaluation:\")\n",
        "        eval_ppl(model, english_test_ds, \"English new (precomputed-Fisher)\")\n",
        "        eval_ppl(model, french_test_ds,  \"French protected (precomputed-Fisher)\")\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "# 1. Make a base model for Fisher estimation\n",
        "base_model = GPT2LMHeadModel.from_pretrained(model_name).to(device)\n",
        "base_model.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "\n",
        "# 2. Estimate Fisher on French ONCE\n",
        "mfisher_french = estimate_model_fisher_french(base_model, num_batches=200)\n",
        "\n",
        "# 3. Run English finetuning using precomputed Fisher, no French batches\n",
        "protected_model_pre_mfisher = run_protected_adam_precomputed(\n",
        "    num_epochs=3,\n",
        "    lr=1e-5,\n",
        "    alpha_geom=1.0,\n",
        "    beta_geom=10.0,\n",
        "    gamma_exp=0.5,\n",
        "    rho_all=0.99,\n",
        "    fisher_sub=mfisher_french,   # <- pass the dict here\n",
        ")\n",
        "\n",
        "\n",
        "# 2. Estimate Fisher on French ONCE\n",
        "fisher_french = estimate_fisher_french(base_model, num_batches=200)\n",
        "\n",
        "# 3. Run English finetuning using precomputed Fisher, no French batches\n",
        "protected_model_pre = run_protected_adam_precomputed(\n",
        "    num_epochs=3,\n",
        "    lr=1e-5,\n",
        "    alpha_geom=1.0,\n",
        "    beta_geom=10.0,\n",
        "    gamma_exp=0.5,\n",
        "    rho_all=0.99,\n",
        "    fisher_sub=fisher_french,   # <- pass the dict here\n",
        ")\n",
        "\n",
        "\n",
        "#"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 555
        },
        "id": "Q7ouhy6W_9b7",
        "outputId": "36bb129d-ea7f-4e61-add9-e6baa4b09f51"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== ProtectedAdam-precomputed2 (additive): Adam base + Fisher protection ===\n",
            "alpha_geom=1.0, beta_geom=0.1, gamma_exp=0.5, rho_all=0.99, global_vsub_mean=4.199e-06\n",
            "[Epoch 0 Step 100] loss_new = 5.3787\n",
            "[Epoch 0 Step 200] loss_new = 4.5667\n",
            "Epoch 0 evaluation:\n",
            "English new (ProtAdam-pre2-add) perplexity: 67.227\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "French protected (ProtAdam-pre2-add) perplexity: 44.408\n",
            "[Epoch 1 Step 100] loss_new = 5.1986\n",
            "[Epoch 1 Step 200] loss_new = 4.3117\n",
            "Epoch 1 evaluation:\n",
            "English new (ProtAdam-pre2-add) perplexity: 57.814\n",
            "French protected (ProtAdam-pre2-add) perplexity: 44.985\n",
            "[Epoch 2 Step 100] loss_new = 4.2889\n",
            "[Epoch 2 Step 200] loss_new = 4.7338\n",
            "Epoch 2 evaluation:\n",
            "English new (ProtAdam-pre2-add) perplexity: 52.388\n",
            "French protected (ProtAdam-pre2-add) perplexity: 45.750\n"
          ]
        }
      ],
      "source": [
        "# does not work, ignore for now\n",
        "def run_protected_adam_precomputed2(\n",
        "    num_epochs=2,\n",
        "    lr=5e-5,\n",
        "    alpha_geom=1.0,      # scale for v_all (Adam geometry)\n",
        "    beta_geom=10.0,      # strength of protection from v_sub\n",
        "    gamma_exp=0.5,       # exponent applied only to normalized v_sub\n",
        "    rho_all=0.99,\n",
        "    fisher_sub=None,     # dict[name -> tensor], precomputed Fisher on French\n",
        "):\n",
        "    \"\"\"\n",
        "    Protected Adam with precomputed Fisher (additive version).\n",
        "\n",
        "    - v_all: EMA of grad^2 on English (new task), like Adam.\n",
        "    - v_sub: fixed Fisher from French (protected capability), precomputed.\n",
        "    - v_sub is normalized globally once to be dimensionless.\n",
        "\n",
        "    Update (per-parameter i):\n",
        "        v_all_i ← EMA of g_i^2\n",
        "        v_sub_i ≈ Fisher_i\n",
        "\n",
        "        v_sub_scaled_i = v_sub_i / global_mean(v_sub)\n",
        "\n",
        "        base_rms_i   = sqrt(alpha_geom * v_all_i)\n",
        "        protect_i    = beta_geom * (v_sub_scaled_i ** gamma_exp)\n",
        "\n",
        "        denom_i = base_rms_i + protect_i + eps\n",
        "\n",
        "        Δθ_i = -lr * m_hat_i / denom_i\n",
        "\n",
        "    Properties:\n",
        "      - If fisher_sub is None or beta_geom = 0 -> exactly Adam.\n",
        "      - If v_sub is small -> denom ≈ base_rms -> Adam-like.\n",
        "      - If v_sub is large -> extra additive penalty in denom -> stronger protection.\n",
        "    \"\"\"\n",
        "\n",
        "    # 1) Start from base GPT-2\n",
        "    base_model = GPT2LMHeadModel.from_pretrained(model_name)\n",
        "    base_model.resize_token_embeddings(len(tokenizer))\n",
        "    model = copy.deepcopy(base_model).to(device)\n",
        "    model.train()\n",
        "\n",
        "    # 2) Collect named parameters to align with fisher_sub[name]\n",
        "    named_params = [\n",
        "        (name, p) for name, p in model.named_parameters()\n",
        "        if p.requires_grad\n",
        "    ]\n",
        "\n",
        "    # 3) Initialize state (m, v_all, v_sub)\n",
        "    state = {}\n",
        "    for name, p in named_params:\n",
        "        v_sub_init = torch.zeros_like(p.data)\n",
        "        if fisher_sub is not None and name in fisher_sub:\n",
        "            v_sub_init = fisher_sub[name].clone().to(p.data.device)\n",
        "        state[name] = {\n",
        "            \"m\": torch.zeros_like(p.data),\n",
        "            \"v_all\": torch.zeros_like(p.data),\n",
        "            \"v_sub\": v_sub_init,\n",
        "        }\n",
        "\n",
        "    # 4) Compute a global mean of v_sub for normalization (dimensionless)\n",
        "    if fisher_sub is not None:\n",
        "        total_sum = 0.0\n",
        "        total_count = 0\n",
        "        for name, p in named_params:\n",
        "            v_sub = state[name][\"v_sub\"]\n",
        "            if v_sub.numel() > 0:\n",
        "                total_sum += v_sub.sum().item()\n",
        "                total_count += v_sub.numel()\n",
        "        if total_count > 0:\n",
        "            global_vsub_mean = total_sum / total_count\n",
        "        else:\n",
        "            global_vsub_mean = 1.0\n",
        "    else:\n",
        "        global_vsub_mean = 1.0\n",
        "\n",
        "    beta1 = 0.9\n",
        "    eps = 1e-8\n",
        "    global_step = 0\n",
        "\n",
        "    print(\"=== ProtectedAdam-precomputed2 (additive): Adam base + Fisher protection ===\")\n",
        "    print(\n",
        "        f\"alpha_geom={alpha_geom}, beta_geom={beta_geom}, \"\n",
        "        f\"gamma_exp={gamma_exp}, rho_all={rho_all}, \"\n",
        "        f\"global_vsub_mean={global_vsub_mean:.3e}\"\n",
        "    )\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        for step, batch in enumerate(eng_loader):\n",
        "            batch = {k: v.to(device) for k, v in batch.items()}\n",
        "\n",
        "            # ----- 1) Forward/backward on English (new task) -----\n",
        "            model.zero_grad()\n",
        "            out = model(**batch)\n",
        "            loss = out.loss\n",
        "            loss.backward()\n",
        "\n",
        "            global_step += 1\n",
        "\n",
        "            # ----- 2) Protected Adam step (additive Fisher term) -----\n",
        "            with torch.no_grad():\n",
        "                for name, p in named_params:\n",
        "                    if p.grad is None:\n",
        "                        continue\n",
        "\n",
        "                    g = p.grad.data\n",
        "                    s = state[name]\n",
        "\n",
        "                    # First moment (Adam)\n",
        "                    s[\"m\"].mul_(beta1).add_(g, alpha=1 - beta1)\n",
        "\n",
        "                    # Second moment on \"all\" (new English) data (Adam-style)\n",
        "                    s[\"v_all\"].mul_(rho_all).addcmul_(g, g, value=1 - rho_all)\n",
        "\n",
        "                    v_all = s[\"v_all\"]\n",
        "                    v_sub = s[\"v_sub\"]\n",
        "\n",
        "                    # Base Adam geometry: sqrt of v_all (scaled)\n",
        "                    base_rms = (alpha_geom * v_all).sqrt()\n",
        "\n",
        "                    # Normalized protective curvature from v_sub (dimensionless)\n",
        "                    if fisher_sub is not None and beta_geom != 0.0 and global_vsub_mean > 0.0:\n",
        "                        v_sub_scaled = v_sub / (global_vsub_mean + 1e-12)\n",
        "                        v_sub_scaled = torch.clamp(v_sub_scaled, min=0.0)  # safety\n",
        "                        protect_term = beta_geom * v_sub_scaled.pow(gamma_exp)\n",
        "                    else:\n",
        "                        protect_term = 0.0\n",
        "\n",
        "                    m_hat = s[\"m\"] / (1 - beta1**global_step)\n",
        "\n",
        "                    # ADDITIVE protection: denom = base_rms + protective term\n",
        "                    denom = base_rms + protect_term + eps\n",
        "                    step_dir = m_hat / denom\n",
        "\n",
        "                    p.data.add_(step_dir, alpha=-lr)\n",
        "\n",
        "            if (step + 1) % 100 == 0:\n",
        "                print(f\"[Epoch {epoch} Step {step+1}] loss_new = {loss.item():.4f}\")\n",
        "\n",
        "        # ----- 3) Epoch-end evaluation -----\n",
        "        print(f\"Epoch {epoch} evaluation:\")\n",
        "        eng_ppl = eval_ppl(model, english_test_ds, \"English new (ProtAdam-pre2-add)\")\n",
        "        fr_ppl  = eval_ppl(model, french_test_ds,  \"French protected (ProtAdam-pre2-add)\")\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "# 3. Run English finetuning using precomputed Fisher, no French batches\n",
        "protected_model_pre = run_protected_adam_precomputed2(\n",
        "    num_epochs=3,\n",
        "    lr=1e-5,\n",
        "    alpha_geom=1.0,\n",
        "    beta_geom=0.1,\n",
        "    gamma_exp=0.5,\n",
        "    rho_all=0.99,\n",
        "    fisher_sub=fisher_french,   # <- pass the dict here\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BAgBd4Mko-n2",
        "outputId": "b721b0db-0453-4118-ce6b-5463fb7ae492"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Adam with Fisher KL trust region on French ===\n",
            "lr=1e-05, delta_kl=1e-10\n",
            "[Epoch 0 Step 100] loss_new = 4.6404, KL_est = 7.657e-09, scale = 0.114\n",
            "[Epoch 0 Step 200] loss_new = 4.3920, KL_est = 6.171e-09, scale = 0.127\n",
            "Epoch 0 evaluation:\n",
            "English new (Adam+KL) perplexity: 51.647\n",
            "French protected (Adam+KL) perplexity: 47.432\n",
            "[Epoch 1 Step 100] loss_new = 4.2031, KL_est = 3.879e-09, scale = 0.161\n",
            "[Epoch 1 Step 200] loss_new = 4.4493, KL_est = 3.554e-09, scale = 0.168\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 evaluation:\n",
            "English new (Adam+KL) perplexity: 46.106\n",
            "French protected (Adam+KL) perplexity: 52.848\n",
            "[Epoch 2 Step 100] loss_new = 3.7124, KL_est = 3.011e-09, scale = 0.182\n",
            "[Epoch 2 Step 200] loss_new = 3.2919, KL_est = 3.718e-09, scale = 0.164\n",
            "Epoch 2 evaluation:\n",
            "English new (Adam+KL) perplexity: 44.779\n",
            "French protected (Adam+KL) perplexity: 56.988\n"
          ]
        }
      ],
      "source": [
        "def run_adam_with_fisher_trust_region(\n",
        "    num_epochs=2,\n",
        "    lr=1e-5,\n",
        "    beta1=0.9,\n",
        "    beta2=0.999,\n",
        "    eps=1e-8,\n",
        "    fisher_sub=None,    # dict[name -> tensor] from estimate_fisher_french_named(...)\n",
        "    delta_kl=1e-3,      # KL budget per step (approx)\n",
        "):\n",
        "    \"\"\"\n",
        "    Adam on English, with a TRPO-style KL trust region on French capability:\n",
        "      1) Compute standard Adam step Δθ.\n",
        "      2) Estimate French KL ≈ 0.5 * Σ_i F_sub[i] * (Δθ_i)^2\n",
        "      3) If KL > delta_kl: scale Δθ by sqrt(delta_kl / KL).\n",
        "    \"\"\"\n",
        "\n",
        "    # Start from the same base model as elsewhere\n",
        "    base_model = GPT2LMHeadModel.from_pretrained(model_name)\n",
        "    base_model.resize_token_embeddings(len(tokenizer))\n",
        "    model = copy.deepcopy(base_model).to(device)\n",
        "    model.train()\n",
        "\n",
        "    # Named params for alignment with fisher_sub\n",
        "    named_params = [\n",
        "        (name, p) for name, p in model.named_parameters()\n",
        "        if p.requires_grad\n",
        "    ]\n",
        "\n",
        "    # Adam state\n",
        "    state = {}\n",
        "    for name, p in named_params:\n",
        "        state[name] = {\n",
        "            \"m\": torch.zeros_like(p.data),\n",
        "            \"v\": torch.zeros_like(p.data),\n",
        "        }\n",
        "\n",
        "    global_step = 0\n",
        "\n",
        "    print(\"=== Adam with Fisher KL trust region on French ===\")\n",
        "    print(f\"lr={lr}, delta_kl={delta_kl}\")\n",
        "    for epoch in range(num_epochs):\n",
        "        for step, batch in enumerate(eng_loader):\n",
        "            batch = {k: v.to(device) for k, v in batch.items()}\n",
        "\n",
        "            # 1) Forward/backward on English batch\n",
        "            model.zero_grad()\n",
        "            out = model(**batch)\n",
        "            loss = out.loss\n",
        "            loss.backward()\n",
        "\n",
        "            global_step += 1\n",
        "\n",
        "            # 2) Compute Adam proposal step Δθ for each param (WITHOUT applying yet)\n",
        "            proposed_steps = {}  # name -> tensor (Δθ)\n",
        "            for name, p in named_params:\n",
        "                if p.grad is None:\n",
        "                    proposed_steps[name] = torch.zeros_like(p.data)\n",
        "                    continue\n",
        "\n",
        "                g = p.grad.data\n",
        "                s = state[name]\n",
        "\n",
        "                # Adam moments\n",
        "                s[\"m\"].mul_(beta1).add_(g, alpha=1 - beta1)\n",
        "                s[\"v\"].mul_(beta2).addcmul_(g, g, value=1 - beta2)\n",
        "\n",
        "                # Bias-corrected\n",
        "                m_hat = s[\"m\"] / (1 - beta1 ** global_step)\n",
        "                v_hat = s[\"v\"] / (1 - beta2 ** global_step)\n",
        "\n",
        "                # Classic Adam step (note: step is *direction*, no lr yet)\n",
        "                step_dir = m_hat / (v_hat.sqrt() + eps)\n",
        "\n",
        "                # Proposed parameter change Δθ = -lr * step_dir\n",
        "                delta_theta = -lr * step_dir\n",
        "                proposed_steps[name] = delta_theta\n",
        "\n",
        "            # 3) Estimate French KL for this joint step using precomputed Fisher\n",
        "            kl_est = 0.0\n",
        "            if fisher_sub is not None:\n",
        "                for name, p in named_params:\n",
        "                    if name not in fisher_sub:\n",
        "                        continue\n",
        "                    delta = proposed_steps[name]\n",
        "                    if delta is None:\n",
        "                        continue\n",
        "                    F = fisher_sub[name].to(delta.device)\n",
        "                    # 0.5 * sum_i F_i * (Δθ_i)^2\n",
        "                    kl_est += 0.5 * (F * (delta ** 2)).sum().item()\n",
        "\n",
        "            # 4) Compute scaling factor to enforce KL ≤ delta_kl\n",
        "            if fisher_sub is None or kl_est <= 0.0:\n",
        "                scale = 1.0\n",
        "            elif kl_est <= delta_kl:\n",
        "                scale = 1.0\n",
        "            else:\n",
        "                scale = (delta_kl / kl_est) ** 0.5\n",
        "\n",
        "            # 5) Apply scaled step\n",
        "            for name, p in named_params:\n",
        "                delta = proposed_steps[name]\n",
        "                if delta is None:\n",
        "                    continue\n",
        "                p.data.add_(delta * scale)\n",
        "\n",
        "            if (step + 1) % 100 == 0:\n",
        "                print(\n",
        "                    f\"[Epoch {epoch} Step {step+1}] \"\n",
        "                    f\"loss_new = {loss.item():.4f}, KL_est = {kl_est:.3e}, scale = {scale:.3f}\"\n",
        "                )\n",
        "\n",
        "        # 6) Evaluation at epoch end\n",
        "        print(f\"Epoch {epoch} evaluation:\")\n",
        "        eng_ppl = eval_ppl(model, english_test_ds, \"English new (Adam+KL)\")\n",
        "        fr_ppl  = eval_ppl(model, french_test_ds,  \"French protected (Adam+KL)\")\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Precompute model Fisher on French (once)\n",
        "base_model = GPT2LMHeadModel.from_pretrained(model_name).to(device)\n",
        "base_model.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "fisher_french = estimate_fisher_french(base_model, num_batches=200)\n",
        "\n",
        "# Now run English finetuning with TRPO-style KL trust region on French\n",
        "adam_trpo_model = run_adam_with_fisher_trust_region(\n",
        "    num_epochs=3,\n",
        "    lr=1e-5,\n",
        "    fisher_sub=fisher_french,\n",
        "    delta_kl=1e-10,   # tune this up/down\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZW0AGZBHOA7O",
        "outputId": "128551b1-f88f-4f75-e6ef-94955a281746"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Final comparison ===\n",
            "Baseline Adam:\n",
            "English new (baseline) perplexity: 42.242\n",
            "French protected (baseline) perplexity: 72.956\n",
            "\n",
            "EWC:\n",
            "English new (EWC) perplexity: 43.868\n",
            "French protected (EWC) perplexity: 74.271\n",
            "\n",
            "ProtectedAdam-γ:\n",
            "English new (ProtectedAdam-γ) perplexity: 43.522\n",
            "French protected (ProtectedAdam-γ) perplexity: 65.237\n",
            "\n",
            "ProtectedAdam2-γ:\n",
            "English new (ProtectedAdam-γ) perplexity: 48.107\n",
            "French protected (ProtectedAdam-γ) perplexity: 94.295\n",
            "\n",
            "Replay:\n",
            "English new (ProtectedAdam-γ) perplexity: 28.323\n",
            "French protected (ProtectedAdam-γ) perplexity: 34.839\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "34.83931552642409"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(\"=== Final comparison ===\")\n",
        "print(\"Baseline Adam:\")\n",
        "eval_ppl(baseline_model, english_test_ds, \"English new (baseline)\")\n",
        "eval_ppl(baseline_model, french_test_ds,  \"French protected (baseline)\")\n",
        "\n",
        "print(\"\\nEWC:\")\n",
        "eval_ppl(ewc_model, english_test_ds, \"English new (EWC)\")\n",
        "eval_ppl(ewc_model, french_test_ds,  \"French protected (EWC)\")\n",
        "\n",
        "print(\"\\nProtectedAdam-γ:\")\n",
        "eval_ppl(protected_model, english_test_ds, \"English new (ProtectedAdam-γ)\")\n",
        "eval_ppl(protected_model, french_test_ds,  \"French protected (ProtectedAdam-γ)\")\n",
        "\n",
        "\n",
        "print(\"\\nProtectedAdam2-γ:\")\n",
        "eval_ppl(protected_model2, english_test_ds, \"English new (ProtectedAdam-γ)\")\n",
        "eval_ppl(protected_model2, french_test_ds,  \"French protected (ProtectedAdam-γ)\")\n",
        "\n",
        "print(\"\\nReplay:\")\n",
        "eval_ppl(replay_model, english_test_ds, \"English new (ProtectedAdam-γ)\")\n",
        "eval_ppl(replay_model, french_test_ds,  \"French protected (ProtectedAdam-γ)\")\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "00a45ce331f049659ddc5a8d3a733689": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "019d2a1857fe46099f9fc01c6ba6b8d7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a9cd86371154105b73bcf2ede9feea1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4017aa81e3504205b797a47b4541d236",
              "IPY_MODEL_1afded3de67843e89d9ce05dacf97cf6",
              "IPY_MODEL_3d2e1581055140788c0638914354f8ed"
            ],
            "layout": "IPY_MODEL_b07617e6f8d34273a5929b6ed5998120"
          }
        },
        "11481ce4d7c54a20b328fe987088d02b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "149b331d4d87433398ee419064405baa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c48cfdbb01a6438087a163d31de89005",
            "placeholder": "​",
            "style": "IPY_MODEL_a8851e5f5d6f46e8860bc772fa5b81ea",
            "value": "model.safetensors: 100%"
          }
        },
        "17a88ca67a994b51b5f425842c0ab3ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f7143d3bd72f4e1f9e119e1b29205cfb",
            "placeholder": "​",
            "style": "IPY_MODEL_cf6bf77b10dc4e04920eb2c05b5a4347",
            "value": "generation_config.json: 100%"
          }
        },
        "19a30732e19745b8a333de9eb6332a41": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_46a0746bf84440f38874b729d617f1df",
              "IPY_MODEL_9de635c4e355447e8e2a4d9f760fdfde",
              "IPY_MODEL_8998157212b8431ba8509dd0df98981b"
            ],
            "layout": "IPY_MODEL_9921b84c7f784e7ba9f32a97602546a7"
          }
        },
        "1afded3de67843e89d9ce05dacf97cf6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a197dbff6da43a6b445dfe17b2c2522",
            "max": 26,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_412823a0f00e42059339c56fb4bd9c9f",
            "value": 26
          }
        },
        "1f6ddb9d63b442dcb6d2b772c5068212": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "21357a168091432fbf46ec848df81842": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b5f3adfc279949e58696997e532348ee",
            "placeholder": "​",
            "style": "IPY_MODEL_4eb8fcc217cf4b9e98b63c09077a17ec",
            "value": "tokenizer.json: 100%"
          }
        },
        "2846c79926f440708121d6b5efa2f901": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38706d9664be4357b79dd614fbac9b27": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3adc4be8a5e442cc8c4d230d8ec3ef85": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3c41a4d44ad349d2accb847f8ec65f41": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3d2e1581055140788c0638914354f8ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7bc5dd35c071495b82c20903d663b66c",
            "placeholder": "​",
            "style": "IPY_MODEL_91a9aec8a55f4f418af506009da10f35",
            "value": " 26.0/26.0 [00:00&lt;00:00, 3.32kB/s]"
          }
        },
        "3ee498aad5c54b4c956bb39619959b60": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e6c8823a320447f7bae20c76e4070c0b",
            "max": 1042301,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8c9e710110a6423b84ade1d41b8a0529",
            "value": 1042301
          }
        },
        "4017aa81e3504205b797a47b4541d236": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c27c084743f643cc972967bcb0eb5753",
            "placeholder": "​",
            "style": "IPY_MODEL_6e69c53fb73d44caaf004f4a1baf5330",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "412823a0f00e42059339c56fb4bd9c9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4644d3f2f33d4f089ee5d788d8a2a0ef": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46a0746bf84440f38874b729d617f1df": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f9182aedceb2421b9a77a245d20a9a1e",
            "placeholder": "​",
            "style": "IPY_MODEL_95b18249d1884fa7895fb09393d2598b",
            "value": "config.json: 100%"
          }
        },
        "46ab261f4cc549e181eeae76c646abaa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_21357a168091432fbf46ec848df81842",
              "IPY_MODEL_53dbd36dc7e4462f8d94a403a0d82875",
              "IPY_MODEL_c1bac9dec2244a1e9eef085386d047f1"
            ],
            "layout": "IPY_MODEL_ec9d2bfc9b82450199239de8eada416d"
          }
        },
        "4a197dbff6da43a6b445dfe17b2c2522": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a2226e944a4410aa53f1717e07169b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4e9ea7427ef0479c9b0216fdb9604c8a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4eb8fcc217cf4b9e98b63c09077a17ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4f1ed9d96a5a4693ac360e9f90e42b8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "503d3af66d1c4b47ac0f9fd4caf475ae": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53dbd36dc7e4462f8d94a403a0d82875": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4644d3f2f33d4f089ee5d788d8a2a0ef",
            "max": 1355256,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_38706d9664be4357b79dd614fbac9b27",
            "value": 1355256
          }
        },
        "5df1c3945e404094b3f18c099b502a84": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_00a45ce331f049659ddc5a8d3a733689",
            "placeholder": "​",
            "style": "IPY_MODEL_b7e41e3eac364027a5a1bf7342f7bd49",
            "value": " 1.04M/1.04M [00:00&lt;00:00, 1.57MB/s]"
          }
        },
        "6099f135e0814a47822b3749934696b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a2f3c8562c204b1d9222851eed5f106f",
            "placeholder": "​",
            "style": "IPY_MODEL_f521b4a4d7154de6ba16f3e6bdf59b51",
            "value": "vocab.json: 100%"
          }
        },
        "65ac5143b332424ca9424506b20cd40a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "675449c0ef484dc3b3baae5bbe8b5fd5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e69c53fb73d44caaf004f4a1baf5330": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7681bec193b248ad8beca1bd01baf4c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2846c79926f440708121d6b5efa2f901",
            "placeholder": "​",
            "style": "IPY_MODEL_3adc4be8a5e442cc8c4d230d8ec3ef85",
            "value": " 124/124 [00:00&lt;00:00, 16.4kB/s]"
          }
        },
        "7805724c2c5448d4b29119483f055636": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7bc5dd35c071495b82c20903d663b66c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7dddedc6cfcb46848461c6aa231650ec": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8998157212b8431ba8509dd0df98981b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_675449c0ef484dc3b3baae5bbe8b5fd5",
            "placeholder": "​",
            "style": "IPY_MODEL_65ac5143b332424ca9424506b20cd40a",
            "value": " 665/665 [00:00&lt;00:00, 85.9kB/s]"
          }
        },
        "8bdf857cc0fb474f9bf8c73fa0ea2257": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_17a88ca67a994b51b5f425842c0ab3ff",
              "IPY_MODEL_ecdf1063c4cc48cab41115fbda94cc85",
              "IPY_MODEL_7681bec193b248ad8beca1bd01baf4c6"
            ],
            "layout": "IPY_MODEL_1f6ddb9d63b442dcb6d2b772c5068212"
          }
        },
        "8c9e710110a6423b84ade1d41b8a0529": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8d5615ddaac748d7a1ba5a26726aa6fb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ebe0ad1bb4e456a97821b31d8dfb9f6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ee340f1e44442aca9ad56eaf28e3ec6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91a9aec8a55f4f418af506009da10f35": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "92bf0487d45e4c06869ae88ee0bb877c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "95b18249d1884fa7895fb09393d2598b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9921b84c7f784e7ba9f32a97602546a7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9de635c4e355447e8e2a4d9f760fdfde": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_11481ce4d7c54a20b328fe987088d02b",
            "max": 665,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e97ed5800cff4055900545ff376979be",
            "value": 665
          }
        },
        "a1fc267bd68947dfbafa9ed3e6fb56c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a2f3c8562c204b1d9222851eed5f106f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8851e5f5d6f46e8860bc772fa5b81ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b07617e6f8d34273a5929b6ed5998120": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0fa9161ed064445aece8d321b3d88a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ee340f1e44442aca9ad56eaf28e3ec6",
            "max": 548105171,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3c41a4d44ad349d2accb847f8ec65f41",
            "value": 548105171
          }
        },
        "b5f3adfc279949e58696997e532348ee": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7e41e3eac364027a5a1bf7342f7bd49": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bbe725cd4bf4424490b1b6444fd128a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_149b331d4d87433398ee419064405baa",
              "IPY_MODEL_b0fa9161ed064445aece8d321b3d88a7",
              "IPY_MODEL_cf32259002024b7da355cc4eb0a752e8"
            ],
            "layout": "IPY_MODEL_503d3af66d1c4b47ac0f9fd4caf475ae"
          }
        },
        "c199e25df4d54001919f0481edc0b358": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e7c2de72aff4428db80fd3ddd8d82557",
              "IPY_MODEL_cb45de6c1d7d4dc7809c42da301e9fba",
              "IPY_MODEL_d8e0603c141f4674a1f57399cee4ef45"
            ],
            "layout": "IPY_MODEL_8d5615ddaac748d7a1ba5a26726aa6fb"
          }
        },
        "c1bac9dec2244a1e9eef085386d047f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ebe0ad1bb4e456a97821b31d8dfb9f6",
            "placeholder": "​",
            "style": "IPY_MODEL_4a2226e944a4410aa53f1717e07169b5",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 6.35MB/s]"
          }
        },
        "c27c084743f643cc972967bcb0eb5753": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c48cfdbb01a6438087a163d31de89005": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb45de6c1d7d4dc7809c42da301e9fba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d928ee45c23f436a9aa89ca5ef53df92",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ff49ae10aa48498dbb0cc35ab638c298",
            "value": 456318
          }
        },
        "ce768476c2144ff58e413e5195528b39": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf32259002024b7da355cc4eb0a752e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce768476c2144ff58e413e5195528b39",
            "placeholder": "​",
            "style": "IPY_MODEL_4f1ed9d96a5a4693ac360e9f90e42b8a",
            "value": " 548M/548M [00:01&lt;00:00, 360MB/s]"
          }
        },
        "cf6bf77b10dc4e04920eb2c05b5a4347": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d2e42c54ade243779ec71eb5fd4a51bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6099f135e0814a47822b3749934696b3",
              "IPY_MODEL_3ee498aad5c54b4c956bb39619959b60",
              "IPY_MODEL_5df1c3945e404094b3f18c099b502a84"
            ],
            "layout": "IPY_MODEL_7dddedc6cfcb46848461c6aa231650ec"
          }
        },
        "d8e0603c141f4674a1f57399cee4ef45": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_019d2a1857fe46099f9fc01c6ba6b8d7",
            "placeholder": "​",
            "style": "IPY_MODEL_92bf0487d45e4c06869ae88ee0bb877c",
            "value": " 456k/456k [00:00&lt;00:00, 1.07MB/s]"
          }
        },
        "d928ee45c23f436a9aa89ca5ef53df92": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6c8823a320447f7bae20c76e4070c0b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7c2de72aff4428db80fd3ddd8d82557": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e9ea7427ef0479c9b0216fdb9604c8a",
            "placeholder": "​",
            "style": "IPY_MODEL_7805724c2c5448d4b29119483f055636",
            "value": "merges.txt: 100%"
          }
        },
        "e97ed5800cff4055900545ff376979be": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ec9d2bfc9b82450199239de8eada416d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ecdf1063c4cc48cab41115fbda94cc85": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed40a4f1820246b99ca964b03244c906",
            "max": 124,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a1fc267bd68947dfbafa9ed3e6fb56c9",
            "value": 124
          }
        },
        "ed40a4f1820246b99ca964b03244c906": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f521b4a4d7154de6ba16f3e6bdf59b51": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f7143d3bd72f4e1f9e119e1b29205cfb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9182aedceb2421b9a77a245d20a9a1e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff49ae10aa48498dbb0cc35ab638c298": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
