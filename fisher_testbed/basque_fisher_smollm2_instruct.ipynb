{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Experiments with Fisher"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup English and 'Protected' texts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import math\n",
        "import copy\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from tqdm.notebook import tqdm # this makes tqdm.write() work with notebooks!\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import AdamW\n",
        "\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, get_scheduler\n",
        "from datasets import load_dataset, load_from_disk\n",
        "\n",
        "from trl.trainer.sft_trainer import DataCollatorForLanguageModeling\n",
        "from copy import deepcopy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "def add_generation_chat_template(tokenizer):\n",
        "    if \"qwen\" in tokenizer.name_or_path.lower():\n",
        "        # we have to use DataCollatorForLanguageModeling with completion_only_loss=True\n",
        "        # however, for that tokenizer needs to have return_assistant_tokens_mask=True, and qwen decided against adding support for {% generation %} / {% endgeneration %} functionality\n",
        "        # so we download a community qwen3 chat template that has it\n",
        "        !wget -O all_assistant.jinja --no-check-certificate https://raw.githubusercontent.com/HarryMayne/qwen_3_chat_templates/refs/heads/main/all_assistant.jinja\n",
        "        !mv all_assistant.jinja chat_templates/qwen_all_assistant.jinja\n",
        "        with open('chat_templates/qwen_all_assistant.jinja', 'r') as f:\n",
        "            tokenizer.chat_template = f.read()\n",
        "    if \"smollm2\" in tokenizer.name_or_path.lower():\n",
        "        with open('chat_templates/smollm2_all_assistant.jinja', 'r') as f:\n",
        "            tokenizer.chat_template = f.read()\n",
        "    return tokenizer\n",
        "\n",
        "def load_or_preprocess_dataset(model_id, dataset_id, tokenizer, max_length=4096):\n",
        "    local_ds_id = f\"datasets/{model_id}/{dataset_id}\"\n",
        "    num_proc = 16\n",
        "    if True:\n",
        "        print(f\"Dataset not found locally, processing and caching...\")\n",
        "        raw_dataset = load_dataset(dataset_id)[\"train\"]\n",
        "        def preprocess(example):\n",
        "            tokenized = tokenizer.apply_chat_template(\n",
        "                example[\"messages\"],\n",
        "                tokenize=True,\n",
        "                return_assistant_tokens_mask=True,\n",
        "                return_dict=True,\n",
        "            )\n",
        "            return {\n",
        "                \"input_ids\": tokenized[\"input_ids\"],\n",
        "                \"assistant_masks\": tokenized[\"assistant_masks\"],\n",
        "            }\n",
        "        \n",
        "        tokenized_dataset = raw_dataset.map(preprocess, remove_columns=raw_dataset.column_names, num_proc=num_proc, desc=\"Tokenizing\")\n",
        "        def shorter_than(example):\n",
        "            return len(example[\"input_ids\"]) <= max_length\n",
        "        final_dataset = tokenized_dataset.filter(shorter_than, num_proc=num_proc, desc=f\"Filtering to max length {max_length}\")\n",
        "        print(f\"Tokenized: {len(tokenized_dataset)}, After filtering: {len(final_dataset)}\")\n",
        "        final_dataset.save_to_disk(local_ds_id)\n",
        "    return final_dataset\n",
        "\n",
        "def create_dataloader(tokenized_dataset, batch_size):\n",
        "    collator = DataCollatorForLanguageModeling(pad_token_id=tokenizer.pad_token_id,)\n",
        "    dataloader = DataLoader(\n",
        "        tokenized_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        collate_fn=collator,\n",
        "    )\n",
        "    return dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import set_seed\n",
        "random_seed = 42\n",
        "set_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: cuda\n",
            "{%- for message in messages %}\n",
            "    {%- if loop.first and messages[0]['role'] != 'system' %}\n",
            "        {{- '<|im_start|>system\\nYou are a helpful AI assistant named SmolLM, trained by Hugging Face<|im_end|>\\n' }}\n",
            "    {%- endif %}\n",
            "    {%- if message['role'] == 'assistant' %}\n",
            "        {{- '<|im_start|>' + message['role'] }}\n",
            "        {% generation %}\n",
            "        {{- '\\n' + message['content'] + '<|im_end|>\\n' }}\n",
            "        {% endgeneration %}\n",
            "    {%- else %}\n",
            "        {{- '<|im_start|>' + message['role'] + '\\n' + message['content'] + '<|im_end|>\\n' }}\n",
            "    {%- endif %}\n",
            "{%- endfor %}\n",
            "{%- if add_generation_prompt %}\n",
            "    {{- '<|im_start|>assistant\\n' }}\n",
            "{%- endif %}\n"
          ]
        }
      ],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Device:\", device)\n",
        "\n",
        "model_name = \"HuggingFaceTB/SmolLM2-135M-Instruct\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "tokenizer.pad_token = tokenizer.eos_token  # for batching\n",
        "tokenizer = add_generation_chat_template(tokenizer)\n",
        "print(tokenizer.chat_template)\n",
        "\n",
        "batch_size = 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset not found locally, processing and caching...\n",
            "Tokenized: 86158, After filtering: 3400\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4d2d20330f984f6588682a95c71e5e66",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Saving the dataset (0/1 shards):   0%|          | 0/3400 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "eng_id = \"Neelectric/OpenR1-Math-220k_extended_Llama3_4096toks\"\n",
        "eng_ds = load_or_preprocess_dataset(model_name, eng_id, tokenizer, 1024)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset not found locally, processing and caching...\n",
            "Tokenized: 86745, After filtering: 75491\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0e2dc075341c4e4485037257e32226c6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Saving the dataset (0/1 shards):   0%|          | 0/75491 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "ba_id = \"Neelectric/wildguardmix_Llama-3.1-8B-Instruct_4096toks\"\n",
        "ba_ds = load_or_preprocess_dataset(model_name, ba_id, tokenizer, 1024)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3400\n",
            "3400\n"
          ]
        }
      ],
      "source": [
        "full_length = len(eng_ds)\n",
        "print(full_length)\n",
        "ba_ds = ba_ds.select(range(full_length))\n",
        "print(len(ba_ds))\n",
        "eng_ds = eng_ds.shuffle(seed=random_seed)\n",
        "ba_ds = ba_ds.shuffle(seed=random_seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322,
          "referenced_widgets": [
            "0a9cd86371154105b73bcf2ede9feea1",
            "4017aa81e3504205b797a47b4541d236",
            "1afded3de67843e89d9ce05dacf97cf6",
            "3d2e1581055140788c0638914354f8ed",
            "b07617e6f8d34273a5929b6ed5998120",
            "c27c084743f643cc972967bcb0eb5753",
            "6e69c53fb73d44caaf004f4a1baf5330",
            "4a197dbff6da43a6b445dfe17b2c2522",
            "412823a0f00e42059339c56fb4bd9c9f",
            "7bc5dd35c071495b82c20903d663b66c",
            "91a9aec8a55f4f418af506009da10f35",
            "d2e42c54ade243779ec71eb5fd4a51bf",
            "6099f135e0814a47822b3749934696b3",
            "3ee498aad5c54b4c956bb39619959b60",
            "5df1c3945e404094b3f18c099b502a84",
            "7dddedc6cfcb46848461c6aa231650ec",
            "a2f3c8562c204b1d9222851eed5f106f",
            "f521b4a4d7154de6ba16f3e6bdf59b51",
            "e6c8823a320447f7bae20c76e4070c0b",
            "8c9e710110a6423b84ade1d41b8a0529",
            "00a45ce331f049659ddc5a8d3a733689",
            "b7e41e3eac364027a5a1bf7342f7bd49",
            "c199e25df4d54001919f0481edc0b358",
            "e7c2de72aff4428db80fd3ddd8d82557",
            "cb45de6c1d7d4dc7809c42da301e9fba",
            "d8e0603c141f4674a1f57399cee4ef45",
            "8d5615ddaac748d7a1ba5a26726aa6fb",
            "4e9ea7427ef0479c9b0216fdb9604c8a",
            "7805724c2c5448d4b29119483f055636",
            "d928ee45c23f436a9aa89ca5ef53df92",
            "ff49ae10aa48498dbb0cc35ab638c298",
            "019d2a1857fe46099f9fc01c6ba6b8d7",
            "92bf0487d45e4c06869ae88ee0bb877c",
            "46ab261f4cc549e181eeae76c646abaa",
            "21357a168091432fbf46ec848df81842",
            "53dbd36dc7e4462f8d94a403a0d82875",
            "c1bac9dec2244a1e9eef085386d047f1",
            "ec9d2bfc9b82450199239de8eada416d",
            "b5f3adfc279949e58696997e532348ee",
            "4eb8fcc217cf4b9e98b63c09077a17ec",
            "4644d3f2f33d4f089ee5d788d8a2a0ef",
            "38706d9664be4357b79dd614fbac9b27",
            "8ebe0ad1bb4e456a97821b31d8dfb9f6",
            "4a2226e944a4410aa53f1717e07169b5",
            "19a30732e19745b8a333de9eb6332a41",
            "46a0746bf84440f38874b729d617f1df",
            "9de635c4e355447e8e2a4d9f760fdfde",
            "8998157212b8431ba8509dd0df98981b",
            "9921b84c7f784e7ba9f32a97602546a7",
            "f9182aedceb2421b9a77a245d20a9a1e",
            "95b18249d1884fa7895fb09393d2598b",
            "11481ce4d7c54a20b328fe987088d02b",
            "e97ed5800cff4055900545ff376979be",
            "675449c0ef484dc3b3baae5bbe8b5fd5",
            "65ac5143b332424ca9424506b20cd40a"
          ]
        },
        "id": "-KxrbhNtq7bc",
        "outputId": "bd4e7ec8-ef80-4cb7-d16a-808a85c8fd6c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2720\n",
            "2720\n",
            "680\n",
            "2720\n",
            "680\n"
          ]
        }
      ],
      "source": [
        "# Train / test splits\n",
        "num_train = int(0.8 * full_length)\n",
        "print(num_train)\n",
        "basque_train_ds = ba_ds.select(range(num_train))\n",
        "basque_test_ds = ba_ds.select(range(num_train, full_length))\n",
        "print(len(basque_train_ds))\n",
        "print(len(basque_test_ds))\n",
        "\n",
        "english_train_ds = eng_ds.select(range(num_train))\n",
        "english_test_ds = eng_ds.select(range(num_train, full_length))\n",
        "print(len(english_train_ds))\n",
        "print(len(english_test_ds))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ynTogCxlD6qe",
        "outputId": "2fa89744-95db-4461-bd1f-e9bc372e1f99"
      },
      "outputs": [],
      "source": [
        "# block_size = 64\n",
        "# batch_size = 8\n",
        "\n",
        "# basque_train_ds  = LineByLineLMDataset(basque_train, tokenizer, block_size)\n",
        "# basque_test_ds   = LineByLineLMDataset(basque_test,  tokenizer, block_size)\n",
        "# english_train_ds = LineByLineLMDataset(english_train, tokenizer, block_size)\n",
        "# english_test_ds  = LineByLineLMDataset(english_test,  tokenizer, block_size)\n",
        "\n",
        "# eng_loader = DataLoader(english_train_ds, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
        "# ba_loader  = DataLoader(basque_train_ds,  batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
        "\n",
        "# len(english_train_ds), len(basque_train_ds)\n",
        "\n",
        "eng_loader = create_dataloader(english_train_ds, batch_size)\n",
        "ba_loader = create_dataloader(english_test_ds, batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "3COzmCNrD8_u"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def eval_ppl(model, dataset, name, batch_size_eval=8):\n",
        "    model.eval()\n",
        "    loader = create_dataloader(dataset, batch_size_eval)\n",
        "    total_loss = 0.0\n",
        "    total_tokens = 0\n",
        "    for batch in tqdm(loader):\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "        out = model(**batch)\n",
        "        loss = out.loss * batch[\"attention_mask\"].sum()\n",
        "        total_loss += loss.item()\n",
        "        total_tokens += batch[\"attention_mask\"].sum().item()\n",
        "    ppl = math.exp(total_loss / total_tokens)\n",
        "    print(f\"{name} perplexity: {ppl:.3f}\")\n",
        "    model.train()\n",
        "    return ppl\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Before any optim: ppl on train and protect before fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "base_model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "model = copy.deepcopy(base_model).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c0c2dc78d3e9400a864fc423016eef06",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/340 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Baseline eng before optim perplexity: 4.794\n"
          ]
        }
      ],
      "source": [
        "eng_ppl = eval_ppl(model, english_train_ds, \"Baseline eng before optim\", batch_size_eval=8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527,
          "referenced_widgets": [
            "bbe725cd4bf4424490b1b6444fd128a2",
            "149b331d4d87433398ee419064405baa",
            "b0fa9161ed064445aece8d321b3d88a7",
            "cf32259002024b7da355cc4eb0a752e8",
            "503d3af66d1c4b47ac0f9fd4caf475ae",
            "c48cfdbb01a6438087a163d31de89005",
            "a8851e5f5d6f46e8860bc772fa5b81ea",
            "8ee340f1e44442aca9ad56eaf28e3ec6",
            "3c41a4d44ad349d2accb847f8ec65f41",
            "ce768476c2144ff58e413e5195528b39",
            "4f1ed9d96a5a4693ac360e9f90e42b8a",
            "8bdf857cc0fb474f9bf8c73fa0ea2257",
            "17a88ca67a994b51b5f425842c0ab3ff",
            "ecdf1063c4cc48cab41115fbda94cc85",
            "7681bec193b248ad8beca1bd01baf4c6",
            "1f6ddb9d63b442dcb6d2b772c5068212",
            "f7143d3bd72f4e1f9e119e1b29205cfb",
            "cf6bf77b10dc4e04920eb2c05b5a4347",
            "ed40a4f1820246b99ca964b03244c906",
            "a1fc267bd68947dfbafa9ed3e6fb56c9",
            "2846c79926f440708121d6b5efa2f901",
            "3adc4be8a5e442cc8c4d230d8ec3ef85"
          ]
        },
        "id": "YCnIJL95D_xR",
        "outputId": "e54bb78b-1a96-43cb-d896-271084ac0983"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Before opt:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`loss_type=None` was set in the config but it is unrecognized. Using the default loss: `ForCausalLMLoss`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "English new perplexity: 83.357\n",
            "Basque protected perplexity: 1197.813\n",
            "=== Baseline Adam: train on English only ===\n",
            "[Epoch 0 Step 100] loss_new = 4.2586\n",
            "[Epoch 0 Step 200] loss_new = 3.5406\n",
            "Epoch 0 evaluation:\n",
            "English new perplexity: 43.736\n",
            "Basque protected perplexity: 1784.078\n",
            "[Epoch 1 Step 100] loss_new = 3.7917\n",
            "[Epoch 1 Step 200] loss_new = 2.3742\n",
            "Epoch 1 evaluation:\n",
            "English new perplexity: 43.166\n",
            "Basque protected perplexity: 2169.199\n",
            "[Epoch 2 Step 100] loss_new = 2.9043\n",
            "[Epoch 2 Step 200] loss_new = 2.8937\n",
            "Epoch 2 evaluation:\n",
            "English new perplexity: 43.097\n",
            "Basque protected perplexity: 2645.470\n",
            "[Epoch 3 Step 100] loss_new = 2.8604\n",
            "[Epoch 3 Step 200] loss_new = 2.9524\n",
            "Epoch 3 evaluation:\n",
            "English new perplexity: 41.908\n",
            "Basque protected perplexity: 2986.717\n"
          ]
        }
      ],
      "source": [
        "from torch.optim import AdamW\n",
        "\n",
        "def run_baseline_adam(num_epochs=2, lr=1e-5):\n",
        "    base_model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "    base_model.resize_token_embeddings(len(tokenizer))\n",
        "    model = copy.deepcopy(base_model).to(device)\n",
        "    optimizer = AdamW(model.parameters(), lr=lr)\n",
        "\n",
        "    print(f\"Before opt:\")\n",
        "    eng_ppl = eval_ppl(model, english_test_ds, \"English new\")\n",
        "    fr_ppl  = eval_ppl(model, basque_test_ds,  \"Basque protected\")\n",
        "\n",
        "\n",
        "    print(\"=== Baseline Adam: train on English only ===\")\n",
        "    for epoch in range(num_epochs):\n",
        "        for step, batch in enumerate(eng_loader):\n",
        "            batch = {k: v.to(device) for k, v in batch.items()}\n",
        "            model.zero_grad()\n",
        "            out = model(**batch)\n",
        "            loss = out.loss\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            if (step + 1) % 100 == 0:\n",
        "                print(f\"[Epoch {epoch} Step {step+1}] loss_new = {loss.item():.4f}\")\n",
        "\n",
        "        print(f\"Epoch {epoch} evaluation:\")\n",
        "        eng_ppl = eval_ppl(model, english_test_ds, \"English new\")\n",
        "        fr_ppl  = eval_ppl(model, basque_test_ds,  \"Basque protected\")\n",
        "    return model\n",
        "\n",
        "baseline_model = run_baseline_adam(num_epochs=4, lr=1e-5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lz-u9NgkECO1",
        "outputId": "ed415c53-b8ac-47e4-822d-23c48409b63a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Estimating Fisher on Basque (protected) ...\n",
            "=== EWC: train on English with Basque EWC penalty ===\n",
            "[Epoch 0 Step 100] loss_new=2.9424, ewc_loss=0.0001\n",
            "[Epoch 0 Step 200] loss_new=3.7322, ewc_loss=0.0002\n",
            "Epoch 0 evaluation:\n",
            "English new (EWC) perplexity: 42.162\n",
            "Basque protected (EWC) perplexity: 1230.778\n",
            "[Epoch 1 Step 100] loss_new=2.4321, ewc_loss=0.0002\n",
            "[Epoch 1 Step 200] loss_new=2.4304, ewc_loss=0.0002\n",
            "Epoch 1 evaluation:\n",
            "English new (EWC) perplexity: 43.163\n",
            "Basque protected (EWC) perplexity: 1863.377\n",
            "[Epoch 2 Step 100] loss_new=2.3077, ewc_loss=0.0002\n",
            "[Epoch 2 Step 200] loss_new=2.1978, ewc_loss=0.0002\n",
            "Epoch 2 evaluation:\n",
            "English new (EWC) perplexity: 44.610\n",
            "Basque protected (EWC) perplexity: 2244.481\n"
          ]
        }
      ],
      "source": [
        "def estimate_fisher_on_basque(model, num_batches=200):\n",
        "    model.eval()\n",
        "    params = [p for p in model.parameters() if p.requires_grad]\n",
        "    fisher = {p: torch.zeros_like(p.data) for p in params}\n",
        "\n",
        "    loader = DataLoader(basque_train_ds, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
        "    it = iter(loader)\n",
        "    for i in range(num_batches):\n",
        "        try:\n",
        "            batch = next(it)\n",
        "        except StopIteration:\n",
        "            it = iter(loader)\n",
        "            batch = next(it)\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "        model.zero_grad()\n",
        "        out = model(**batch)\n",
        "        loss = out.loss\n",
        "        loss.backward()\n",
        "        for p in params:\n",
        "            if p.grad is None:\n",
        "                continue\n",
        "            fisher[p] += p.grad.data.pow(2)\n",
        "    for p in params:\n",
        "        fisher[p] /= num_batches\n",
        "    model.train()\n",
        "    return fisher\n",
        "\n",
        "def run_ewc(num_epochs=2, lr=5e-5, ewc_lambda=50.0):\n",
        "    base_model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "    base_model.resize_token_embeddings(len(tokenizer))\n",
        "    model = copy.deepcopy(base_model).to(device)\n",
        "\n",
        "    print(\"Estimating Fisher on Basque (protected) ...\")\n",
        "    fisher = estimate_fisher_on_basque(model, num_batches=100)\n",
        "    theta0 = copy.deepcopy(model).to(device)\n",
        "\n",
        "    optimizer = AdamW(model.parameters(), lr=lr)\n",
        "\n",
        "    params = [p for p in model.parameters() if p.requires_grad]\n",
        "\n",
        "    print(\"=== EWC: train on English with Basque EWC penalty ===\")\n",
        "    for epoch in range(num_epochs):\n",
        "        for step, batch in enumerate(eng_loader):\n",
        "            batch = {k: v.to(device) for k, v in batch.items()}\n",
        "            model.zero_grad()\n",
        "            out = model(**batch)\n",
        "            loss_new = out.loss\n",
        "\n",
        "            ewc_loss = 0.0\n",
        "            for p, p0 in zip(params, theta0.parameters()):\n",
        "                ewc_loss = ewc_loss + (fisher[p] * (p - p0).pow(2)).sum()\n",
        "            total_loss = loss_new + 0.5 * ewc_lambda * ewc_loss\n",
        "\n",
        "            total_loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            if (step + 1) % 100 == 0:\n",
        "                print(f\"[Epoch {epoch} Step {step+1}] loss_new={loss_new.item():.4f}, ewc_loss={ewc_loss.item():.4f}\")\n",
        "\n",
        "        print(f\"Epoch {epoch} evaluation:\")\n",
        "        eng_ppl = eval_ppl(model, english_test_ds, \"English new (EWC)\")\n",
        "        ba_ppl  = eval_ppl(model, basque_test_ds,  \"Basque protected (EWC)\")\n",
        "    return model\n",
        "\n",
        "ewc_model = run_ewc(num_epochs=3, lr=5e-5, ewc_lambda=50.0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5vS3js6UEEs8",
        "outputId": "50c1adf8-2795-458a-bc1a-6ff40a432ec3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== ProtectedAdam-γ: geometry shaped by Basque subset ===\n",
            "alpha_geom=1.0, beta_geom=10.0, gamma_exp=0.5\n",
            "[Epoch 0 Step 100] loss_new = 3.3215\n",
            "[Epoch 0 Step 200] loss_new = 3.4844\n",
            "Epoch 0 evaluation:\n",
            "English new (ProtectedAdam-γ) perplexity: 45.503\n",
            "Basque protected (ProtectedAdam-γ) perplexity: 1335.100\n",
            "[Epoch 1 Step 100] loss_new = 3.1518\n",
            "[Epoch 1 Step 200] loss_new = 3.3106\n",
            "Epoch 1 evaluation:\n",
            "English new (ProtectedAdam-γ) perplexity: 44.303\n",
            "Basque protected (ProtectedAdam-γ) perplexity: 1425.156\n",
            "[Epoch 2 Step 100] loss_new = 2.6852\n",
            "[Epoch 2 Step 200] loss_new = 3.4899\n",
            "Epoch 2 evaluation:\n",
            "English new (ProtectedAdam-γ) perplexity: 43.644\n",
            "Basque protected (ProtectedAdam-γ) perplexity: 1467.923\n"
          ]
        }
      ],
      "source": [
        "def run_protected_adam(\n",
        "    num_epochs=2,\n",
        "    lr=5e-5,\n",
        "    alpha_geom=1.0,\n",
        "    beta_geom=10.0,\n",
        "    gamma_exp=0.5,\n",
        "    subset_update_every=5,\n",
        "    rho_all=0.99,\n",
        "    rho_sub=0.99,\n",
        "):\n",
        "    base_model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "    base_model.resize_token_embeddings(len(tokenizer))\n",
        "    model = copy.deepcopy(base_model).to(device)\n",
        "    model.train()\n",
        "\n",
        "    params = [p for p in model.parameters() if p.requires_grad]\n",
        "\n",
        "    state = {}\n",
        "    for p in params:\n",
        "        state[p] = {\n",
        "            \"m\": torch.zeros_like(p.data),\n",
        "            \"v_all\": torch.zeros_like(p.data),\n",
        "            \"v_sub\": torch.zeros_like(p.data),\n",
        "        }\n",
        "\n",
        "    beta1 = 0.9\n",
        "    eps = 1e-6\n",
        "    global_step = 0\n",
        "\n",
        "    def protected_adam_step():\n",
        "        nonlocal global_step\n",
        "        global_step += 1\n",
        "        for p in params:\n",
        "            if p.grad is None:\n",
        "                continue\n",
        "            grad = p.grad.data\n",
        "            s = state[p]\n",
        "\n",
        "            # first moment\n",
        "            s[\"m\"].mul_(beta1).add_(grad, alpha=1 - beta1)\n",
        "\n",
        "            # second moment on \"all\" (new English) data\n",
        "            s[\"v_all\"].mul_(rho_all).addcmul_(grad, grad, value=1 - rho_all)\n",
        "\n",
        "            v_all = s[\"v_all\"]\n",
        "            v_sub = s[\"v_sub\"]\n",
        "            v_protect = alpha_geom * v_all + beta_geom * v_sub\n",
        "\n",
        "            m_hat = s[\"m\"] / (1 - beta1**global_step)\n",
        "            denom = (v_protect + eps).pow(gamma_exp)\n",
        "            step = m_hat / denom\n",
        "            p.data.add_(step, alpha=-lr)\n",
        "\n",
        "    def update_subset_curvature():\n",
        "        for p in params:\n",
        "            if p.grad is None:\n",
        "                continue\n",
        "            grad = p.grad.data\n",
        "            s = state[p]\n",
        "            s[\"v_sub\"].mul_(rho_sub).addcmul_(grad, grad, value=1 - rho_sub)\n",
        "\n",
        "    fr_iter = iter(ba_loader)\n",
        "\n",
        "    print(\"=== ProtectedAdam-γ: geometry shaped by Basque subset ===\")\n",
        "    print(f\"alpha_geom={alpha_geom}, beta_geom={beta_geom}, gamma_exp={gamma_exp}\")\n",
        "    for epoch in range(num_epochs):\n",
        "        for step, batch in enumerate(eng_loader):\n",
        "            # 1) English batch: gradient for new task\n",
        "            batch = {k: v.to(device) for k, v in batch.items()}\n",
        "            model.zero_grad()\n",
        "            out = model(**batch)\n",
        "            loss = out.loss\n",
        "            loss.backward()\n",
        "\n",
        "            # 2) Take ProtectedAdam step (updates v_all + params)\n",
        "            protected_adam_step()\n",
        "\n",
        "            # 3) Occasionally update subset curvature using Basque\n",
        "            if (step + 1) % subset_update_every == 0:\n",
        "                try:\n",
        "                    fr_batch = next(fr_iter)\n",
        "                except StopIteration:\n",
        "                    fr_iter = iter(ba_loader)\n",
        "                    fr_batch = next(fr_iter)\n",
        "                fr_batch = {k: v.to(device) for k, v in fr_batch.items()}\n",
        "                model.zero_grad()\n",
        "                fr_out = model(**fr_batch)\n",
        "                fr_loss = fr_out.loss\n",
        "                fr_loss.backward()\n",
        "                update_subset_curvature()\n",
        "                model.zero_grad()\n",
        "\n",
        "            if (step + 1) % 100 == 0:\n",
        "                print(f\"[Epoch {epoch} Step {step+1}] loss_new = {loss.item():.4f}\")\n",
        "\n",
        "        print(f\"Epoch {epoch} evaluation:\")\n",
        "        eng_ppl = eval_ppl(model, english_test_ds, \"English new (ProtectedAdam-γ)\")\n",
        "        fr_ppl  = eval_ppl(model, basque_test_ds,  \"Basque protected (ProtectedAdam-γ)\")\n",
        "\n",
        "    return model\n",
        "\n",
        "protected_model = run_protected_adam(\n",
        "    num_epochs=3,\n",
        "    lr=1e-5,\n",
        "    alpha_geom=1.0,\n",
        "    beta_geom=10.0,   # strength of protected geometry\n",
        "    gamma_exp=0.5,    # between 0.5 (Adam) and 1.0 (diag NGD)\n",
        "    subset_update_every=5,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yHTG9YTgOOAf",
        "outputId": "f4d4a82a-4533-46c7-c6a2-cbc5f86580ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Before opt:\n",
            "English new (ProtectedAdam-γ) perplexity: 83.357\n",
            "Basque protected (ProtectedAdam-γ) perplexity: 1197.813\n",
            "=== ProtectedAdam-γ: geometry shaped by Basque subset ===\n",
            "alpha_geom=1.0, beta_geom=10.0, gamma_exp=0.5\n",
            "[Epoch 0 Step 100] loss_new = 2.9968\n",
            "[Epoch 0 Step 200] loss_new = 3.2017\n",
            "Epoch 0 evaluation:\n",
            "English new (ProtectedAdam-γ) perplexity: 44.726\n",
            "Basque protected (ProtectedAdam-γ) perplexity: 1628.112\n",
            "[Epoch 1 Step 100] loss_new = 3.0774\n",
            "[Epoch 1 Step 200] loss_new = 2.2951\n",
            "Epoch 1 evaluation:\n",
            "English new (ProtectedAdam-γ) perplexity: 44.513\n",
            "Basque protected (ProtectedAdam-γ) perplexity: 1757.193\n",
            "[Epoch 2 Step 100] loss_new = 3.0296\n",
            "[Epoch 2 Step 200] loss_new = 2.4865\n",
            "Epoch 2 evaluation:\n",
            "English new (ProtectedAdam-γ) perplexity: 45.276\n",
            "Basque protected (ProtectedAdam-γ) perplexity: 1845.656\n"
          ]
        }
      ],
      "source": [
        "def run_protected_adam2(\n",
        "    num_epochs=3,\n",
        "    lr=5e-5,\n",
        "    alpha_geom=1.0,\n",
        "    beta_geom=10.0,\n",
        "    gamma_exp=0.5,\n",
        "    subset_update_every=5,\n",
        "    rho_all=0.99,\n",
        "    rho_sub=0.99,\n",
        "):\n",
        "    base_model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "    base_model.resize_token_embeddings(len(tokenizer))\n",
        "    model = copy.deepcopy(base_model).to(device)\n",
        "    model.train()\n",
        "\n",
        "    params = [p for p in model.parameters() if p.requires_grad]\n",
        "\n",
        "    state = {}\n",
        "    for p in params:\n",
        "        state[p] = {\n",
        "            \"m\": torch.zeros_like(p.data),\n",
        "            \"v_all\": torch.zeros_like(p.data),\n",
        "            \"v_sub\": torch.zeros_like(p.data),\n",
        "        }\n",
        "\n",
        "    beta1 = 0.9\n",
        "    eps = 1e-6\n",
        "    global_step = 0\n",
        "\n",
        "    def protected_adam_step():\n",
        "        nonlocal global_step\n",
        "        global_step += 1\n",
        "\n",
        "        # First pass: update moments, compute v_protect, and accumulate\n",
        "        # the mean denominators for γ=0.5 (baseline) and γ=gamma_exp\n",
        "        temp = {}\n",
        "        sum_baseline = 0.0\n",
        "        sum_gamma = 0.0\n",
        "        count_tensors = 0\n",
        "\n",
        "        for p in params:\n",
        "            if p.grad is None:\n",
        "                continue\n",
        "            grad = p.grad.data\n",
        "            s = state[p]\n",
        "\n",
        "            # First moment\n",
        "            s[\"m\"].mul_(beta1).add_(grad, alpha=1 - beta1)\n",
        "\n",
        "            # Second moment on \"all\" (new English) data\n",
        "            s[\"v_all\"].mul_(rho_all).addcmul_(grad, grad, value=1 - rho_all)\n",
        "\n",
        "            v_all = s[\"v_all\"]\n",
        "            v_sub = s[\"v_sub\"]\n",
        "            v_protect = alpha_geom * v_all + beta_geom * v_sub\n",
        "\n",
        "            # Bias-corrected first moment (optional but keeps Adam-like behaviour)\n",
        "            m_hat = s[\"m\"] / (1 - beta1**global_step)\n",
        "\n",
        "            denom_baseline = (v_protect + eps).pow(0.5)\n",
        "            denom_gamma = (v_protect + eps).pow(gamma_exp)\n",
        "\n",
        "            sum_baseline += denom_baseline.mean()\n",
        "            sum_gamma += denom_gamma.mean()\n",
        "            count_tensors += 1\n",
        "\n",
        "            temp[p] = {\n",
        "                \"m_hat\": m_hat,\n",
        "                \"v_protect\": v_protect,\n",
        "            }\n",
        "\n",
        "        if count_tensors == 0:\n",
        "            return\n",
        "\n",
        "        # Renormalization factor so that average step size matches γ=0.5 case\n",
        "        scale = (sum_baseline / sum_gamma).detach()\n",
        "\n",
        "        # Second pass: apply update with renormalized step size\n",
        "        for p in params:\n",
        "            if p.grad is None or p not in temp:\n",
        "                continue\n",
        "            buf = temp[p]\n",
        "            m_hat = buf[\"m_hat\"]\n",
        "            v_protect = buf[\"v_protect\"]\n",
        "\n",
        "            denom_gamma = (v_protect + eps).pow(gamma_exp)\n",
        "            step = (m_hat / denom_gamma) * scale\n",
        "            p.data.add_(step, alpha=-lr)\n",
        "\n",
        "    def update_subset_curvature():\n",
        "        for p in params:\n",
        "            if p.grad is None:\n",
        "                continue\n",
        "            grad = p.grad.data\n",
        "            s = state[p]\n",
        "            s[\"v_sub\"].mul_(rho_sub).addcmul_(grad, grad, value=1 - rho_sub)\n",
        "\n",
        "    fr_iter = iter(ba_loader)\n",
        "\n",
        "    print(f\"Before opt:\")\n",
        "    eng_ppl = eval_ppl(model, english_test_ds, \"English new (ProtectedAdam-γ)\")\n",
        "    fr_ppl  = eval_ppl(model, basque_test_ds,  \"Basque protected (ProtectedAdam-γ)\")\n",
        "\n",
        "\n",
        "    print(\"=== ProtectedAdam-γ: geometry shaped by Basque subset ===\")\n",
        "    print(f\"alpha_geom={alpha_geom}, beta_geom={beta_geom}, gamma_exp={gamma_exp}\")\n",
        "    for epoch in range(num_epochs):\n",
        "        for step, batch in enumerate(eng_loader):\n",
        "            # 1) English batch: gradient for new task\n",
        "            batch = {k: v.to(device) for k, v in batch.items()}\n",
        "            model.zero_grad()\n",
        "            out = model(**batch)\n",
        "            loss = out.loss\n",
        "            loss.backward()\n",
        "\n",
        "            # 2) Take ProtectedAdam step (updates v_all + params)\n",
        "            protected_adam_step()\n",
        "\n",
        "            # 3) Occasionally update subset curvature using Basque\n",
        "            if (step + 1) % subset_update_every == 0:\n",
        "                try:\n",
        "                    fr_batch = next(fr_iter)\n",
        "                except StopIteration:\n",
        "                    fr_iter = iter(ba_loader)\n",
        "                    fr_batch = next(fr_iter)\n",
        "                fr_batch = {k: v.to(device) for k, v in fr_batch.items()}\n",
        "                model.zero_grad()\n",
        "                fr_out = model(**fr_batch)\n",
        "                fr_loss = fr_out.loss\n",
        "                fr_loss.backward()\n",
        "                update_subset_curvature()\n",
        "                model.zero_grad()\n",
        "\n",
        "            if (step + 1) % 100 == 0:\n",
        "                print(f\"[Epoch {epoch} Step {step+1}] loss_new = {loss.item():.4f}\")\n",
        "\n",
        "        print(f\"Epoch {epoch} evaluation:\")\n",
        "        eng_ppl = eval_ppl(model, english_test_ds, \"English new (ProtectedAdam-γ)\")\n",
        "        fr_ppl  = eval_ppl(model, basque_test_ds,  \"Basque protected (ProtectedAdam-γ)\")\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "protected_model2 = run_protected_adam2(\n",
        "    num_epochs=3,\n",
        "    lr=5e-5,\n",
        "    alpha_geom=1.0,\n",
        "    beta_geom=10.0,   # strength of protected geometry\n",
        "    gamma_exp=0.5,    # between 0.5 (Adam) and 1.0 (diag NGD)\n",
        "    subset_update_every=5,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZnYsSOoViX2",
        "outputId": "3a83e68c-b724-4a8a-8b25-c1b0b3bb8e87"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Replay baseline: English training + Basque replay ===\n",
            "subset_update_every=5, replay_weight=1.0\n",
            "Before opt:\n",
            "English new (replay) perplexity: 83.357\n",
            "Basque protected (replay) perplexity: 1197.813\n",
            "[Epoch 0 Step 100] loss_new=3.7665, loss_replay=5.5810, total=9.3476\n",
            "[Epoch 0 Step 200] loss_new=3.4632, loss_replay=5.2603, total=8.7235\n",
            "Epoch 0 evaluation:\n",
            "English new (replay) perplexity: 45.219\n",
            "Basque protected (replay) perplexity: 183.202\n",
            "[Epoch 1 Step 100] loss_new=2.7046, loss_replay=5.0360, total=7.7406\n",
            "[Epoch 1 Step 200] loss_new=2.4994, loss_replay=4.9481, total=7.4475\n",
            "Epoch 1 evaluation:\n",
            "English new (replay) perplexity: 45.772\n",
            "Basque protected (replay) perplexity: 126.821\n",
            "[Epoch 2 Step 100] loss_new=2.4492, loss_replay=4.6953, total=7.1445\n",
            "[Epoch 2 Step 200] loss_new=2.6651, loss_replay=4.3451, total=7.0102\n",
            "Epoch 2 evaluation:\n",
            "English new (replay) perplexity: 45.777\n",
            "Basque protected (replay) perplexity: 104.797\n"
          ]
        }
      ],
      "source": [
        "def run_replay(\n",
        "    num_epochs=2,\n",
        "    lr=5e-5,\n",
        "    subset_update_every=5,\n",
        "    replay_weight=1.0,   # λ: strength of Basque replay loss\n",
        "):\n",
        "    \"\"\"\n",
        "    Experience Replay baseline.\n",
        "\n",
        "    - Optimizes English CE loss every step.\n",
        "    - Every `subset_update_every` steps, also optimizes Basque CE.\n",
        "    - Total loss = CE_english + replay_weight * CE_Basque.\n",
        "    - Uses plain AdamW.\n",
        "    - No curvature, no shielding, no geometry.\n",
        "    \"\"\"\n",
        "\n",
        "    # Load model\n",
        "    base_model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "    base_model.resize_token_embeddings(len(tokenizer))\n",
        "    model = copy.deepcopy(base_model).to(device)\n",
        "    model.train()\n",
        "\n",
        "    optimizer = AdamW(model.parameters(), lr=lr)\n",
        "\n",
        "    # Basque iterator for replay\n",
        "    fr_iter = iter(ba_loader)\n",
        "\n",
        "    print(\"=== Replay baseline: English training + Basque replay ===\")\n",
        "    print(f\"subset_update_every={subset_update_every}, replay_weight={replay_weight}\")\n",
        "\n",
        "    print(\"Before opt:\")\n",
        "    eval_ppl(model, english_test_ds, \"English new (replay)\")\n",
        "    eval_ppl(model, basque_test_ds,  \"Basque protected (replay)\")\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        for step, batch in enumerate(eng_loader):\n",
        "            batch = {k: v.to(device) for k, v in batch.items()}\n",
        "\n",
        "            # English forward/backward\n",
        "            model.zero_grad()\n",
        "            out = model(**batch)\n",
        "            loss_new = out.loss\n",
        "            total_loss = loss_new\n",
        "\n",
        "            # Basque replay every N steps\n",
        "            if (step + 1) % subset_update_every == 0:\n",
        "                try:\n",
        "                    ba_batch = next(fr_iter)\n",
        "                except StopIteration:\n",
        "                    fr_iter = iter(ba_loader)\n",
        "                    ba_batch = next(fr_iter)\n",
        "                ba_batch = {k: v.to(device) for k, v in ba_batch.items()}\n",
        "\n",
        "                ba_out = model(**ba_batch)\n",
        "                ba_loss = ba_out.loss\n",
        "\n",
        "                total_loss = loss_new + replay_weight * ba_loss\n",
        "\n",
        "            # Backprop + update\n",
        "            total_loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Logging\n",
        "            if (step + 1) % 100 == 0:\n",
        "                if (step + 1) % subset_update_every == 0:\n",
        "                    print(\n",
        "                        f\"[Epoch {epoch} Step {step+1}] \"\n",
        "                        f\"loss_new={loss_new.item():.4f}, \"\n",
        "                        f\"loss_replay={ba_loss.item():.4f}, \"\n",
        "                        f\"total={total_loss.item():.4f}\"\n",
        "                    )\n",
        "                else:\n",
        "                    print(f\"[Epoch {epoch} Step {step+1}] loss_new={loss_new.item():.4f}\")\n",
        "\n",
        "        # End epoch eval\n",
        "        print(f\"Epoch {epoch} evaluation:\")\n",
        "        eval_ppl(model, english_test_ds, \"English new (replay)\")\n",
        "        eval_ppl(model, basque_test_ds,  \"Basque protected (replay)\")\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "replay_model = run_replay(\n",
        "    num_epochs=3,\n",
        "    lr=5e-5,\n",
        "    subset_update_every=5,\n",
        "    replay_weight=1.0,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "jeeW4bw4ZbWo"
      },
      "outputs": [],
      "source": [
        "def estimate_fisher_basque(model, num_batches=200):\n",
        "    model.eval()\n",
        "    fisher = {\n",
        "        name: torch.zeros_like(p.data)\n",
        "        for name, p in model.named_parameters()\n",
        "        if p.requires_grad\n",
        "    }\n",
        "\n",
        "    loader = DataLoader(\n",
        "        basque_train_ds,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        collate_fn=collate_fn\n",
        "    )\n",
        "    it = iter(loader)\n",
        "\n",
        "    for i in range(num_batches):\n",
        "        try:\n",
        "            batch = next(it)\n",
        "        except StopIteration:\n",
        "            it = iter(loader)\n",
        "            batch = next(it)\n",
        "\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "        model.zero_grad()\n",
        "        out = model(**batch)\n",
        "        loss = out.loss\n",
        "        loss.backward()\n",
        "\n",
        "        for name, p in model.named_parameters():\n",
        "            if not p.requires_grad or p.grad is None:\n",
        "                continue\n",
        "            fisher[name] += p.grad.data.pow(2)\n",
        "\n",
        "    for name in fisher:\n",
        "        fisher[name] /= num_batches\n",
        "\n",
        "    model.train()\n",
        "    return fisher\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "sIlC7y1Vd0Gj"
      },
      "outputs": [],
      "source": [
        "def estimate_model_fisher_basque(model, num_batches=200, top_k=100):\n",
        "    \"\"\"\n",
        "    Compute *model Fisher* diagonal using KL(p_ref || p_model),\n",
        "    with optional top-K truncation of the reference distribution.\n",
        "\n",
        "    top_k < 0  → use full distribution (no truncation)\n",
        "    top_k > 0  → keep only top_k tokens in reference distribution\n",
        "    \"\"\"\n",
        "\n",
        "    # Freeze reference model θ0\n",
        "    ref_model = copy.deepcopy(model).eval().to(device)\n",
        "    for p in ref_model.parameters():\n",
        "        p.requires_grad = False\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    fisher = {\n",
        "        name: torch.zeros_like(p.data)\n",
        "        for name, p in model.named_parameters()\n",
        "        if p.requires_grad\n",
        "    }\n",
        "\n",
        "    loader = DataLoader(\n",
        "        basque_train_ds,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        collate_fn=collate_fn\n",
        "    )\n",
        "    it = iter(loader)\n",
        "\n",
        "    for i in range(num_batches):\n",
        "        try:\n",
        "            batch = next(it)\n",
        "        except StopIteration:\n",
        "            it = iter(loader)\n",
        "            batch = next(it)\n",
        "\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "\n",
        "        # ---- 1. Reference distribution ----\n",
        "        with torch.no_grad():\n",
        "            ref_logits = ref_model(**batch).logits\n",
        "            ref_probs_full = ref_logits.softmax(dim=-1)  # shape [B, T, V]\n",
        "\n",
        "        # ---- 2. Possibly truncate to top-K ----\n",
        "        if top_k is not None and top_k > 0:\n",
        "            # Get top-K indices for each token\n",
        "            top_vals, top_idx = torch.topk(ref_probs_full, k=top_k, dim=-1)\n",
        "            # Renormalize probs over top-K\n",
        "            ref_probs = top_vals / top_vals.sum(dim=-1, keepdim=True)\n",
        "            # Make a tensor of zeros [B,T,V]\n",
        "            ref_probs_k = torch.zeros_like(ref_probs_full)\n",
        "            # Scatter top-K probabilities back into vocab dimension\n",
        "            ref_probs_k.scatter_(-1, top_idx, ref_probs)\n",
        "            ref_probs = ref_probs_k\n",
        "        else:\n",
        "            # use full distribution\n",
        "            ref_probs = ref_probs_full\n",
        "\n",
        "        # ---- 3. Model logits ----\n",
        "        logits = model(**batch).logits\n",
        "        log_probs = logits.log_softmax(dim=-1)\n",
        "\n",
        "        # ---- 4. KL(p_ref || p_model) ----\n",
        "        # KL per token: Σ_i q_i log(q_i/p_i)\n",
        "        kl = (ref_probs * (ref_probs.log() - log_probs)).sum(dim=-1)\n",
        "        loss = kl.mean()\n",
        "\n",
        "        # ---- 5. Backprop = model Fisher at θ0 ----\n",
        "        model.zero_grad()\n",
        "        loss.backward()\n",
        "\n",
        "        # ---- 6. Accumulate grad^2 ----\n",
        "        for name, p in model.named_parameters():\n",
        "            if not p.requires_grad or p.grad is None:\n",
        "                continue\n",
        "            fisher[name] += p.grad.data.pow(2)\n",
        "\n",
        "    # Average\n",
        "    for name in fisher:\n",
        "        fisher[name] /= num_batches\n",
        "\n",
        "    model.train()\n",
        "    return fisher\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nmCW04VjZjuS",
        "outputId": "ea63d295-eeb4-4679-e1ba-54b5551efcf9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== ProtectedAdam-γ with precomputed Basque Fisher ===\n",
            "Epoch 0 evaluation:\n",
            "English new (precomputed-Fisher) perplexity: 44.793\n",
            "Basque protected (precomputed-Fisher) perplexity: 1375.423\n",
            "Epoch 1 evaluation:\n",
            "English new (precomputed-Fisher) perplexity: 43.936\n",
            "Basque protected (precomputed-Fisher) perplexity: 1540.240\n",
            "Epoch 2 evaluation:\n",
            "English new (precomputed-Fisher) perplexity: 43.401\n",
            "Basque protected (precomputed-Fisher) perplexity: 1651.044\n",
            "=== ProtectedAdam-γ with precomputed Basque Fisher ===\n",
            "Epoch 0 evaluation:\n",
            "English new (precomputed-Fisher) perplexity: 44.376\n",
            "Basque protected (precomputed-Fisher) perplexity: 1282.951\n",
            "Epoch 1 evaluation:\n",
            "English new (precomputed-Fisher) perplexity: 42.969\n",
            "Basque protected (precomputed-Fisher) perplexity: 1409.191\n",
            "Epoch 2 evaluation:\n",
            "English new (precomputed-Fisher) perplexity: 42.423\n",
            "Basque protected (precomputed-Fisher) perplexity: 1484.037\n"
          ]
        }
      ],
      "source": [
        "def run_protected_adam_precomputed(\n",
        "    num_epochs=2,\n",
        "    lr=5e-5,\n",
        "    alpha_geom=1.0,\n",
        "    beta_geom=10.0,\n",
        "    gamma_exp=0.5,\n",
        "    rho_all=0.99,\n",
        "    fisher_sub=None,   # dict[name -> tensor]\n",
        "):\n",
        "    base_model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "    model = copy.deepcopy(base_model).to(device)\n",
        "    model.train()\n",
        "\n",
        "    # We'll work with named parameters for alignment\n",
        "    named_params = [\n",
        "        (name, p) for name, p in model.named_parameters()\n",
        "        if p.requires_grad\n",
        "    ]\n",
        "\n",
        "    state = {}\n",
        "    for name, p in named_params:\n",
        "        if fisher_sub is not None and name in fisher_sub:\n",
        "            v_sub_init = fisher_sub[name].clone().to(device)\n",
        "        else:\n",
        "            v_sub_init = torch.zeros_like(p.data)\n",
        "\n",
        "        state[name] = {\n",
        "            \"m\": torch.zeros_like(p.data),\n",
        "            \"v_all\": torch.zeros_like(p.data),\n",
        "            \"v_sub\": v_sub_init,\n",
        "        }\n",
        "\n",
        "    beta1 = 0.9\n",
        "    eps = 1e-6\n",
        "    global_step = 0\n",
        "\n",
        "    def protected_adam_step():\n",
        "        nonlocal global_step\n",
        "        global_step += 1\n",
        "        for name, p in named_params:\n",
        "            if p.grad is None:\n",
        "                continue\n",
        "            grad = p.grad.data\n",
        "            s = state[name]\n",
        "\n",
        "            # first moment\n",
        "            s[\"m\"].mul_(beta1).add_(grad, alpha=1 - beta1)\n",
        "\n",
        "            # second moment on \"all\" (new English) data\n",
        "            s[\"v_all\"].mul_(rho_all).addcmul_(grad, grad, value=1 - rho_all)\n",
        "\n",
        "            v_all = s[\"v_all\"]\n",
        "            v_sub = s[\"v_sub\"]  # fixed precomputed Fisher\n",
        "            v_protect = alpha_geom * v_all + beta_geom * v_sub\n",
        "\n",
        "            m_hat = s[\"m\"] / (1 - beta1**global_step)\n",
        "            denom = (v_protect + eps).pow(gamma_exp)\n",
        "            step = m_hat / denom\n",
        "            p.data.add_(step, alpha=-lr)\n",
        "\n",
        "    print(\"=== ProtectedAdam-γ with precomputed Basque Fisher ===\")\n",
        "    for epoch in range(num_epochs):\n",
        "        for step, batch in enumerate(eng_loader):\n",
        "            batch = {k: v.to(device) for k, v in batch.items()}\n",
        "            model.zero_grad()\n",
        "            out = model(**batch)\n",
        "            loss = out.loss\n",
        "            loss.backward()\n",
        "            protected_adam_step()\n",
        "\n",
        "        print(f\"Epoch {epoch} evaluation:\")\n",
        "        eval_ppl(model, english_test_ds, \"English new (precomputed-Fisher)\")\n",
        "        eval_ppl(model, basque_test_ds,  \"Basque protected (precomputed-Fisher)\")\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "# 1. Make a base model for Fisher estimation\n",
        "base_model = AutoModelForCausalLM.from_pretrained(model_name).to(device)\n",
        "\n",
        "\n",
        "# 2. Estimate Fisher on Basque ONCE\n",
        "mfisher_basque = estimate_model_fisher_basque(base_model, num_batches=200)\n",
        "\n",
        "# 3. Run English finetuning using precomputed Fisher, no Basque batches\n",
        "protected_model_pre_mfisher = run_protected_adam_precomputed(\n",
        "    num_epochs=3,\n",
        "    lr=1e-5,\n",
        "    alpha_geom=1.0,\n",
        "    beta_geom=10.0,\n",
        "    gamma_exp=0.5,\n",
        "    rho_all=0.99,\n",
        "    fisher_sub=mfisher_basque,   # <- pass the dict here\n",
        ")\n",
        "\n",
        "\n",
        "# 2. Estimate Fisher on Basque ONCE\n",
        "fisher_basque = estimate_fisher_basque(base_model, num_batches=200)\n",
        "\n",
        "# 3. Run English finetuning using precomputed Fisher, no Basque batches\n",
        "protected_model_pre = run_protected_adam_precomputed(\n",
        "    num_epochs=3,\n",
        "    lr=1e-5,\n",
        "    alpha_geom=1.0,\n",
        "    beta_geom=10.0,\n",
        "    gamma_exp=0.5,\n",
        "    rho_all=0.99,\n",
        "    fisher_sub=fisher_basque,   # <- pass the dict here\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 555
        },
        "id": "Q7ouhy6W_9b7",
        "outputId": "36bb129d-ea7f-4e61-add9-e6baa4b09f51"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== ProtectedAdam-precomputed2 (additive): Adam base + Fisher protection ===\n",
            "alpha_geom=1.0, beta_geom=0.1, gamma_exp=0.5, rho_all=0.99, global_vsub_mean=4.393e-06\n",
            "[Epoch 0 Step 100] loss_new = 5.0631\n",
            "[Epoch 0 Step 200] loss_new = 4.9248\n",
            "Epoch 0 evaluation:\n",
            "English new (ProtAdam-pre2-add) perplexity: 62.104\n",
            "Basque protected (ProtAdam-pre2-add) perplexity: 1168.050\n",
            "[Epoch 1 Step 100] loss_new = 4.4134\n",
            "[Epoch 1 Step 200] loss_new = 4.3895\n",
            "Epoch 1 evaluation:\n",
            "English new (ProtAdam-pre2-add) perplexity: 51.642\n",
            "Basque protected (ProtAdam-pre2-add) perplexity: 1170.619\n",
            "[Epoch 2 Step 100] loss_new = 4.4425\n",
            "[Epoch 2 Step 200] loss_new = 4.0078\n",
            "Epoch 2 evaluation:\n",
            "English new (ProtAdam-pre2-add) perplexity: 46.780\n",
            "Basque protected (ProtAdam-pre2-add) perplexity: 1182.053\n"
          ]
        }
      ],
      "source": [
        "# does not work, ignore for now\n",
        "def run_protected_adam_precomputed2(\n",
        "    num_epochs=2,\n",
        "    lr=5e-5,\n",
        "    alpha_geom=1.0,      # scale for v_all (Adam geometry)\n",
        "    beta_geom=10.0,      # strength of protection from v_sub\n",
        "    gamma_exp=0.5,       # exponent applied only to normalized v_sub\n",
        "    rho_all=0.99,\n",
        "    fisher_sub=None,     # dict[name -> tensor], precomputed Fisher on Basque\n",
        "):\n",
        "    \"\"\"\n",
        "    Protected Adam with precomputed Fisher (additive version).\n",
        "\n",
        "    - v_all: EMA of grad^2 on English (new task), like Adam.\n",
        "    - v_sub: fixed Fisher from Basque (protected capability), precomputed.\n",
        "    - v_sub is normalized globally once to be dimensionless.\n",
        "\n",
        "    Update (per-parameter i):\n",
        "        v_all_i ← EMA of g_i^2\n",
        "        v_sub_i ≈ Fisher_i\n",
        "\n",
        "        v_sub_scaled_i = v_sub_i / global_mean(v_sub)\n",
        "\n",
        "        base_rms_i   = sqrt(alpha_geom * v_all_i)\n",
        "        protect_i    = beta_geom * (v_sub_scaled_i ** gamma_exp)\n",
        "\n",
        "        denom_i = base_rms_i + protect_i + eps\n",
        "\n",
        "        Δθ_i = -lr * m_hat_i / denom_i\n",
        "\n",
        "    Properties:\n",
        "      - If fisher_sub is None or beta_geom = 0 -> exactly Adam.\n",
        "      - If v_sub is small -> denom ≈ base_rms -> Adam-like.\n",
        "      - If v_sub is large -> extra additive penalty in denom -> stronger protection.\n",
        "    \"\"\"\n",
        "\n",
        "    # 1) Start from base GPT-2\n",
        "    base_model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "    model = copy.deepcopy(base_model).to(device)\n",
        "    model.train()\n",
        "\n",
        "    # 2) Collect named parameters to align with fisher_sub[name]\n",
        "    named_params = [\n",
        "        (name, p) for name, p in model.named_parameters()\n",
        "        if p.requires_grad\n",
        "    ]\n",
        "\n",
        "    # 3) Initialize state (m, v_all, v_sub)\n",
        "    state = {}\n",
        "    for name, p in named_params:\n",
        "        v_sub_init = torch.zeros_like(p.data)\n",
        "        if fisher_sub is not None and name in fisher_sub:\n",
        "            v_sub_init = fisher_sub[name].clone().to(p.data.device)\n",
        "        state[name] = {\n",
        "            \"m\": torch.zeros_like(p.data),\n",
        "            \"v_all\": torch.zeros_like(p.data),\n",
        "            \"v_sub\": v_sub_init,\n",
        "        }\n",
        "\n",
        "    # 4) Compute a global mean of v_sub for normalization (dimensionless)\n",
        "    if fisher_sub is not None:\n",
        "        total_sum = 0.0\n",
        "        total_count = 0\n",
        "        for name, p in named_params:\n",
        "            v_sub = state[name][\"v_sub\"]\n",
        "            if v_sub.numel() > 0:\n",
        "                total_sum += v_sub.sum().item()\n",
        "                total_count += v_sub.numel()\n",
        "        if total_count > 0:\n",
        "            global_vsub_mean = total_sum / total_count\n",
        "        else:\n",
        "            global_vsub_mean = 1.0\n",
        "    else:\n",
        "        global_vsub_mean = 1.0\n",
        "\n",
        "    beta1 = 0.9\n",
        "    eps = 1e-8\n",
        "    global_step = 0\n",
        "\n",
        "    print(\"=== ProtectedAdam-precomputed2 (additive): Adam base + Fisher protection ===\")\n",
        "    print(\n",
        "        f\"alpha_geom={alpha_geom}, beta_geom={beta_geom}, \"\n",
        "        f\"gamma_exp={gamma_exp}, rho_all={rho_all}, \"\n",
        "        f\"global_vsub_mean={global_vsub_mean:.3e}\"\n",
        "    )\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        for step, batch in enumerate(eng_loader):\n",
        "            batch = {k: v.to(device) for k, v in batch.items()}\n",
        "\n",
        "            # ----- 1) Forward/backward on English (new task) -----\n",
        "            model.zero_grad()\n",
        "            out = model(**batch)\n",
        "            loss = out.loss\n",
        "            loss.backward()\n",
        "\n",
        "            global_step += 1\n",
        "\n",
        "            # ----- 2) Protected Adam step (additive Fisher term) -----\n",
        "            with torch.no_grad():\n",
        "                for name, p in named_params:\n",
        "                    if p.grad is None:\n",
        "                        continue\n",
        "\n",
        "                    g = p.grad.data\n",
        "                    s = state[name]\n",
        "\n",
        "                    # First moment (Adam)\n",
        "                    s[\"m\"].mul_(beta1).add_(g, alpha=1 - beta1)\n",
        "\n",
        "                    # Second moment on \"all\" (new English) data (Adam-style)\n",
        "                    s[\"v_all\"].mul_(rho_all).addcmul_(g, g, value=1 - rho_all)\n",
        "\n",
        "                    v_all = s[\"v_all\"]\n",
        "                    v_sub = s[\"v_sub\"]\n",
        "\n",
        "                    # Base Adam geometry: sqrt of v_all (scaled)\n",
        "                    base_rms = (alpha_geom * v_all).sqrt()\n",
        "\n",
        "                    # Normalized protective curvature from v_sub (dimensionless)\n",
        "                    if fisher_sub is not None and beta_geom != 0.0 and global_vsub_mean > 0.0:\n",
        "                        v_sub_scaled = v_sub / (global_vsub_mean + 1e-12)\n",
        "                        v_sub_scaled = torch.clamp(v_sub_scaled, min=0.0)  # safety\n",
        "                        protect_term = beta_geom * v_sub_scaled.pow(gamma_exp)\n",
        "                    else:\n",
        "                        protect_term = 0.0\n",
        "\n",
        "                    m_hat = s[\"m\"] / (1 - beta1**global_step)\n",
        "\n",
        "                    # ADDITIVE protection: denom = base_rms + protective term\n",
        "                    denom = base_rms + protect_term + eps\n",
        "                    step_dir = m_hat / denom\n",
        "\n",
        "                    p.data.add_(step_dir, alpha=-lr)\n",
        "\n",
        "            if (step + 1) % 100 == 0:\n",
        "                print(f\"[Epoch {epoch} Step {step+1}] loss_new = {loss.item():.4f}\")\n",
        "\n",
        "        # ----- 3) Epoch-end evaluation -----\n",
        "        print(f\"Epoch {epoch} evaluation:\")\n",
        "        eng_ppl = eval_ppl(model, english_test_ds, \"English new (ProtAdam-pre2-add)\")\n",
        "        fr_ppl  = eval_ppl(model, basque_test_ds,  \"Basque protected (ProtAdam-pre2-add)\")\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "# 3. Run English finetuning using precomputed Fisher, no Basque batches\n",
        "protected_model_pre = run_protected_adam_precomputed2(\n",
        "    num_epochs=3,\n",
        "    lr=1e-5,\n",
        "    alpha_geom=1.0,\n",
        "    beta_geom=0.1,\n",
        "    gamma_exp=0.5,\n",
        "    rho_all=0.99,\n",
        "    fisher_sub=fisher_basque,   # <- pass the dict here\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BAgBd4Mko-n2",
        "outputId": "b721b0db-0453-4118-ce6b-5463fb7ae492"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Adam with Fisher KL trust region on Basque ===\n",
            "lr=1e-05, delta_kl=1e-10\n",
            "[Epoch 0 Step 100] loss_new = 5.2644, KL_est = 8.133e-09, scale = 0.111\n",
            "[Epoch 0 Step 200] loss_new = 4.6718, KL_est = 8.090e-09, scale = 0.111\n",
            "Epoch 0 evaluation:\n",
            "English new (Adam+KL) perplexity: 52.872\n",
            "Basque protected (Adam+KL) perplexity: 1183.309\n",
            "[Epoch 1 Step 100] loss_new = 4.0843, KL_est = 4.778e-09, scale = 0.145\n",
            "[Epoch 1 Step 200] loss_new = 4.1564, KL_est = 4.154e-09, scale = 0.155\n",
            "Epoch 1 evaluation:\n",
            "English new (Adam+KL) perplexity: 46.493\n",
            "Basque protected (Adam+KL) perplexity: 1336.613\n",
            "[Epoch 2 Step 100] loss_new = 3.6354, KL_est = 4.001e-09, scale = 0.158\n",
            "[Epoch 2 Step 200] loss_new = 3.4773, KL_est = 3.032e-09, scale = 0.182\n",
            "Epoch 2 evaluation:\n",
            "English new (Adam+KL) perplexity: 45.036\n",
            "Basque protected (Adam+KL) perplexity: 1466.439\n"
          ]
        }
      ],
      "source": [
        "def run_adam_with_fisher_trust_region(\n",
        "    num_epochs=2,\n",
        "    lr=1e-5,\n",
        "    beta1=0.9,\n",
        "    beta2=0.999,\n",
        "    eps=1e-8,\n",
        "    fisher_sub=None,    # dict[name -> tensor] from estimate_fishe_basque_named(...)\n",
        "    delta_kl=1e-3,      # KL budget per step (approx)\n",
        "):\n",
        "    \"\"\"\n",
        "    Adam on English, with a TRPO-style KL trust region on Basque capability:\n",
        "      1) Compute standard Adam step Δθ.\n",
        "      2) Estimate Basque KL ≈ 0.5 * Σ_i F_sub[i] * (Δθ_i)^2\n",
        "      3) If KL > delta_kl: scale Δθ by sqrt(delta_kl / KL).\n",
        "    \"\"\"\n",
        "\n",
        "    # Start from the same base model as elsewhere\n",
        "    base_model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "    base_model.resize_token_embeddings(len(tokenizer))\n",
        "    model = copy.deepcopy(base_model).to(device)\n",
        "    model.train()\n",
        "\n",
        "    # Named params for alignment with fisher_sub\n",
        "    named_params = [\n",
        "        (name, p) for name, p in model.named_parameters()\n",
        "        if p.requires_grad\n",
        "    ]\n",
        "\n",
        "    # Adam state\n",
        "    state = {}\n",
        "    for name, p in named_params:\n",
        "        state[name] = {\n",
        "            \"m\": torch.zeros_like(p.data),\n",
        "            \"v\": torch.zeros_like(p.data),\n",
        "        }\n",
        "\n",
        "    global_step = 0\n",
        "\n",
        "    print(\"=== Adam with Fisher KL trust region on Basque ===\")\n",
        "    print(f\"lr={lr}, delta_kl={delta_kl}\")\n",
        "    for epoch in range(num_epochs):\n",
        "        for step, batch in enumerate(eng_loader):\n",
        "            batch = {k: v.to(device) for k, v in batch.items()}\n",
        "\n",
        "            # 1) Forward/backward on English batch\n",
        "            model.zero_grad()\n",
        "            out = model(**batch)\n",
        "            loss = out.loss\n",
        "            loss.backward()\n",
        "\n",
        "            global_step += 1\n",
        "\n",
        "            # 2) Compute Adam proposal step Δθ for each param (WITHOUT applying yet)\n",
        "            proposed_steps = {}  # name -> tensor (Δθ)\n",
        "            for name, p in named_params:\n",
        "                if p.grad is None:\n",
        "                    proposed_steps[name] = torch.zeros_like(p.data)\n",
        "                    continue\n",
        "\n",
        "                g = p.grad.data\n",
        "                s = state[name]\n",
        "\n",
        "                # Adam moments\n",
        "                s[\"m\"].mul_(beta1).add_(g, alpha=1 - beta1)\n",
        "                s[\"v\"].mul_(beta2).addcmul_(g, g, value=1 - beta2)\n",
        "\n",
        "                # Bias-corrected\n",
        "                m_hat = s[\"m\"] / (1 - beta1 ** global_step)\n",
        "                v_hat = s[\"v\"] / (1 - beta2 ** global_step)\n",
        "\n",
        "                # Classic Adam step (note: step is *direction*, no lr yet)\n",
        "                step_dir = m_hat / (v_hat.sqrt() + eps)\n",
        "\n",
        "                # Proposed parameter change Δθ = -lr * step_dir\n",
        "                delta_theta = -lr * step_dir\n",
        "                proposed_steps[name] = delta_theta\n",
        "\n",
        "            # 3) Estimate Basque KL for this joint step using precomputed Fisher\n",
        "            kl_est = 0.0\n",
        "            if fisher_sub is not None:\n",
        "                for name, p in named_params:\n",
        "                    if name not in fisher_sub:\n",
        "                        continue\n",
        "                    delta = proposed_steps[name]\n",
        "                    if delta is None:\n",
        "                        continue\n",
        "                    F = fisher_sub[name].to(delta.device)\n",
        "                    # 0.5 * sum_i F_i * (Δθ_i)^2\n",
        "                    kl_est += 0.5 * (F * (delta ** 2)).sum().item()\n",
        "\n",
        "            # 4) Compute scaling factor to enforce KL ≤ delta_kl\n",
        "            if fisher_sub is None or kl_est <= 0.0:\n",
        "                scale = 1.0\n",
        "            elif kl_est <= delta_kl:\n",
        "                scale = 1.0\n",
        "            else:\n",
        "                scale = (delta_kl / kl_est) ** 0.5\n",
        "\n",
        "            # 5) Apply scaled step\n",
        "            for name, p in named_params:\n",
        "                delta = proposed_steps[name]\n",
        "                if delta is None:\n",
        "                    continue\n",
        "                p.data.add_(delta * scale)\n",
        "\n",
        "            if (step + 1) % 100 == 0:\n",
        "                print(\n",
        "                    f\"[Epoch {epoch} Step {step+1}] \"\n",
        "                    f\"loss_new = {loss.item():.4f}, KL_est = {kl_est:.3e}, scale = {scale:.3f}\"\n",
        "                )\n",
        "\n",
        "        # 6) Evaluation at epoch end\n",
        "        print(f\"Epoch {epoch} evaluation:\")\n",
        "        eng_ppl = eval_ppl(model, english_test_ds, \"English new (Adam+KL)\")\n",
        "        fr_ppl  = eval_ppl(model, basque_test_ds,  \"Basque protected (Adam+KL)\")\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Precompute model Fisher on Basque (once)\n",
        "base_model = AutoModelForCausalLM.from_pretrained(model_name).to(device)\n",
        "base_model.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "fisher_basque = estimate_fisher_basque(base_model, num_batches=200)\n",
        "\n",
        "# Now run English finetuning with TRPO-style KL trust region on Basque\n",
        "adam_trpo_model = run_adam_with_fisher_trust_region(\n",
        "    num_epochs=3,\n",
        "    lr=1e-5,\n",
        "    fisher_sub=fisher_basque,\n",
        "    delta_kl=1e-10,   # tune this up/down\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZW0AGZBHOA7O",
        "outputId": "128551b1-f88f-4f75-e6ef-94955a281746"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Final comparison ===\n",
            "Before training:\n",
            "English new (before training) perplexity: 83.357\n",
            "Basque protected (before training) perplexity: 1197.813\n",
            "Baseline Adam:\n",
            "English new (baseline) perplexity: 41.908\n",
            "Basque protected (baseline) perplexity: 2986.717\n",
            "\n",
            "EWC:\n",
            "English new (EWC) perplexity: 44.610\n",
            "Basque protected (EWC) perplexity: 2244.481\n",
            "\n",
            "ProtectedAdam-γ:\n",
            "English new (ProtectedAdam-γ) perplexity: 43.644\n",
            "Basque protected (ProtectedAdam-γ) perplexity: 1467.923\n",
            "\n",
            "ProtectedAdam2-γ:\n",
            "English new (ProtectedAdam-γ) perplexity: 45.276\n",
            "Basque protected (ProtectedAdam-γ) perplexity: 1845.656\n",
            "\n",
            "Replay:\n",
            "English new (ProtectedAdam-γ) perplexity: 45.777\n",
            "Basque protected (ProtectedAdam-γ) perplexity: 104.797\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "104.79691320983954"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(\"=== Final comparison ===\")\n",
        "\n",
        "print(\"Before training:\")\n",
        "base_model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "base_model.resize_token_embeddings(len(tokenizer))\n",
        "model = copy.deepcopy(base_model).to(device)\n",
        "\n",
        "eval_ppl(model, english_test_ds, \"English new (before training)\")\n",
        "eval_ppl(model, basque_test_ds,  \"Basque protected (before training)\")\n",
        "\n",
        "print(\"Baseline Adam:\")\n",
        "eval_ppl(baseline_model, english_test_ds, \"English new (baseline)\")\n",
        "eval_ppl(baseline_model, basque_test_ds,  \"Basque protected (baseline)\")\n",
        "\n",
        "print(\"\\nEWC:\")\n",
        "eval_ppl(ewc_model, english_test_ds, \"English new (EWC)\")\n",
        "eval_ppl(ewc_model, basque_test_ds,  \"Basque protected (EWC)\")\n",
        "\n",
        "print(\"\\nProtectedAdam-γ:\")\n",
        "eval_ppl(protected_model, english_test_ds, \"English new (ProtectedAdam-γ)\")\n",
        "eval_ppl(protected_model, basque_test_ds,  \"Basque protected (ProtectedAdam-γ)\")\n",
        "\n",
        "\n",
        "print(\"\\nProtectedAdam2-γ:\")\n",
        "eval_ppl(protected_model2, english_test_ds, \"English new (ProtectedAdam-γ)\")\n",
        "eval_ppl(protected_model2, basque_test_ds,  \"Basque protected (ProtectedAdam-γ)\")\n",
        "\n",
        "print(\"\\nReplay:\")\n",
        "eval_ppl(replay_model, english_test_ds, \"English new (ProtectedAdam-γ)\")\n",
        "eval_ppl(replay_model, basque_test_ds,  \"Basque protected (ProtectedAdam-γ)\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "00a45ce331f049659ddc5a8d3a733689": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "019d2a1857fe46099f9fc01c6ba6b8d7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a9cd86371154105b73bcf2ede9feea1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4017aa81e3504205b797a47b4541d236",
              "IPY_MODEL_1afded3de67843e89d9ce05dacf97cf6",
              "IPY_MODEL_3d2e1581055140788c0638914354f8ed"
            ],
            "layout": "IPY_MODEL_b07617e6f8d34273a5929b6ed5998120"
          }
        },
        "11481ce4d7c54a20b328fe987088d02b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "149b331d4d87433398ee419064405baa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c48cfdbb01a6438087a163d31de89005",
            "placeholder": "​",
            "style": "IPY_MODEL_a8851e5f5d6f46e8860bc772fa5b81ea",
            "value": "model.safetensors: 100%"
          }
        },
        "17a88ca67a994b51b5f425842c0ab3ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f7143d3bd72f4e1f9e119e1b29205cfb",
            "placeholder": "​",
            "style": "IPY_MODEL_cf6bf77b10dc4e04920eb2c05b5a4347",
            "value": "generation_config.json: 100%"
          }
        },
        "19a30732e19745b8a333de9eb6332a41": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_46a0746bf84440f38874b729d617f1df",
              "IPY_MODEL_9de635c4e355447e8e2a4d9f760fdfde",
              "IPY_MODEL_8998157212b8431ba8509dd0df98981b"
            ],
            "layout": "IPY_MODEL_9921b84c7f784e7ba9f32a97602546a7"
          }
        },
        "1afded3de67843e89d9ce05dacf97cf6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a197dbff6da43a6b445dfe17b2c2522",
            "max": 26,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_412823a0f00e42059339c56fb4bd9c9f",
            "value": 26
          }
        },
        "1f6ddb9d63b442dcb6d2b772c5068212": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "21357a168091432fbf46ec848df81842": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b5f3adfc279949e58696997e532348ee",
            "placeholder": "​",
            "style": "IPY_MODEL_4eb8fcc217cf4b9e98b63c09077a17ec",
            "value": "tokenizer.json: 100%"
          }
        },
        "2846c79926f440708121d6b5efa2f901": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38706d9664be4357b79dd614fbac9b27": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3adc4be8a5e442cc8c4d230d8ec3ef85": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3c41a4d44ad349d2accb847f8ec65f41": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3d2e1581055140788c0638914354f8ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7bc5dd35c071495b82c20903d663b66c",
            "placeholder": "​",
            "style": "IPY_MODEL_91a9aec8a55f4f418af506009da10f35",
            "value": " 26.0/26.0 [00:00&lt;00:00, 3.32kB/s]"
          }
        },
        "3ee498aad5c54b4c956bb39619959b60": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e6c8823a320447f7bae20c76e4070c0b",
            "max": 1042301,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8c9e710110a6423b84ade1d41b8a0529",
            "value": 1042301
          }
        },
        "4017aa81e3504205b797a47b4541d236": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c27c084743f643cc972967bcb0eb5753",
            "placeholder": "​",
            "style": "IPY_MODEL_6e69c53fb73d44caaf004f4a1baf5330",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "412823a0f00e42059339c56fb4bd9c9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4644d3f2f33d4f089ee5d788d8a2a0ef": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46a0746bf84440f38874b729d617f1df": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f9182aedceb2421b9a77a245d20a9a1e",
            "placeholder": "​",
            "style": "IPY_MODEL_95b18249d1884fa7895fb09393d2598b",
            "value": "config.json: 100%"
          }
        },
        "46ab261f4cc549e181eeae76c646abaa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_21357a168091432fbf46ec848df81842",
              "IPY_MODEL_53dbd36dc7e4462f8d94a403a0d82875",
              "IPY_MODEL_c1bac9dec2244a1e9eef085386d047f1"
            ],
            "layout": "IPY_MODEL_ec9d2bfc9b82450199239de8eada416d"
          }
        },
        "4a197dbff6da43a6b445dfe17b2c2522": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a2226e944a4410aa53f1717e07169b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4e9ea7427ef0479c9b0216fdb9604c8a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4eb8fcc217cf4b9e98b63c09077a17ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4f1ed9d96a5a4693ac360e9f90e42b8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "503d3af66d1c4b47ac0f9fd4caf475ae": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53dbd36dc7e4462f8d94a403a0d82875": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4644d3f2f33d4f089ee5d788d8a2a0ef",
            "max": 1355256,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_38706d9664be4357b79dd614fbac9b27",
            "value": 1355256
          }
        },
        "5df1c3945e404094b3f18c099b502a84": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_00a45ce331f049659ddc5a8d3a733689",
            "placeholder": "​",
            "style": "IPY_MODEL_b7e41e3eac364027a5a1bf7342f7bd49",
            "value": " 1.04M/1.04M [00:00&lt;00:00, 1.57MB/s]"
          }
        },
        "6099f135e0814a47822b3749934696b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a2f3c8562c204b1d9222851eed5f106f",
            "placeholder": "​",
            "style": "IPY_MODEL_f521b4a4d7154de6ba16f3e6bdf59b51",
            "value": "vocab.json: 100%"
          }
        },
        "65ac5143b332424ca9424506b20cd40a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "675449c0ef484dc3b3baae5bbe8b5fd5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e69c53fb73d44caaf004f4a1baf5330": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7681bec193b248ad8beca1bd01baf4c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2846c79926f440708121d6b5efa2f901",
            "placeholder": "​",
            "style": "IPY_MODEL_3adc4be8a5e442cc8c4d230d8ec3ef85",
            "value": " 124/124 [00:00&lt;00:00, 16.4kB/s]"
          }
        },
        "7805724c2c5448d4b29119483f055636": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7bc5dd35c071495b82c20903d663b66c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7dddedc6cfcb46848461c6aa231650ec": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8998157212b8431ba8509dd0df98981b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_675449c0ef484dc3b3baae5bbe8b5fd5",
            "placeholder": "​",
            "style": "IPY_MODEL_65ac5143b332424ca9424506b20cd40a",
            "value": " 665/665 [00:00&lt;00:00, 85.9kB/s]"
          }
        },
        "8bdf857cc0fb474f9bf8c73fa0ea2257": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_17a88ca67a994b51b5f425842c0ab3ff",
              "IPY_MODEL_ecdf1063c4cc48cab41115fbda94cc85",
              "IPY_MODEL_7681bec193b248ad8beca1bd01baf4c6"
            ],
            "layout": "IPY_MODEL_1f6ddb9d63b442dcb6d2b772c5068212"
          }
        },
        "8c9e710110a6423b84ade1d41b8a0529": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8d5615ddaac748d7a1ba5a26726aa6fb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ebe0ad1bb4e456a97821b31d8dfb9f6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ee340f1e44442aca9ad56eaf28e3ec6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91a9aec8a55f4f418af506009da10f35": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "92bf0487d45e4c06869ae88ee0bb877c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "95b18249d1884fa7895fb09393d2598b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9921b84c7f784e7ba9f32a97602546a7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9de635c4e355447e8e2a4d9f760fdfde": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_11481ce4d7c54a20b328fe987088d02b",
            "max": 665,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e97ed5800cff4055900545ff376979be",
            "value": 665
          }
        },
        "a1fc267bd68947dfbafa9ed3e6fb56c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a2f3c8562c204b1d9222851eed5f106f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8851e5f5d6f46e8860bc772fa5b81ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b07617e6f8d34273a5929b6ed5998120": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0fa9161ed064445aece8d321b3d88a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ee340f1e44442aca9ad56eaf28e3ec6",
            "max": 548105171,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3c41a4d44ad349d2accb847f8ec65f41",
            "value": 548105171
          }
        },
        "b5f3adfc279949e58696997e532348ee": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7e41e3eac364027a5a1bf7342f7bd49": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bbe725cd4bf4424490b1b6444fd128a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_149b331d4d87433398ee419064405baa",
              "IPY_MODEL_b0fa9161ed064445aece8d321b3d88a7",
              "IPY_MODEL_cf32259002024b7da355cc4eb0a752e8"
            ],
            "layout": "IPY_MODEL_503d3af66d1c4b47ac0f9fd4caf475ae"
          }
        },
        "c199e25df4d54001919f0481edc0b358": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e7c2de72aff4428db80fd3ddd8d82557",
              "IPY_MODEL_cb45de6c1d7d4dc7809c42da301e9fba",
              "IPY_MODEL_d8e0603c141f4674a1f57399cee4ef45"
            ],
            "layout": "IPY_MODEL_8d5615ddaac748d7a1ba5a26726aa6fb"
          }
        },
        "c1bac9dec2244a1e9eef085386d047f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ebe0ad1bb4e456a97821b31d8dfb9f6",
            "placeholder": "​",
            "style": "IPY_MODEL_4a2226e944a4410aa53f1717e07169b5",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 6.35MB/s]"
          }
        },
        "c27c084743f643cc972967bcb0eb5753": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c48cfdbb01a6438087a163d31de89005": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb45de6c1d7d4dc7809c42da301e9fba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d928ee45c23f436a9aa89ca5ef53df92",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ff49ae10aa48498dbb0cc35ab638c298",
            "value": 456318
          }
        },
        "ce768476c2144ff58e413e5195528b39": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf32259002024b7da355cc4eb0a752e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce768476c2144ff58e413e5195528b39",
            "placeholder": "​",
            "style": "IPY_MODEL_4f1ed9d96a5a4693ac360e9f90e42b8a",
            "value": " 548M/548M [00:01&lt;00:00, 360MB/s]"
          }
        },
        "cf6bf77b10dc4e04920eb2c05b5a4347": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d2e42c54ade243779ec71eb5fd4a51bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6099f135e0814a47822b3749934696b3",
              "IPY_MODEL_3ee498aad5c54b4c956bb39619959b60",
              "IPY_MODEL_5df1c3945e404094b3f18c099b502a84"
            ],
            "layout": "IPY_MODEL_7dddedc6cfcb46848461c6aa231650ec"
          }
        },
        "d8e0603c141f4674a1f57399cee4ef45": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_019d2a1857fe46099f9fc01c6ba6b8d7",
            "placeholder": "​",
            "style": "IPY_MODEL_92bf0487d45e4c06869ae88ee0bb877c",
            "value": " 456k/456k [00:00&lt;00:00, 1.07MB/s]"
          }
        },
        "d928ee45c23f436a9aa89ca5ef53df92": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6c8823a320447f7bae20c76e4070c0b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7c2de72aff4428db80fd3ddd8d82557": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e9ea7427ef0479c9b0216fdb9604c8a",
            "placeholder": "​",
            "style": "IPY_MODEL_7805724c2c5448d4b29119483f055636",
            "value": "merges.txt: 100%"
          }
        },
        "e97ed5800cff4055900545ff376979be": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ec9d2bfc9b82450199239de8eada416d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ecdf1063c4cc48cab41115fbda94cc85": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed40a4f1820246b99ca964b03244c906",
            "max": 124,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a1fc267bd68947dfbafa9ed3e6fb56c9",
            "value": 124
          }
        },
        "ed40a4f1820246b99ca964b03244c906": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f521b4a4d7154de6ba16f3e6bdf59b51": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f7143d3bd72f4e1f9e119e1b29205cfb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9182aedceb2421b9a77a245d20a9a1e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff49ae10aa48498dbb0cc35ab638c298": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
