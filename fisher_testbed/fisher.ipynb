{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testbed for testing Fisher-based continual learning for safety"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, get_scheduler\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_model_ids = [\n",
    "    \"meta-llama/Llama-3.2-1B-Instruct\",\n",
    "    \"allenai/OLMo-2-0425-1B-Instruct\",\n",
    "    \"Qwen/Qwen3-0.6B\"\n",
    "]\n",
    "big_model_ids = [\n",
    "    \"meta-llama/Llama-3.1-8B-Instruct\",\n",
    "    \"allenai/OLMo-2-1124-7B-Instruct\",\n",
    "    \"Qwen/Qwen3-8B\",\n",
    "]\n",
    "\n",
    "train_ds_id = \"Neelectric/OpenR1-Math-220k_CN-K12_OLMo-2_4096toks\"\n",
    "device = \"cuda:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_model_and_tokenizer(model_id):\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_id,\n",
    "        dtype=torch.bfloat16,\n",
    "        device_map=device,\n",
    "    )\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        model_id,\n",
    "    )\n",
    "    return model, tokenizer\n",
    "\n",
    "def create_dataloader(dataset_id):\n",
    "    dataset = load_dataset(dataset_id)\n",
    "    return dataset\n",
    "\n",
    "def add_reasoning_chat_template(tokenizer):\n",
    "    print(tokenizer)\n",
    "    # if \"qwen\" in \n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading in Qwen/Qwen3-0.6B\n"
     ]
    }
   ],
   "source": [
    "model_id = small_model_ids[2]\n",
    "print(f\"Loading in {model_id}\")\n",
    "model, tokenizer = load_model_and_tokenizer(model_id)\n",
    "tokenizer = add_reasoning_chat_template(tokenizer)\n",
    "\n",
    "# dataset = create_dataloader(train_ds_id)\n",
    "dataset = load_dataset(train_ds_id)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'content': 'The equation of the circle with endpoints A(-3, -1) and B(5, 5) as the diameter is ______.',\n",
       "  'role': 'user'},\n",
       " {'content': \"<think>\\nOkay, so I need to find the equation of a circle where the endpoints of the diameter are given as points A(-3, -1) and B(5, 5). Hmm, let me think. I remember that the standard equation of a circle is (x - h)^2 + (y - k)^2 = r^2, where (h, k) is the center and r is the radius. Right?\\n\\nFirst, since A and B are the endpoints of the diameter, the center of the circle should be the midpoint of these two points. That makes sense because the midpoint of the diameter is the center of the circle. So, I need to calculate the midpoint between A(-3, -1) and B(5, 5).\\n\\nTo find the midpoint, I can use the midpoint formula. The midpoint formula is ((x1 + x2)/2, (y1 + y2)/2). Let me plug in the values here. The x-coordinate of the midpoint would be (-3 + 5)/2 and the y-coordinate would be (-1 + 5)/2. Calculating that, (-3 + 5) is 2, so 2 divided by 2 is 1. For the y-coordinate, (-1 + 5) is 4, so 4 divided by 2 is 2. So the midpoint, which is the center of the circle, is (1, 2). Alright, so (h, k) is (1, 2). Got that part down.\\n\\nNext, I need to find the radius. Since the radius is half the diameter, I can calculate the length of the diameter first and then divide by 2. The diameter is the distance between points A and B. To find the distance between two points, I can use the distance formula, which is sqrt[(x2 - x1)^2 + (y2 - y1)^2]. Let me apply that here.\\n\\nSubstituting the coordinates of A and B into the distance formula: sqrt[(5 - (-3))^2 + (5 - (-1))^2]. Let me compute each part step by step. The x difference is 5 - (-3), which is 5 + 3 = 8. The y difference is 5 - (-1) = 5 + 1 = 6. Then, squaring those differences: 8^2 = 64 and 6^2 = 36. Adding those together: 64 + 36 = 100. Taking the square root of 100 gives 10. So the length of the diameter is 10. Therefore, the radius is half of that, which is 5. So, r = 5.\\n\\nNow that I have the center (1, 2) and the radius 5, I can plug these values into the standard equation of a circle. Substituting h = 1, k = 2, and r = 5 into (x - h)^2 + (y - k)^2 = r^2 gives (x - 1)^2 + (y - 2)^2 = 25. Wait, let me double-check that.\\n\\nFirst, the center is indeed (1, 2). The radius is 5, so squaring that gives 25. So the equation should be (x - 1)^2 + (y - 2)^2 = 25. Let me verify by plugging in one of the endpoints to see if it satisfies the equation. Let's try point A(-3, -1).\\n\\nPlugging x = -3 and y = -1 into the left-hand side: (-3 - 1)^2 + (-1 - 2)^2 = (-4)^2 + (-3)^2 = 16 + 9 = 25. That equals the right-hand side, which is 25. Okay, that works. Let me check point B(5,5) as well. (5 - 1)^2 + (5 - 2)^2 = (4)^2 + (3)^2 = 16 + 9 = 25. Yep, that also works. So both endpoints lie on the circle, which makes sense because they are the endpoints of the diameter.\\n\\nTherefore, the equation I derived seems correct. Let me recap the steps to ensure I didn't skip anything. Found the midpoint for the center, calculated the distance between the endpoints for the diameter, halved it for the radius, and plugged everything into the standard equation. Checked both endpoints to confirm. Looks solid.\\n\\nI wonder if there's another way to approach this problem. Maybe using the general equation of a circle? The general form is x^2 + y^2 + Dx + Ey + F = 0, but I think the method I used is more straightforward here. Since we know the diameter endpoints, midpoint and distance formula are the way to go. Yeah, probably the simplest method.\\n\\nAlternatively, I could use the fact that for any point (x, y) on the circle, the angle subtended by the diameter is a right angle. So, if I take a generic point (x, y) on the circle, the vectors from (x, y) to A and from (x, y) to B should be perpendicular. Their dot product should be zero. Let me try that approach to see if I get the same equation.\\n\\nVectors PA and PB, where P is (x, y), A is (-3, -1), B is (5,5). So vector PA is (-3 - x, -1 - y) and vector PB is (5 - x, 5 - y). The dot product of PA and PB should be zero. Therefore:\\n\\n(-3 - x)(5 - x) + (-1 - y)(5 - y) = 0\\n\\nLet me compute that:\\n\\nFirst term: (-3 - x)(5 - x) = (-3)(5) + (-3)(-x) + (-x)(5) + (-x)(-x) = -15 + 3x -5x + x^2 = x^2 - 2x -15\\n\\nSecond term: (-1 - y)(5 - y) = (-1)(5) + (-1)(-y) + (-y)(5) + (-y)(-y) = -5 + y -5y + y^2 = y^2 -4y -5\\n\\nAdding the two terms together:\\n\\n(x^2 - 2x -15) + (y^2 -4y -5) = x^2 + y^2 -2x -4y -20 = 0\\n\\nSo the equation is x^2 + y^2 -2x -4y -20 = 0. Let me compare this with the standard form I had earlier. The standard form was (x -1)^2 + (y -2)^2 =25. Expanding that:\\n\\n(x^2 -2x +1) + (y^2 -4y +4) =25\\n\\nWhich simplifies to x^2 + y^2 -2x -4y +5 =25\\n\\nThen x^2 + y^2 -2x -4y -20 =0. Which is exactly the same as the equation obtained through the other method. So that checks out. Both methods lead to the same equation, so that gives me more confidence that the answer is correct.\\n\\nTherefore, the equation of the circle with endpoints A(-3, -1) and B(5,5) as the diameter is (x -1)^2 + (y -2)^2 =25.\\n\\n**Final Answer**\\nThe equation of the circle is \\\\boxed{(x - 1)^2 + (y - 2)^2 = 25}.\\n</think>\\n\\nTo find the equation of the circle with endpoints A(-3, -1) and B(5, 5) as the diameter, we start by determining the center of the circle, which is the midpoint of the diameter. Using the midpoint formula:\\n\\n\\\\[\\n\\\\left( \\\\frac{x_1 + x_2}{2}, \\\\frac{y_1 + y_2}{2} \\\\right)\\n\\\\]\\n\\nSubstituting the coordinates of A and B:\\n\\n\\\\[\\n\\\\left( \\\\frac{-3 + 5}{2}, \\\\frac{-1 + 5}{2} \\\\right) = \\\\left( \\\\frac{2}{2}, \\\\frac{4}{2} \\\\right) = (1, 2)\\n\\\\]\\n\\nNext, we calculate the radius, which is half the length of the diameter. Using the distance formula to find the length of the diameter:\\n\\n\\\\[\\n\\\\sqrt{(x_2 - x_1)^2 + (y_2 - y_1)^2}\\n\\\\]\\n\\nSubstituting the coordinates of A and B:\\n\\n\\\\[\\n\\\\sqrt{(5 - (-3))^2 + (5 - (-1))^2} = \\\\sqrt{(8)^2 + (6)^2} = \\\\sqrt{64 + 36} = \\\\sqrt{100} = 10\\n\\\\]\\n\\nThe radius is half of the diameter, so:\\n\\n\\\\[\\n\\\\frac{10}{2} = 5\\n\\\\]\\n\\nUsing the center \\\\((1, 2)\\\\) and radius 5 in the standard form of the circle equation \\\\((x - h)^2 + (y - k)^2 = r^2\\\\):\\n\\n\\\\[\\n(x - 1)^2 + (y - 2)^2 = 25\\n\\\\]\\n\\nVerifying by checking the endpoints A and B confirms they satisfy the equation. Thus, the equation of the circle is:\\n\\n\\\\[\\n\\\\boxed{(x - 1)^2 + (y - 2)^2 = 25}\\n\\\\]\",\n",
       "  'role': 'assistant'}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = 0\n",
    "messages = dataset['train'][idx]['messages']\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized = tokenizer.apply_chat_template(messages, tokenize=True, return_assistant_tokens_mask=True, return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [128000, 128006, 9125, 128007, 271, 38766, 1303, 33025, 2696, 25, 6790, 220, 2366, 18, 198, 15724, 2696, 25, 220, 1627, 3799, 220, 2366, 20, 271, 128009, 128006, 882, 128007, 271, 791, 24524, 315, 279, 12960, 449, 37442, 362, 4172, 18, 11, 482, 16, 8, 323, 426, 7, 20, 11, 220, 20, 8, 439, 279, 23899, 374, 33771, 13, 128009, 128006, 78191, 128007, 271, 14023, 771, 397, 33413, 11, 779, 358, 1205, 311, 1505, 279, 24524, 315, 264, 12960, 1405, 279, 37442, 315, 279, 23899, 527, 2728, 439, 3585, 362, 4172, 18, 11, 482, 16, 8, 323, 426, 7, 20, 11, 220, 20, 570, 89290, 11, 1095, 757, 1781, 13, 358, 6227, 430, 279, 5410, 24524, 315, 264, 12960, 374, 320, 87, 482, 305, 30876, 17, 489, 320, 88, 482, 597, 30876, 17, 284, 436, 61, 17, 11, 1405, 320, 71, 11, 597, 8, 374, 279, 4219, 323, 436, 374, 279, 10801, 13, 10291, 1980, 5451, 11, 2533, 362, 323, 426, 527, 279, 37442, 315, 279, 23899, 11, 279, 4219, 315, 279, 12960, 1288, 387, 279, 83063, 315, 1521, 1403, 3585, 13, 3011, 3727, 5647, 1606, 279, 83063, 315, 279, 23899, 374, 279, 4219, 315, 279, 12960, 13, 2100, 11, 358, 1205, 311, 11294, 279, 83063, 1990, 362, 4172, 18, 11, 482, 16, 8, 323, 426, 7, 20, 11, 220, 20, 3677, 1271, 1505, 279, 83063, 11, 358, 649, 1005, 279, 83063, 15150, 13, 578, 83063, 15150, 374, 1819, 87, 16, 489, 865, 17, 5738, 17, 11, 320, 88, 16, 489, 379, 17, 5738, 17, 570, 6914, 757, 20206, 304, 279, 2819, 1618, 13, 578, 865, 81797, 315, 279, 83063, 1053, 387, 10505, 18, 489, 220, 20, 5738, 17, 323, 279, 379, 81797, 1053, 387, 10505, 16, 489, 220, 20, 5738, 17, 13, 32459, 1113, 430, 11, 10505, 18, 489, 220, 20, 8, 374, 220, 17, 11, 779, 220, 17, 18255, 555, 220, 17, 374, 220, 16, 13, 1789, 279, 379, 81797, 11, 10505, 16, 489, 220, 20, 8, 374, 220, 19, 11, 779, 220, 19, 18255, 555, 220, 17, 374, 220, 17, 13, 2100, 279, 83063, 11, 902, 374, 279, 4219, 315, 279, 12960, 11, 374, 320, 16, 11, 220, 17, 570, 98693, 11, 779, 320, 71, 11, 597, 8, 374, 320, 16, 11, 220, 17, 570, 25545, 430, 961, 1523, 382, 5971, 11, 358, 1205, 311, 1505, 279, 10801, 13, 8876, 279, 10801, 374, 4376, 279, 23899, 11, 358, 649, 11294, 279, 3160, 315, 279, 23899, 1176, 323, 1243, 22497, 555, 220, 17, 13, 578, 23899, 374, 279, 6138, 1990, 3585, 362, 323, 426, 13, 2057, 1505, 279, 6138, 1990, 1403, 3585, 11, 358, 649, 1005, 279, 6138, 15150, 11, 902, 374, 18430, 9896, 87, 17, 482, 865, 16, 30876, 17, 489, 320, 88, 17, 482, 379, 16, 30876, 17, 948, 6914, 757, 3881, 430, 1618, 382, 3214, 3781, 10831, 279, 14259, 315, 362, 323, 426, 1139, 279, 6138, 15150, 25, 18430, 9896, 20, 482, 10505, 18, 97959, 17, 489, 320, 20, 482, 10505, 16, 97959, 17, 948, 6914, 757, 12849, 1855, 961, 3094, 555, 3094, 13, 578, 865, 6811, 374, 220, 20, 482, 10505, 18, 705, 902, 374, 220, 20, 489, 220, 18, 284, 220, 23, 13, 578, 379, 6811, 374, 220, 20, 482, 10505, 16, 8, 284, 220, 20, 489, 220, 16, 284, 220, 21, 13, 5112, 11, 8330, 3329, 1884, 12062, 25, 220, 23, 61, 17, 284, 220, 1227, 323, 220, 21, 61, 17, 284, 220, 1927, 13, 31470, 1884, 3871, 25, 220, 1227, 489, 220, 1927, 284, 220, 1041, 13, 36925, 279, 9518, 3789, 315, 220, 1041, 6835, 220, 605, 13, 2100, 279, 3160, 315, 279, 23899, 374, 220, 605, 13, 15636, 11, 279, 10801, 374, 4376, 315, 430, 11, 902, 374, 220, 20, 13, 2100, 11, 436, 284, 220, 20, 382, 7184, 430, 358, 617, 279, 4219, 320, 16, 11, 220, 17, 8, 323, 279, 10801, 220, 20, 11, 358, 649, 20206, 1521, 2819, 1139, 279, 5410, 24524, 315, 264, 12960, 13, 3804, 3781, 10831, 305, 284, 220, 16, 11, 597, 284, 220, 17, 11, 323, 436, 284, 220, 20, 1139, 320, 87, 482, 305, 30876, 17, 489, 320, 88, 482, 597, 30876, 17, 284, 436, 61, 17, 6835, 320, 87, 482, 220, 16, 30876, 17, 489, 320, 88, 482, 220, 17, 30876, 17, 284, 220, 914, 13, 14144, 11, 1095, 757, 2033, 16313, 430, 382, 5451, 11, 279, 4219, 374, 13118, 320, 16, 11, 220, 17, 570, 578, 10801, 374, 220, 20, 11, 779, 8330, 3329, 430, 6835, 220, 914, 13, 2100, 279, 24524, 1288, 387, 320, 87, 482, 220, 16, 30876, 17, 489, 320, 88, 482, 220, 17, 30876, 17, 284, 220, 914, 13, 6914, 757, 10356, 555, 628, 36368, 304, 832, 315, 279, 37442, 311, 1518, 422, 433, 69001, 279, 24524, 13, 6914, 596, 1456, 1486, 362, 4172, 18, 11, 482, 16, 3677, 2169, 36368, 865, 284, 482, 18, 323, 379, 284, 482, 16, 1139, 279, 2163, 25417, 3185, 25, 10505, 18, 482, 220, 16, 30876, 17, 489, 10505, 16, 482, 220, 17, 30876, 17, 284, 10505, 19, 30876, 17, 489, 10505, 18, 30876, 17, 284, 220, 845, 489, 220, 24, 284, 220, 914, 13, 3011, 17239, 279, 1314, 25417, 3185, 11, 902, 374, 220, 914, 13, 36539, 11, 430, 4375, 13, 6914, 757, 1817, 1486, 426, 7, 20, 11, 20, 8, 439, 1664, 13, 320, 20, 482, 220, 16, 30876, 17, 489, 320, 20, 482, 220, 17, 30876, 17, 284, 320, 19, 30876, 17, 489, 320, 18, 30876, 17, 284, 220, 845, 489, 220, 24, 284, 220, 914, 13, 85294, 11, 430, 1101, 4375, 13, 2100, 2225, 37442, 10457, 389, 279, 12960, 11, 902, 3727, 5647, 1606, 814, 527, 279, 37442, 315, 279, 23899, 382, 55915, 11, 279, 24524, 358, 14592, 5084, 4495, 13, 6914, 757, 55099, 279, 7504, 311, 6106, 358, 3287, 956, 10936, 4205, 13, 12595, 279, 83063, 369, 279, 4219, 11, 16997, 279, 6138, 1990, 279, 37442, 369, 279, 23899, 11, 15104, 2111, 433, 369, 279, 10801, 11, 323, 59329, 4395, 1139, 279, 5410, 24524, 13, 94461, 2225, 37442, 311, 7838, 13, 42906, 6573, 382, 40, 5895, 422, 1070, 596, 2500, 1648, 311, 5603, 420, 3575, 13, 10926, 1701, 279, 4689, 24524, 315, 264, 12960, 30, 578, 4689, 1376, 374, 865, 61, 17, 489, 379, 61, 17, 489, 89897, 489, 44511, 489, 435, 284, 220, 15, 11, 719, 358, 1781, 279, 1749, 358, 1511, 374, 810, 31439, 1618, 13, 8876, 584, 1440, 279, 23899, 37442, 11, 83063, 323, 6138, 15150, 527, 279, 1648, 311, 733, 13, 22335, 11, 4762, 279, 45648, 1749, 382, 93114, 11, 358, 1436, 1005, 279, 2144, 430, 369, 904, 1486, 320, 87, 11, 379, 8, 389, 279, 12960, 11, 279, 9392, 42129, 2954, 555, 279, 23899, 374, 264, 1314, 9392, 13, 2100, 11, 422, 358, 1935, 264, 14281, 1486, 320, 87, 11, 379, 8, 389, 279, 12960, 11, 279, 23728, 505, 320, 87, 11, 379, 8, 311, 362, 323, 505, 320, 87, 11, 379, 8, 311, 426, 1288, 387, 77933, 13, 11205, 13046, 2027, 1288, 387, 7315, 13, 6914, 757, 1456, 430, 5603, 311, 1518, 422, 358, 636, 279, 1890, 24524, 382, 85844, 13174, 323, 32034, 11, 1405, 393, 374, 320, 87, 11, 379, 705, 362, 374, 10505, 18, 11, 482, 16, 705, 426, 374, 320, 20, 11, 20, 570, 2100, 4724, 13174, 374, 10505, 18, 482, 865, 11, 482, 16, 482, 379, 8, 323, 4724, 32034, 374, 320, 20, 482, 865, 11, 220, 20, 482, 379, 570, 578, 13046, 2027, 315, 13174, 323, 32034, 1288, 387, 7315, 13, 15636, 1473, 4172, 18, 482, 865, 2432, 20, 482, 865, 8, 489, 10505, 16, 482, 379, 2432, 20, 482, 379, 8, 284, 220, 15, 271, 10267, 757, 12849, 430, 1473, 5451, 4751, 25, 10505, 18, 482, 865, 2432, 20, 482, 865, 8, 284, 10505, 18, 2432, 20, 8, 489, 10505, 18, 2432, 12, 87, 8, 489, 10505, 87, 2432, 20, 8, 489, 10505, 87, 2432, 12, 87, 8, 284, 482, 868, 489, 220, 18, 87, 482, 20, 87, 489, 865, 61, 17, 284, 865, 61, 17, 482, 220, 17, 87, 482, 868, 271, 16041, 4751, 25, 10505, 16, 482, 379, 2432, 20, 482, 379, 8, 284, 10505, 16, 2432, 20, 8, 489, 10505, 16, 2432, 12, 88, 8, 489, 10505, 88, 2432, 20, 8, 489, 10505, 88, 2432, 12, 88, 8, 284, 482, 20, 489, 379, 482, 20, 88, 489, 379, 61, 17, 284, 379, 61, 17, 482, 19, 88, 482, 20, 271, 33408, 279, 1403, 3878, 3871, 1473, 2120, 61, 17, 482, 220, 17, 87, 482, 868, 8, 489, 320, 88, 61, 17, 482, 19, 88, 482, 20, 8, 284, 865, 61, 17, 489, 379, 61, 17, 482, 17, 87, 482, 19, 88, 482, 508, 284, 220, 15, 271, 4516, 279, 24524, 374, 865, 61, 17, 489, 379, 61, 17, 482, 17, 87, 482, 19, 88, 482, 508, 284, 220, 15, 13, 6914, 757, 9616, 420, 449, 279, 5410, 1376, 358, 1047, 6931, 13, 578, 5410, 1376, 574, 320, 87, 482, 16, 30876, 17, 489, 320, 88, 482, 17, 30876, 17, 284, 914, 13, 7943, 26673, 430, 1473, 2120, 61, 17, 482, 17, 87, 489, 16, 8, 489, 320, 88, 61, 17, 482, 19, 88, 489, 19, 8, 284, 914, 271, 23956, 15858, 9803, 311, 865, 61, 17, 489, 379, 61, 17, 482, 17, 87, 482, 19, 88, 489, 20, 284, 914, 271, 12487, 865, 61, 17, 489, 379, 61, 17, 482, 17, 87, 482, 19, 88, 482, 508, 284, 15, 13, 16299, 374, 7041, 279, 1890, 439, 279, 24524, 12457, 1555, 279, 1023, 1749, 13, 2100, 430, 12621, 704, 13, 11995, 5528, 3063, 311, 279, 1890, 24524, 11, 779, 430, 6835, 757, 810, 12410, 430, 279, 4320, 374, 4495, 382, 55915, 11, 279, 24524, 315, 279, 12960, 449, 37442, 362, 4172, 18, 11, 482, 16, 8, 323, 426, 7, 20, 11, 20, 8, 439, 279, 23899, 374, 320, 87, 482, 16, 30876, 17, 489, 320, 88, 482, 17, 30876, 17, 284, 914, 382, 334, 19918, 22559, 1035, 791, 24524, 315, 279, 12960, 374, 1144, 80175, 97165, 87, 482, 220, 16, 30876, 17, 489, 320, 88, 482, 220, 17, 30876, 17, 284, 220, 914, 28374, 524, 27963, 1363, 1271, 1505, 279, 24524, 315, 279, 12960, 449, 37442, 362, 4172, 18, 11, 482, 16, 8, 323, 426, 7, 20, 11, 220, 20, 8, 439, 279, 23899, 11, 584, 1212, 555, 26679, 279, 4219, 315, 279, 12960, 11, 902, 374, 279, 83063, 315, 279, 23899, 13, 12362, 279, 83063, 15150, 1473, 59, 9837, 59, 2414, 7, 1144, 38118, 46440, 62, 16, 489, 865, 62, 17, 15523, 17, 2186, 1144, 38118, 90, 88, 62, 16, 489, 379, 62, 17, 15523, 17, 92, 1144, 1315, 340, 59, 2595, 3214, 3781, 10831, 279, 14259, 315, 362, 323, 426, 1473, 59, 9837, 59, 2414, 7, 1144, 38118, 20597, 18, 489, 220, 20, 15523, 17, 2186, 1144, 38118, 20597, 16, 489, 220, 20, 15523, 17, 92, 1144, 1315, 8, 284, 1144, 2414, 7, 1144, 38118, 90, 17, 15523, 17, 2186, 1144, 38118, 90, 19, 15523, 17, 92, 1144, 1315, 8, 284, 320, 16, 11, 220, 17, 340, 59, 2595, 5971, 11, 584, 11294, 279, 10801, 11, 902, 374, 4376, 279, 3160, 315, 279, 23899, 13, 12362, 279, 6138, 15150, 311, 1505, 279, 3160, 315, 279, 23899, 1473, 59, 9837, 59, 27986, 97165, 87, 62, 17, 482, 865, 62, 16, 30876, 17, 489, 320, 88, 62, 17, 482, 379, 62, 16, 30876, 17, 534, 59, 2595, 3214, 3781, 10831, 279, 14259, 315, 362, 323, 426, 1473, 59, 9837, 59, 27986, 97165, 20, 482, 10505, 18, 97959, 17, 489, 320, 20, 482, 10505, 16, 97959, 17, 92, 284, 1144, 27986, 97165, 23, 30876, 17, 489, 320, 21, 30876, 17, 92, 284, 1144, 27986, 90, 1227, 489, 220, 1927, 92, 284, 1144, 27986, 90, 1041, 92, 284, 220, 605, 198, 59, 2595, 791, 10801, 374, 4376, 315, 279, 23899, 11, 779, 1473, 59, 9837, 59, 38118, 90, 605, 15523, 17, 92, 284, 220, 20, 198, 59, 2595, 16834, 279, 4219, 1144, 1209, 16, 11, 220, 17, 10929, 8, 323, 10801, 220, 20, 304, 279, 5410, 1376, 315, 279, 12960, 24524, 1144, 1209, 87, 482, 305, 30876, 17, 489, 320, 88, 482, 597, 30876, 17, 284, 436, 61, 17, 59, 7887, 59, 9837, 2120, 482, 220, 16, 30876, 17, 489, 320, 88, 482, 220, 17, 30876, 17, 284, 220, 914, 198, 59, 2595, 10351, 7922, 555, 13598, 279, 37442, 362, 323, 426, 43496, 814, 27651, 279, 24524, 13, 14636, 11, 279, 24524, 315, 279, 12960, 374, 1473, 59, 9837, 59, 80175, 97165, 87, 482, 220, 16, 30876, 17, 489, 320, 88, 482, 220, 17, 30876, 17, 284, 220, 914, 534, 59, 60, 128009], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'assistant_masks': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"
     ]
    }
   ],
   "source": [
    "print(tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_with_sft():\n",
    "    model.train()\n",
    "    for epoch in tqdm(range(num_epochs), desc=\"Epochs\", dynamic_ncols=True):\n",
    "        for batch in tqdm(train_dataloader, desc=\"Steps in Epoch\", dynamic_ncols=True):\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            outputs = model(**batch)\n",
    "            loss = outputs.loss\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "            optimizer.zero_grad()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final eval of methods"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openr1_v3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
