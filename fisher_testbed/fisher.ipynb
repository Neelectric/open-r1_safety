{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testbed for testing Fisher-based continual learning for safety"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and helper functions\n",
    "- Mostly boilerplate, skippable code.\n",
    "- Loads model onto device, loads tokenizer and sets assistant tags and reasoning system prompt as expected by trainer.\n",
    "- Tries to load pre-processed/-tokenized dataset from local dir. Otherwise, downloads dataset, prepares it for DataCollator by setting assistant_tokens_mask, and saves to local."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, get_scheduler\n",
    "from datasets import load_dataset, load_from_disk\n",
    "\n",
    "from trl.trainer.sft_trainer import DataCollatorForLanguageModeling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_and_tokenizer(model_id, device):\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_id,dtype=torch.bfloat16,device_map=device,)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_id,)\n",
    "    return model, tokenizer\n",
    "\n",
    "def load_or_preprocess_dataset(model_id, dataset_id, tokenizer, max_length=4096):\n",
    "    local_ds_id = f\"datasets/{model_id}/{dataset_id}\"\n",
    "    num_proc = 16\n",
    "    # try:\n",
    "    #     # final_dataset = load_from_disk(local_ds_id)\n",
    "    #     # print(f\"Loaded dataset from local dir {local_ds_id}\")\n",
    "    # except:\n",
    "    if True:\n",
    "        print(f\"Dataset not found locally, processing and caching...\")\n",
    "        raw_dataset = load_dataset(dataset_id)[\"train\"]\n",
    "        # raw_dataset = raw_dataset.select(range(5))  # use .select() not slicing - slicing returns a dict!\n",
    "        \n",
    "        def preprocess(example):\n",
    "            tokenized = tokenizer.apply_chat_template(\n",
    "                example[\"messages\"],\n",
    "                tokenize=True,\n",
    "                return_assistant_tokens_mask=True,\n",
    "                return_dict=True,\n",
    "            )\n",
    "            return {\n",
    "                \"input_ids\": tokenized[\"input_ids\"],\n",
    "                \"assistant_masks\": tokenized[\"assistant_masks\"],\n",
    "            }\n",
    "        \n",
    "        tokenized_dataset = raw_dataset.map(preprocess, remove_columns=raw_dataset.column_names, num_proc=num_proc, desc=\"Tokenizing\")\n",
    "        def shorter_than(example):\n",
    "            return len(example[\"input_ids\"]) <= max_length\n",
    "        final_dataset = tokenized_dataset.filter(shorter_than, num_proc=num_proc, desc=f\"Filtering to max length {max_length}\")\n",
    "        print(f\"Tokenized: {len(tokenized_dataset)}, After filtering: {len(final_dataset)}\")\n",
    "        final_dataset.save_to_disk(local_ds_id)\n",
    "    return final_dataset\n",
    "\n",
    "\n",
    "def create_dataloader(tokenizer, tokenized_dataset, batch_size):\n",
    "    collator = DataCollatorForLanguageModeling(pad_token_id=tokenizer.pad_token_id,)\n",
    "    dataloader = DataLoader(\n",
    "        tokenized_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        collate_fn=collator,\n",
    "    )\n",
    "    return dataloader\n",
    "\n",
    "def add_reasoning_chat_template(tokenizer):\n",
    "    if \"qwen\" in tokenizer.name_or_path.lower():\n",
    "        # we have to use DataCollatorForLanguageModeling with completion_only_loss=True\n",
    "        # however, for that tokenizer needs to have return_assistant_tokens_mask=True, and qwen decided against adding support for {% generation %} / {% endgeneration %} functionality\n",
    "        # so we download a community qwen3 chat template that has it\n",
    "        !wget -O all_assistant.jinja --no-check-certificate https://raw.githubusercontent.com/HarryMayne/qwen_3_chat_templates/refs/heads/main/all_assistant.jinja\n",
    "        !mv all_assistant.jinja chat_templates/all_assistant.jinja\n",
    "        with open('chat_templates/all_assistant.jinja', 'r') as f:\n",
    "            tokenizer.chat_template = f.read()\n",
    "\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model/Dataset IDs, hyperparam choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_model_ids = [\n",
    "    \"meta-llama/Llama-3.2-1B-Instruct\",\n",
    "    \"allenai/OLMo-2-0425-1B-Instruct\",\n",
    "    \"Qwen/Qwen3-0.6B\",\n",
    "    \"HuggingFaceTB/SmolLM2-135M-Instruct\"\n",
    "]\n",
    "big_model_ids = [\n",
    "    \"meta-llama/Llama-3.1-8B-Instruct\",\n",
    "    \"allenai/OLMo-2-1124-7B-Instruct\",\n",
    "    \"Qwen/Qwen3-8B\",\n",
    "    \"HuggingFaceTB/SmolLM2-1.7B-Instruct\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_id = \"Neelectric/OpenR1-Math-220k_CN-K12_OLMo-2_4096toks\"\n",
    "device = \"cuda:0\"\n",
    "model_id = small_model_ids[2]\n",
    "batch_size = 8\n",
    "max_length = 1024\n",
    "num_epochs = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading model, tokenizer, dataset, dataloader, optimizer, LR scheduler, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading in Qwen/Qwen3-0.6B\n",
      "--2025-12-29 17:14:34--  https://raw.githubusercontent.com/HarryMayne/qwen_3_chat_templates/refs/heads/main/all_assistant.jinja\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.111.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 4153 (4.1K) [text/plain]\n",
      "Saving to: ‘all_assistant.jinja’\n",
      "\n",
      "all_assistant.jinja 100%[===================>]   4.06K  --.-KB/s    in 0s      \n",
      "\n",
      "2025-12-29 17:14:34 (35.3 MB/s) - ‘all_assistant.jinja’ saved [4153/4153]\n",
      "\n",
      "Dataset not found locally, processing and caching...\n",
      "Tokenized: 69132, After filtering: 4749\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0846b485ffd84908b31af4ed454e5339",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/4749 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f\"Loading in {model_id}\")\n",
    "model, tokenizer = load_model_and_tokenizer(model_id, device)\n",
    "tokenizer = add_reasoning_chat_template(tokenizer)\n",
    "tokenized_dataset = load_or_preprocess_dataset(model_id, dataset_id, tokenizer, max_length=max_length)\n",
    "dataloader = create_dataloader(tokenizer, tokenized_dataset, batch_size)\n",
    "num_training_steps = num_epochs * len(dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "594"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'labels', 'attention_mask'])\n",
      "torch.Size([8, 1011])\n",
      "  0 | 151644 |   -100 | <|im_start|>\n",
      "  1 |    872 |   -100 | user\n",
      "  2 |    198 |   -100 | \n",
      "\n",
      "  3 |    641 |   -100 | In\n",
      "  4 |    279 |   -100 |  the\n",
      "  5 |  80715 |   -100 |  Cartesian\n",
      "  6 |  16184 |   -100 |  coordinate\n",
      "  7 |   1849 |   -100 |  system\n",
      "  8 |     11 |   -100 | ,\n",
      "  9 |    279 |   -100 |  the\n",
      " 10 |  13934 |   -100 |  coordinates\n",
      " 11 |    315 |   -100 |  of\n",
      " 12 |   1459 |   -100 |  point\n",
      " 13 |    400 |   -100 |  $\n",
      " 14 |     47 |   -100 | P\n",
      " 15 |   4080 |   -100 | (-\n",
      " 16 |     17 |   -100 | 2\n",
      " 17 |   4999 |   -100 | ,-\n",
      " 18 |     18 |   -100 | 3\n",
      " 19 |  15087 |   -100 | )$\n",
      " 20 |   1283 |   -100 |  after\n",
      " 21 |   7218 |   -100 |  moving\n",
      " 22 |    400 |   -100 |  $\n",
      " 23 |     18 |   -100 | 3\n",
      " 24 |      3 |   -100 | $\n",
      " 25 |   8153 |   -100 |  units\n",
      " 26 |    311 |   -100 |  to\n",
      " 27 |    279 |   -100 |  the\n",
      " 28 |   1290 |   -100 |  right\n",
      " 29 |    525 |   -100 |  are\n",
      " 30 |    320 |   -100 |  (\n",
      " 31 |  49270 |   -100 |  ).\n",
      "\n",
      "\n",
      " 32 |     32 |   -100 | A\n",
      " 33 |     25 |   -100 | :\n",
      " 34 |    400 |   -100 |  $\n",
      " 35 |   4080 |   -100 | (-\n",
      " 36 |     20 |   -100 | 5\n",
      " 37 |   4999 |   -100 | ,-\n",
      " 38 |     18 |   -100 | 3\n",
      " 39 |  15087 |   -100 | )$\n",
      " 40 |    271 |   -100 | \n",
      "\n",
      "\n",
      " 41 |     33 |   -100 | B\n",
      " 42 |     25 |   -100 | :\n",
      " 43 |   4930 |   -100 |  $(\n",
      " 44 |     16 |   -100 | 1\n",
      " 45 |   4999 |   -100 | ,-\n",
      " 46 |     18 |   -100 | 3\n",
      " 47 |  15087 |   -100 | )$\n",
      " 48 |    271 |   -100 | \n",
      "\n",
      "\n",
      " 49 |     34 |   -100 | C\n",
      " 50 |     25 |   -100 | :\n",
      " 51 |   4930 |   -100 |  $(\n",
      " 52 |     16 |   -100 | 1\n",
      " 53 |     11 |   -100 | ,\n",
      " 54 |     15 |   -100 | 0\n",
      " 55 |  15087 |   -100 | )$\n",
      " 56 |    271 |   -100 | \n",
      "\n",
      "\n",
      " 57 |     35 |   -100 | D\n",
      " 58 |     25 |   -100 | :\n",
      " 59 |    400 |   -100 |  $\n",
      " 60 |   4080 |   -100 | (-\n",
      " 61 |     17 |   -100 | 2\n",
      " 62 |     11 |   -100 | ,\n",
      " 63 |     15 |   -100 | 0\n",
      " 64 |  15087 |   -100 | )$\n",
      " 65 | 151645 |   -100 | <|im_end|>\n",
      " 66 |    198 |   -100 | \n",
      "\n",
      " 67 | 151644 |   -100 | <|im_start|>\n",
      " 68 |  77091 |   -100 | assistant\n",
      " 69 |    198 |   -100 | \n",
      "\n",
      " 70 | 151667 | 151667 | <think>\n",
      " 71 |    198 |    198 | \n",
      "\n",
      " 72 |  32313 |  32313 | Okay\n",
      " 73 |     11 |     11 | ,\n",
      " 74 |   1077 |   1077 |  let\n",
      " 75 |    594 |    594 | 's\n",
      " 76 |   1490 |   1490 |  see\n",
      " 77 |   1588 |   1588 |  here\n",
      " 78 |     13 |     13 | .\n",
      " 79 |    576 |    576 |  The\n",
      " 80 |   3491 |   3491 |  problem\n",
      " 81 |    374 |    374 |  is\n",
      " 82 |  10161 |  10161 |  asking\n",
      " 83 |    911 |    911 |  about\n",
      " 84 |   7218 |   7218 |  moving\n",
      " 85 |    264 |    264 |  a\n",
      " 86 |   1459 |   1459 |  point\n",
      " 87 |    304 |    304 |  in\n",
      " 88 |    279 |    279 |  the\n",
      " 89 |  80715 |  80715 |  Cartesian\n",
      " 90 |  16184 |  16184 |  coordinate\n",
      " 91 |   1849 |   1849 |  system\n",
      " 92 |     13 |     13 | .\n",
      " 93 |    576 |    576 |  The\n",
      " 94 |   4024 |   4024 |  original\n",
      " 95 |   1459 |   1459 |  point\n",
      " 96 |    374 |    374 |  is\n",
      " 97 |    393 |    393 |  P\n",
      " 98 |   4080 |   4080 | (-\n",
      " 99 |     17 |     17 | 2\n",
      "100 |     11 |     11 | ,\n",
      "101 |    481 |    481 |  -\n",
      "102 |     18 |     18 | 3\n",
      "103 |    701 |    701 | ),\n",
      "104 |    323 |    323 |  and\n",
      "105 |    582 |    582 |  we\n",
      "106 |   1184 |   1184 |  need\n",
      "107 |    311 |    311 |  to\n",
      "108 |   1477 |   1477 |  find\n",
      "109 |   1181 |   1181 |  its\n",
      "110 |    501 |    501 |  new\n",
      "111 |  13934 |  13934 |  coordinates\n",
      "112 |   1283 |   1283 |  after\n",
      "113 |   7218 |   7218 |  moving\n",
      "114 |    220 |    220 |  \n",
      "115 |     18 |     18 | 3\n",
      "116 |   8153 |   8153 |  units\n",
      "117 |    311 |    311 |  to\n",
      "118 |    279 |    279 |  the\n",
      "119 |   1290 |   1290 |  right\n",
      "120 |     13 |     13 | .\n",
      "121 |    576 |    576 |  The\n",
      "122 |   2606 |   2606 |  options\n",
      "123 |    525 |    525 |  are\n",
      "124 |    362 |    362 |  A\n",
      "125 |   1526 |   1526 |  through\n",
      "126 |    422 |    422 |  D\n",
      "127 |     11 |     11 | ,\n",
      "128 |    448 |    448 |  with\n",
      "129 |    425 |    425 |  B\n",
      "130 |   1660 |   1660 |  being\n",
      "131 |    320 |    320 |  (\n",
      "132 |     16 |     16 | 1\n",
      "133 |     11 |     11 | ,\n",
      "134 |    481 |    481 |  -\n",
      "135 |     18 |     18 | 3\n",
      "136 |    568 |    568 | ).\n",
      "137 |  88190 |  88190 |  Hmm\n",
      "138 |     11 |     11 | ,\n",
      "139 |   7218 |   7218 |  moving\n",
      "140 |    311 |    311 |  to\n",
      "141 |    279 |    279 |  the\n",
      "142 |   1290 |   1290 |  right\n",
      "143 |   1112 |   1112 | ...\n",
      "144 |    358 |    358 |  I\n",
      "145 |   1744 |   1744 |  think\n",
      "146 |    429 |    429 |  that\n",
      "147 |  21501 |  21501 |  affects\n",
      "148 |    279 |    279 |  the\n",
      "149 |    856 |    856 |  x\n",
      "150 |  80697 |  80697 | -coordinate\n",
      "151 |     13 |     13 | .\n",
      "152 |   6771 |   6771 |  Let\n",
      "153 |    752 |    752 |  me\n",
      "154 |  19091 |  19091 |  recall\n",
      "155 |     25 |     25 | :\n",
      "156 |    304 |    304 |  in\n",
      "157 |    279 |    279 |  the\n",
      "158 |  80715 |  80715 |  Cartesian\n",
      "159 |  11031 |  11031 |  plane\n",
      "160 |     11 |     11 | ,\n",
      "161 |   7218 |   7218 |  moving\n",
      "162 |   2115 |   2115 |  left\n",
      "163 |    476 |    476 |  or\n",
      "164 |   1290 |   1290 |  right\n",
      "165 |   4344 |   4344 |  changes\n",
      "166 |    279 |    279 |  the\n",
      "167 |    856 |    856 |  x\n",
      "168 |  80697 |  80697 | -coordinate\n",
      "169 |     11 |     11 | ,\n",
      "170 |   1393 |   1393 |  while\n",
      "171 |   7218 |   7218 |  moving\n",
      "172 |    705 |    705 |  up\n",
      "173 |    476 |    476 |  or\n",
      "174 |   1495 |   1495 |  down\n",
      "175 |   4344 |   4344 |  changes\n",
      "176 |    279 |    279 |  the\n",
      "177 |    379 |    379 |  y\n",
      "178 |  80697 |  80697 | -coordinate\n",
      "179 |     13 |     13 | .\n",
      "180 |  10083 |  10083 |  Right\n",
      "181 |    374 |    374 |  is\n",
      "182 |    279 |    279 |  the\n",
      "183 |   6785 |   6785 |  positive\n",
      "184 |    856 |    856 |  x\n",
      "185 |  33049 |  33049 | -direction\n",
      "186 |     11 |     11 | ,\n",
      "187 |    323 |    323 |  and\n",
      "188 |   2115 |   2115 |  left\n",
      "189 |    374 |    374 |  is\n",
      "190 |    279 |    279 |  the\n",
      "191 |   8225 |   8225 |  negative\n",
      "192 |    856 |    856 |  x\n",
      "193 |  33049 |  33049 | -direction\n",
      "194 |     13 |     13 | .\n",
      "195 |   2055 |   2055 |  So\n",
      "196 |    421 |    421 |  if\n",
      "197 |    582 |    582 |  we\n",
      "198 |   1191 |   1191 |  start\n",
      "199 |    518 |    518 |  at\n",
      "200 |  10293 |  10293 |  (-\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(dataloader))\n",
    "print(batch.keys())  # should have input_ids, attention_mask, labels\n",
    "print(batch[\"input_ids\"].shape)\n",
    "idx = 0\n",
    "for i, (tok, label) in enumerate(zip(batch[\"input_ids\"][idx], batch[\"labels\"][idx])):\n",
    "    print(f\"{i:3d} | {tok:6d} | {label:6d} | {tokenizer.decode([tok])}\")\n",
    "    if i == 200: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': torch.Size([8, 1008]),\n",
       " 'labels': torch.Size([8, 1008]),\n",
       " 'attention_mask': torch.Size([8, 1008])}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(dataloader))\n",
    "batch_shapes = {k: v.shape for k, v in batch.items()}\n",
    "batch_shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "594"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=1e-4)\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0.05,\n",
    "    num_training_steps=num_training_steps,\n",
    ")\n",
    "num_training_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps in Epoch:   0%|          | 1/594 [00:01<10:23,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, loss 0.7193632125854492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps in Epoch:   4%|▍         | 26/594 [00:13<04:45,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, loss 0.6527539491653442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps in Epoch:   9%|▊         | 51/594 [00:25<04:32,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, loss 0.7412439584732056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps in Epoch:  13%|█▎        | 76/594 [00:37<04:19,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, loss 0.5436487793922424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps in Epoch:  17%|█▋        | 101/594 [00:49<04:09,  1.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, loss 0.46334826946258545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps in Epoch:  21%|██        | 126/594 [01:01<03:48,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, loss 0.7002703547477722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps in Epoch:  25%|██▌       | 151/594 [01:13<03:43,  1.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, loss 0.5913276672363281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps in Epoch:  30%|██▉       | 176/594 [01:25<03:30,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, loss 0.5665621757507324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps in Epoch:  34%|███▍      | 201/594 [01:37<03:17,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, loss 0.5797455906867981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps in Epoch:  38%|███▊      | 226/594 [01:49<03:04,  2.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, loss 0.4455873668193817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps in Epoch:  42%|████▏     | 251/594 [02:01<02:50,  2.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, loss 0.45242220163345337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps in Epoch:  46%|████▋     | 276/594 [02:13<02:37,  2.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, loss 0.4335593581199646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps in Epoch:  51%|█████     | 301/594 [02:25<02:26,  2.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, loss 0.609246015548706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps in Epoch:  55%|█████▍    | 326/594 [02:36<02:14,  2.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, loss 0.5312982797622681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps in Epoch:  59%|█████▉    | 351/594 [02:48<02:01,  2.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, loss 0.42360013723373413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps in Epoch:  63%|██████▎   | 376/594 [03:00<01:49,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, loss 0.499336838722229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps in Epoch:  68%|██████▊   | 401/594 [03:12<01:36,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, loss 0.533674418926239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps in Epoch:  72%|███████▏  | 426/594 [03:24<01:22,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, loss 0.5209651589393616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps in Epoch:  76%|███████▌  | 451/594 [03:36<01:11,  2.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, loss 0.4188932180404663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps in Epoch:  80%|████████  | 476/594 [03:48<00:58,  2.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, loss 0.46627914905548096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps in Epoch:  84%|████████▍ | 501/594 [04:00<00:46,  2.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, loss 0.29156753420829773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps in Epoch:  89%|████████▊ | 526/594 [04:12<00:34,  1.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, loss 0.5834300518035889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps in Epoch:  93%|█████████▎| 551/594 [04:24<00:21,  2.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, loss 0.3561060428619385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps in Epoch:  97%|█████████▋| 576/594 [04:36<00:09,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, loss 0.41198185086250305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps in Epoch: 100%|██████████| 594/594 [04:44<00:00,  2.09it/s]\n"
     ]
    }
   ],
   "source": [
    "# def train_with_sft():\n",
    "model.train()\n",
    "epoch = 1\n",
    "# for epoch in tqdm(range(num_epochs), desc=\"Epochs\", dynamic_ncols=True):\n",
    "for i in tqdm(range(num_training_steps), desc=\"Steps in Epoch\", dynamic_ncols=True):\n",
    "    batch = next(iter(dataloader))\n",
    "    batch = {k: v.to(device) for k, v in batch.items()}\n",
    "    outputs = model(**batch)\n",
    "    loss = outputs.loss\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    lr_scheduler.step()\n",
    "    optimizer.zero_grad()\n",
    "    if i % 25 == 0:\n",
    "        tqdm.write(f\"Epoch {epoch}, loss {loss.to('cpu')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[151644,    872,    198,  11510,   6556,    362,   7755,   5780,    369,\n",
      "            264,    400,     24,      3,     12,  85526,  20408,  23791,   4227,\n",
      "            323,  17933,    518,    264,  10799,   8061,  26807,     13,   3197,\n",
      "           1340,  22479,    518,    264,   6783,   4628,    315,    400,     82,\n",
      "              3,  40568,    817,   6460,     11,    279,   4227,   4990,   1059,\n",
      "            220,     19,   4115,     11,   2670,    400,     83,      3,   4420,\n",
      "           7391,    304,    279,  10799,   8061,     13,   3197,   1340,  22479,\n",
      "            400,     82,     10,     17,      3,  40568,    817,   6460,     11,\n",
      "            279,   4227,   4990,   1059,    220,     17,   4115,    323,    220,\n",
      "             17,     19,   4420,     11,   2670,    400,     83,      3,   4420,\n",
      "           7391,    304,    279,  10799,   8061,     13,  82610,    362,   7755,\n",
      "          22479,    518,    400,     82,     10,    200,  19959,     90,     16,\n",
      "          15170,     17,  31716,  40568,    817,   6460,     13,   7379,    279,\n",
      "           1372,    315,   4420,    279,   4227,   4990,   1059,     11,   2670,\n",
      "            279,    400,     83,      3,   4420,   7391,    304,    279,  10799,\n",
      "           8061,     13, 151645,    198, 151644,  77091,    198]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Every morning Aya goes for a $9$-kilometer-long walk and stops at a coffee shop afterwards. When she walks at a constant speed of $s$ kilometers per hour, the walk takes her 4 hours, including $t$ minutes spent in the coffee shop. When she walks $s+2$ kilometers per hour, the walk takes her 2 hours and 24 minutes, including $t$ minutes spent in the coffee shop. Suppose Aya walks at $s+\\frac{1}{2}$ kilometers per hour. Find the number of minutes the walk takes her, including the $t$ minutes spent in the coffee shop.\"},\n",
    "]\n",
    "tokenized = tokenizer.apply_chat_template(\n",
    "                messages,\n",
    "                tokenize=True,\n",
    "                add_generation_prompt=True,\n",
    "                return_tensors=\"pt\",\n",
    "            ).to(\"cuda\")\n",
    "print(tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model.generate(\n",
    "    tokenized,\n",
    "    do_sample=False,\n",
    "    temperature=0.001,\n",
    "    max_new_tokens=2048\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"<|im_start|>user\\nEvery morning Aya goes for a $9$-kilometer-long walk and stops at a coffee shop afterwards. When she walks at a constant speed of $s$ kilometers per hour, the walk takes her 4 hours, including $t$ minutes spent in the coffee shop. When she walks $s+2$ kilometers per hour, the walk takes her 2 hours and 24 minutes, including $t$ minutes spent in the coffee shop. Suppose Aya walks at $s+\\x0crac{1}{2}$ kilometers per hour. Find the number of minutes the walk takes her, including the $t$ minutes spent in the coffee shop.<|im_end|>\\n<|im_start|>assistant\\n<think>\\nOkay, let's see. So Aya walks 9 kilometers long every morning, and she stops at a coffee shop. The problem says she walks at a constant speed of s kilometers per hour, which takes her 4 hours, including t minutes in the coffee shop. Then, when she walks at s + 2 km/h, the walk takes her 2 hours and 24 minutes, also including t minutes in the coffee shop. We need to find the number of minutes the walk takes her, including t minutes spent in the coffee shop.\\n\\nHmm, so first, I need to find the value of s. Since she walks 9 km at a constant speed, the time taken should be the distance divided by the speed. So, time = distance / speed. So, for the first scenario, time is 4 hours, distance is 9 km, so s = 9 / 4 hours per km. Let me write that down.\\n\\ns = 9 / 4 hours per km. Then, when she walks at s + 2 km/h, which is 9/4 + 2 km/h, the time taken is 2 hours and 24 minutes. Let me convert 2 hours and 24 minutes to hours to make it easier. 2 hours is 2/60 hours, which is 1/3 hours. 24 minutes is 24/60 hours, which is 0.4 hours. So 2 hours and 24 minutes is 1/3 + 0.4 = 0.75 hours. So, the time taken at s + 2 km/h is 0.75 hours.\\n\\nSo, using the formula time = distance / speed, we can set up an equation where s + 2 = 9 / (s + 2). Wait, no, the time at s + 2 km/h is 0.75 hours, and the distance is still 9 km. So, 9 km divided by (s + 2) km/h equals 0.75 hours. So, 9 = (s + 2) * 0.75. Then, solving for s, we get s = 9 / 0.75 - 2. Let me calculate that.\\n\\n9 divided by 0.75. 0.75 is 3/4, so 9 divided by 3/4 is 9 * (4/3) = 12. So, s = 12 - 2 = 10. So, s is 10 km/h.\\n\\nNow, we need to find the number of minutes the walk takes her, including t minutes spent in the coffee shop. So, the time taken at s = 10 km/h is 4 hours, which includes t minutes. So, 4 hours is 4 hours + t minutes. But since she walks at 10 km/h, the time should be 9 km / 10 km/h = 0.9 hours. Converting 0.9 hours to minutes, 0.9 * 60 = 54 minutes. So, the walk takes her 54 minutes, including t minutes in the coffee shop. But we know that when she walks at s + 2 = 12 km/h, the time is 0.75 hours, which is 2 hours and 24 minutes. So, 9 km / 12 km/h = 0.75 hours, which is 2 hours and 24 minutes. Therefore, t minutes is 24 minutes. So, the total time is 54 minutes. Therefore, the answer should be 54 minutes.\\n\\nWait, let me check again. If s is 10 km/h, then the time at 10 km/h is 9/10 hours, which is 0.9 hours. 0.9 hours is 54 minutes. Then, when she walks at 12 km/h, the time is 9/12 hours, which is 0.75 hours, which is 2 hours and 24 minutes. So, t minutes is 24 minutes. Therefore, the total time is 54 minutes. So, the answer is 54 minutes. That seems right.\\n\\nBut let me verify the steps again. First, find s using the two scenarios. The first scenario: 9 km at s km/h takes 4 hours. So, s = 9/4. Then, the second scenario: 9 km at s + 2 km/h takes 2 hours and 24 minutes, which is 0.75 hours. So, 9 = (s + 2) * 0.75. Solving for s gives s = 10. Then, the time at s = 10 is 0.9 hours, which is 54 minutes. So, yes, that seems correct. Therefore, the answer is 54 minutes.\\n\\n**Final Answer**\\nThe number of minutes the walk takes her, including the $t$ minutes spent in the coffee shop, is \\\\boxed{54}.\\n</think>\\n\\nTo find the number of minutes the walk takes her, including the time spent in the coffee shop, we start by determining the constant speed \\\\( s \\\\) of Aya's walk.\\n\\nGiven:\\n- The distance walked is 9 kilometers.\\n- The time taken at \\\\( s \\\\) km/h is 4 hours.\\n- The time taken at \\\\( s + 2 \\\\) km/h is 2 hours and 24 minutes.\\n\\nFirst, we calculate \\\\( s \\\\) using the time taken at the original speed:\\n\\\\[\\ns = \\\\frac{9 \\\\text{ km}}{4 \\\\text{ hours}} = \\\\frac{9}{4} \\\\text{ km/h}\\n\\\\]\\n\\nNext, we use the time taken at the increased speed \\\\( s + 2 \\\\) km/h to find \\\\( s \\\\):\\n\\\\[\\ns + 2 = \\\\frac{9 \\\\text{ km}}{2 \\\\text{ hours} + \\\\frac{24}{60} \\\\text{ hours}} = \\\\frac{9}{\\\\frac{1}{3} + \\\\frac{24}{60}} = \\\\frac{9}{\\\\frac{1}{3} + \\\\frac{2}{5}} = \\\\frac{9}{\\\\frac{15}{15} + \\\\frac{6}{15}} = \\\\frac{9}{\\\\frac{21}{15}} = \\\\frac{9 \\\\times 15}{21} = \\\\frac{135}{21} = 10 \\\\text{ km/h}\\n\\\\]\\n\\nThus, \\\\( s = 10 \\\\) km/h. The time taken to walk 9 km at \\\\( s = 10 \\\\) km/h is:\\n\\\\[\\n\\\\frac{9 \\\\text{ km}}{10 \\\\text{ km/h}} = 0.9 \\\\text{ hours} = 54 \\\\text{ minutes}\\n\\\\]\\n\\nTherefore, the number of minutes the walk takes her, including the time spent in the coffee shop, is \\\\(\\\\boxed{54}\\\\).<|im_end|>\"]\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.batch_decode(outputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final eval of methods"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openr1_v3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
