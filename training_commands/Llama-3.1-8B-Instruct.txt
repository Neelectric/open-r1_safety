## practice on 1 machine
VERSION=v00.001 envsubst < recipes/meta-llama/Llama-3.1-8B-Instruct/sft/config_distill_v00.001.yaml > temp_config_01.yaml && accelerate launch --config_file recipes/accelerate_configs/zero3_last.yaml --num_processes=1 src/open_r1/sft.py --config temp_config_01.yaml


### SFT distillation
VERSION=v00.01 envsubst < recipes/meta-llama/Llama-3.1-8B-Instruct/sft/config_distill_v00.01.yaml > temp_config.yaml && accelerate launch --config_file recipes/accelerate_configs/zero3_last.yaml --num_processes=4 src/open_r1/sft.py --config temp_config.yaml

VERSION=v00.11 envsubst < recipes/meta-llama/Llama-3.1-8B-Instruct/sft/config_distill_v00.11.yaml > temp_config.yaml && accelerate launch --config_file recipes/accelerate_configs/zero3_last.yaml --num_processes=2 src/open_r1/sft.py --config temp_config.yaml





## doing bf16 grpo
VERSION=v00.13 envsubst < recipes/meta-llama/Llama-3.1-8B-Instruct/grpo/config_grpo_v00.13.yaml > temp_config.yaml && \
accelerate launch --config_file recipes/accelerate_configs/zero2.yaml --num_processes=4 src/open_r1/grpo.py --config temp_config.yaml



# weird variants claude suggested to try and fix errors before torch==2.9.0 vllm==0.11.2 bump
VLLM_ATTENTION_BACKEND=TORCH_SDPA VERSION=v00.09 envsubst < recipes/meta-llama/Llama-3.1-8B-Instruct/grpo/config_grpo_v00.09.yaml > temp_config.yaml && \
accelerate launch --config_file recipes/accelerate_configs/zero3.yaml --num_processes=5 src/open_r1/grpo.py --config temp_config.yaml

VLLM_ATTENTION_BACKEND=TORCH_SDPA VLLM_USE_CUDAGRAPH=0 







## SFT with code
setsid accelerate launch --config_file recipes/accelerate_configs/zero3_last.yaml --num_processes=8 src/open_r1/sft.py --config recipes/meta-llama/Llama-3.1-8B-Instruct/sft_code/config_distill_v00.02.yaml > training_output.txt 2>&1 &